{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "from PIL import Image\n",
    "import time\n",
    "import cv2 as cv\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print('Device:', device)\n",
    "print('Current cuda device:', torch.cuda.current_device())\n",
    "print('Count of using GPUs:', torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "torch.cuda.set_device(1)\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xs_0=list()\n",
    "xs_0_=list()\n",
    "xs_1=list()\n",
    "ys_0=list()\n",
    "data_number= 200\n",
    "batch_size = 20\n",
    "epochs = 20000\n",
    "#100장정도.. 램 가능\n",
    "with open ('data/Data_narrow.txt', 'rt' ) as r_n:\n",
    "    target_r = r_n.readline()\n",
    "    for j in range(data_number): \n",
    "        print(j)\n",
    "        xs_0=list()\n",
    "        for i in range(20): \n",
    "            temp_red=list()\n",
    "            temp_blue=list()\n",
    "            temp_green=list()\n",
    "            \n",
    "            r=open ('data/'+str(i+20*j)+'_building_r.csv', 'r' )\n",
    "            rdr=csv.reader(r)\n",
    "            for target in rdr:\n",
    "                temp_red.append(target)\n",
    "                \n",
    "            r=open ('data/'+str(i+20*j)+'_building_g.csv', 'r' )\n",
    "            rdr=csv.reader(r)\n",
    "            for target in rdr:\n",
    "                temp_green.append(target)\n",
    "                \n",
    "            r=open ('data/'+str(i+20*j)+'_building_b.csv', 'r' )\n",
    "            rdr=csv.reader(r)\n",
    "            for target in rdr:\n",
    "                temp_blue.append(target)\n",
    "                \n",
    "            temp_red=np.array(temp_red, dtype=np.float64)\n",
    "            temp_greed=np.array(temp_green, dtype=np.float64)\n",
    "            temp_blue=np.array(temp_blue, dtype=np.float64)\n",
    "\n",
    "            xs_1=np.stack((temp_red, temp_green, temp_blue), axis=0)\n",
    "            xs_1=list(xs_1) \n",
    "            xs_0.append(xs_1)\n",
    "            \n",
    "            target_r = r_n.readline()\n",
    "            if i<20:\n",
    "                A_r,B_r,C_r,D_r,E_r,F_r,G_r,H_r,I_r,J_r,K_r=target_r.split(',')  \n",
    "\n",
    "                if i==0:\n",
    "                    pass\n",
    "\n",
    "                else:\n",
    "                    if i==1:\n",
    "                        ys_0.append([float(E_r)])\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        ys_0=ys_0[:-1]+[ys_0[-1]+[float(E_r)]]\n",
    "\n",
    "        xs_0_.append(xs_0)\n",
    "\n",
    "x_train = np.array(xs_0_, dtype=np.float64)\n",
    "y_train = np.array(ys_0, dtype=np.float64)\n",
    "x_train = torch.from_numpy(x_train).cuda()\n",
    "y_train = torch.from_numpy(y_train).cuda()\n",
    "\n",
    "xs_0=list()\n",
    "xs_0_=list()\n",
    "xs_1=list()\n",
    "\n",
    "for j in range(data_number): \n",
    "    xs_0=list()\n",
    "    for i in range(20): \n",
    "        temp_red=list()\n",
    "        temp_blue=list()\n",
    "        temp_green=list()\n",
    "\n",
    "        r=open ('data/'+str(i+20*j)+'_r.csv', 'r' )\n",
    "        rdr=csv.reader(r)\n",
    "        for target in rdr:\n",
    "            temp_red.append(target)\n",
    "\n",
    "        r=open ('data/'+str(i+20*j)+'_g.csv', 'r' )\n",
    "        rdr=csv.reader(r)\n",
    "        for target in rdr:\n",
    "            temp_green.append(target)\n",
    "\n",
    "        r=open ('data/'+str(i+20*j)+'_b.csv', 'r' )\n",
    "        rdr=csv.reader(r)\n",
    "        for target in rdr:\n",
    "            temp_blue.append(target)\n",
    "\n",
    "        temp_red=np.array(temp_red, dtype=np.float64)\n",
    "        temp_greed=np.array(temp_green, dtype=np.float64)\n",
    "        temp_blue=np.array(temp_blue, dtype=np.float64)\n",
    "\n",
    "        xs_1=np.stack((temp_red, temp_green, temp_blue), axis=0)\n",
    "        xs_1=list(xs_1) \n",
    "        xs_0.append(xs_1)\n",
    "    \n",
    "    xs_0_.append(xs_0)\n",
    "        \n",
    "x_test = np.array(xs_0_, dtype=np.float64)\n",
    "x_test = torch.from_numpy(x_test).cuda()\n",
    "\n",
    "print(x_train.shape,y_train.shape)\n",
    "dataset = TensorDataset(x_train, y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataset_test = TensorDataset(x_test, y_train)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "#print(x_test.shape)\n",
    "\n",
    "xs_0=list()\n",
    "xs_0_=list()\n",
    "xs_1=list()\n",
    "ys_0=list()\n",
    "temp_red=list()\n",
    "temp_blue=list()\n",
    "temp_green=list()\n",
    "\n",
    "print(\"data_ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class LRCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LRCN, self).__init__()\n",
    "        self.layer_1 = nn.Conv2d(3,2,7,stride=3,dtype=torch.float64)\n",
    "        self.layer_2 = nn.Conv2d(3,2,7,stride=3,dtype=torch.float64)\n",
    "        self.layer_3 = nn.Conv2d(3,2,7,stride=3,dtype=torch.float64)\n",
    "        self.layer_4 = nn.Conv2d(3,2,7,stride=3,dtype=torch.float64)\n",
    "        self.layer_5 = nn.Conv2d(3,2,7,stride=3,dtype=torch.float64)\n",
    "        self.layer_6 = nn.Conv2d(3,2,7,stride=3,dtype=torch.float64)\n",
    "        self.layer_7 = nn.Conv2d(3,2,7,stride=3,dtype=torch.float64)\n",
    "        self.layer_8 = nn.Conv2d(3,2,7,stride=3,dtype=torch.float64)\n",
    "        self.layer_9 = nn.Conv2d(3,2,7,stride=3,dtype=torch.float64)\n",
    "        self.layer_10 = nn.Conv2d(3,2,7,stride=3,dtype=torch.float64)\n",
    "        self.layer_11 = nn.Conv2d(3,2,7,stride=3,dtype=torch.float64)\n",
    "        self.layer_12 = nn.Conv2d(3,2,7,stride=3,dtype=torch.float64)\n",
    "        self.layer_13 = nn.Conv2d(3,2,7,stride=3,dtype=torch.float64)\n",
    "        self.layer_14 = nn.Conv2d(3,2,7,stride=3,dtype=torch.float64)\n",
    "        self.layer_15 = nn.Conv2d(3,2,7,stride=3,dtype=torch.float64)\n",
    "        self.layer_16 = nn.Conv2d(3,2,7,stride=3,dtype=torch.float64)\n",
    "        self.layer_17 = nn.Conv2d(3,2,7,stride=3,dtype=torch.float64)\n",
    "        self.layer_18 = nn.Conv2d(3,2,7,stride=3,dtype=torch.float64)\n",
    "        self.layer_19 = nn.Conv2d(3,2,7,stride=3,dtype=torch.float64)\n",
    "        self.layer_20 = nn.Conv2d(3,2,7,stride=3,dtype=torch.float64)\n",
    "        self.layer_21 = nn.Linear(83200, 1,dtype=torch.float64)\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.length = x_train.shape[1]\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.glob_flag=0\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_1 = self.layer_1(x[:,0,:,:,:])\n",
    "        self.a = self.relu(x_1)\n",
    "        x_2 = self.layer_2(x[:,1,:,:,:])\n",
    "        self.b = self.relu(x_2)\n",
    "        x_3 = self.layer_3(x[:,2,:,:,:])\n",
    "        self.c = self.relu(x_3)\n",
    "        x_4 = self.layer_2(x[:,3,:,:,:])\n",
    "        self.d = self.relu(x_4)\n",
    "        x_5 = self.layer_1(x[:,4,:,:,:])\n",
    "        self.e = self.relu(x_5)\n",
    "        x_6 = self.layer_2(x[:,5,:,:,:])\n",
    "        self.f = self.relu(x_6)\n",
    "        x_7 = self.layer_1(x[:,6,:,:,:])\n",
    "        self.g = self.relu(x_7)\n",
    "        x_8 = self.layer_2(x[:,7,:,:,:])\n",
    "        self.h = self.relu(x_8)\n",
    "        x_9 = self.layer_1(x[:,8,:,:,:])\n",
    "        self.i = self.relu(x_9)\n",
    "        x_10 = self.layer_2(x[:,9,:,:,:])\n",
    "        self.j = self.relu(x_10)\n",
    "        x_11 = self.layer_1(x[:,10,:,:,:])\n",
    "        self.k = self.relu(x_11)\n",
    "        x_12 = self.layer_2(x[:,11,:,:,:])\n",
    "        self.l = self.relu(x_12)\n",
    "        x_13 = self.layer_1(x[:,12,:,:,:])\n",
    "        self.m = self.relu(x_13)\n",
    "        x_14 = self.layer_2(x[:,13,:,:,:])\n",
    "        self.n = self.relu(x_14)\n",
    "        x_15 = self.layer_1(x[:,14,:,:,:])\n",
    "        self.o = self.relu(x_15)\n",
    "        x_16 = self.layer_2(x[:,15,:,:,:])\n",
    "        self.p = self.relu(x_16)\n",
    "        x_17 = self.layer_1(x[:,16,:,:,:])\n",
    "        self.q = self.relu(x_17)\n",
    "        x_18 = self.layer_2(x[:,17,:,:,:])\n",
    "        self.r = self.relu(x_18)\n",
    "        x_19 = self.layer_2(x[:,18,:,:,:])\n",
    "        self.s = self.relu(x_19)\n",
    "        x_20 = self.layer_1(x[:,19,:,:,:])\n",
    "        self.t = self.relu(x_20)\n",
    "        \n",
    "        \n",
    "        self.u = torch.cat((self.a.reshape((self.batch_size, -1)),self.b.reshape((self.batch_size, -1))),axis=1)\n",
    "        self.u = torch.cat((self.u,self.c.reshape((self.batch_size, -1))),axis=1)\n",
    "        self.u = torch.cat((self.u,self.d.reshape((self.batch_size, -1))),axis=1)\n",
    "        self.u = torch.cat((self.u,self.e.reshape((self.batch_size, -1))),axis=1)\n",
    "        self.u = torch.cat((self.u,self.f.reshape((self.batch_size, -1))),axis=1)\n",
    "        self.u = torch.cat((self.u,self.g.reshape((self.batch_size, -1))),axis=1)\n",
    "        self.u = torch.cat((self.u,self.h.reshape((self.batch_size, -1))),axis=1)\n",
    "        self.u = torch.cat((self.u,self.i.reshape((self.batch_size, -1))),axis=1)\n",
    "        self.u = torch.cat((self.u,self.j.reshape((self.batch_size, -1))),axis=1)\n",
    "        self.u = torch.cat((self.u,self.k.reshape((self.batch_size, -1))),axis=1)\n",
    "        self.u = torch.cat((self.u,self.l.reshape((self.batch_size, -1))),axis=1)\n",
    "        self.u = torch.cat((self.u,self.m.reshape((self.batch_size, -1))),axis=1)\n",
    "        self.u = torch.cat((self.u,self.n.reshape((self.batch_size, -1))),axis=1)\n",
    "        self.u = torch.cat((self.u,self.o.reshape((self.batch_size, -1))),axis=1)\n",
    "        self.u = torch.cat((self.u,self.p.reshape((self.batch_size, -1))),axis=1)\n",
    "        self.u = torch.cat((self.u,self.q.reshape((self.batch_size, -1))),axis=1)\n",
    "        self.u = torch.cat((self.u,self.r.reshape((self.batch_size, -1))),axis=1)\n",
    "        self.u = torch.cat((self.u,self.s.reshape((self.batch_size, -1))),axis=1)\n",
    "        self.u = torch.cat((self.u,self.t.reshape((self.batch_size, -1))),axis=1)\n",
    "    \n",
    "        x= self.layer_21(self.u)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = LRCN().cuda()\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.MultiplicativeLR(optimizer=optimizer,\n",
    "                                        lr_lambda=lambda epoch: 0.995 ,\n",
    "                                        last_epoch=-1,\n",
    "                                        verbose=False)\n",
    "\n",
    "def image_out(feature,batch,name):\n",
    "    width_ = feature.grad.shape[-1]\n",
    "    result_temp = torch.sum(feature.grad.detach(),-1)\n",
    "    height_ = result_temp.shape[-1]\n",
    "    result_temp = torch.sum(result_temp,-1)\n",
    "    channel=result_temp.shape[1]\n",
    "    result_temp = result_temp/channel\n",
    "    temp_sum=0 \n",
    "    temp_ = feature.detach().reshape((model.batch_size, channel, height_,width_))\n",
    "    for j in range(result_temp.shape[1]):\n",
    "        temp_sum += result_temp[batch,j]*(temp_[batch,j,:,:])\n",
    "    temp_sum=model.relu(temp_sum)\n",
    "    result_temp = temp_sum.detach().cpu().numpy()\n",
    "    min_= np.min(result_temp)\n",
    "    result_temp=result_temp-min_\n",
    "    max_ = np.max(result_temp)\n",
    "    result_ = np.around(((255*result_temp)/max_)).astype(np.uint8)\n",
    "    pil_image=Image.fromarray(result_)\n",
    "    pil_image.save(name)\n",
    "    pil_image.close()\n",
    "\n",
    "def parameter_out():\n",
    "    return 0\n",
    "\n",
    "def train(dataloader, model, loss, optimizer):\n",
    "    loss_sum=0\n",
    "    total_number=len(dataloader)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        pred = model(X)\n",
    "        loss_result = loss(pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        if total_number == batch + 1:\n",
    "            model.a.retain_grad()\n",
    "            model.b.retain_grad()\n",
    "            model.c.retain_grad()\n",
    "            model.d.retain_grad()\n",
    "            model.e.retain_grad()\n",
    "            model.f.retain_grad()\n",
    "            model.g.retain_grad()\n",
    "            model.h.retain_grad()\n",
    "            model.i.retain_grad()\n",
    "            model.j.retain_grad()\n",
    "            model.k.retain_grad()\n",
    "            model.l.retain_grad()\n",
    "            model.m.retain_grad()\n",
    "            model.n.retain_grad()\n",
    "            model.o.retain_grad()\n",
    "            model.p.retain_grad()\n",
    "            model.q.retain_grad()\n",
    "            model.r.retain_grad()\n",
    "            model.s.retain_grad()\n",
    "            model.t.retain_grad()\n",
    "\n",
    "        loss_result.backward()\n",
    "        optimizer.step()\n",
    "        loss_sum+=loss_result\n",
    "    \n",
    "    loss_sum/(batch+1)\n",
    "    print(\"train_loss\",loss_sum)\n",
    "    \n",
    "    if model.glob_flag==10:\n",
    "        image_out(model.a,0,\"training_1.png\")\n",
    "        image_out(model.b,0,\"training_2.png\")\n",
    "        image_out(model.c,0,\"training_3.png\")\n",
    "        image_out(model.d,0,\"training_4.png\")\n",
    "        image_out(model.e,0,\"training_5.png\")\n",
    "        image_out(model.f,0,\"training_6.png\")\n",
    "        image_out(model.g,0,\"training_7.png\")\n",
    "        image_out(model.h,0,\"training_8.png\")\n",
    "        image_out(model.i,0,\"training_9.png\")\n",
    "        image_out(model.j,0,\"training_10.png\")\n",
    "        image_out(model.k,0,\"training_11.png\")\n",
    "        image_out(model.l,0,\"training_12.png\")\n",
    "        image_out(model.m,0,\"training_13.png\")\n",
    "        image_out(model.n,0,\"training_14.png\")\n",
    "        image_out(model.o,0,\"training_15.png\")\n",
    "        image_out(model.p,0,\"training_16.png\")\n",
    "        image_out(model.q,0,\"training_17.png\")\n",
    "        image_out(model.r,0,\"training_18.png\")\n",
    "        image_out(model.s,0,\"training_19.png\")\n",
    "        image_out(model.t,0,\"training_20.png\")\n",
    "        \n",
    "            \n",
    "def test(dataloader, model, loss, optimizer):\n",
    "    loss_sum=0\n",
    "    total_number=len(dataloader)\n",
    "    #print(len(dataloader), len(dataloader[0]))\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        pred = model(X)\n",
    "        loss_result = loss(pred, y)\n",
    "        if total_number == batch + 1:\n",
    "            optimizer.zero_grad()\n",
    "            model.a.retain_grad()\n",
    "            model.b.retain_grad()\n",
    "            model.c.retain_grad()\n",
    "            model.d.retain_grad()\n",
    "            model.e.retain_grad()\n",
    "            model.f.retain_grad()\n",
    "            model.g.retain_grad()\n",
    "            model.h.retain_grad()\n",
    "            model.i.retain_grad()\n",
    "            model.j.retain_grad()\n",
    "            model.k.retain_grad()\n",
    "            model.l.retain_grad()\n",
    "            model.m.retain_grad()\n",
    "            model.n.retain_grad()\n",
    "            model.o.retain_grad()\n",
    "            model.p.retain_grad()\n",
    "            model.q.retain_grad()\n",
    "            model.r.retain_grad()\n",
    "            model.s.retain_grad()\n",
    "            model.t.retain_grad()\n",
    "\n",
    "        loss_result.backward()\n",
    "        \n",
    "        loss_sum+=loss_result\n",
    "    loss_sum/(batch+1)\n",
    "    print(\"test_loss\",loss_sum)\n",
    "    \n",
    "    if model.glob_flag==10:\n",
    "        model.glob_flag=0\n",
    "        image_out(model.a,0,\"test_1.png\")\n",
    "        image_out(model.b,0,\"test_2.png\")\n",
    "        image_out(model.c,0,\"test_3.png\")\n",
    "        image_out(model.d,0,\"test_4.png\")\n",
    "        image_out(model.e,0,\"test_5.png\")\n",
    "        image_out(model.f,0,\"test_6.png\")\n",
    "        image_out(model.g,0,\"test_7.png\")\n",
    "        image_out(model.h,0,\"test_8.png\")\n",
    "        image_out(model.i,0,\"test_9.png\")\n",
    "        image_out(model.j,0,\"test_10.png\")\n",
    "        image_out(model.k,0,\"test_11.png\")\n",
    "        image_out(model.l,0,\"test_12.png\")\n",
    "        image_out(model.m,0,\"test_13.png\")\n",
    "        image_out(model.n,0,\"test_14.png\")\n",
    "        image_out(model.o,0,\"test_15.png\")\n",
    "        image_out(model.p,0,\"test_16.png\")\n",
    "        image_out(model.q,0,\"test_17.png\")\n",
    "        image_out(model.r,0,\"test_18.png\")\n",
    "        image_out(model.s,0,\"test_19.png\")\n",
    "        image_out(model.t,0,\"test_20.png\")\n",
    "    \n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(dataloader, model, loss, optimizer)\n",
    "    test(dataloader_test, model, loss, optimizer)\n",
    "    model.glob_flag+=1\n",
    "    scheduler.step()\n",
    "    print(optimizer.param_groups[0]['lr'])\n",
    "print(\"Done!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
