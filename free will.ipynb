{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b5c8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "from PIL import Image\n",
    "import time\n",
    "import cv2 as cv\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print('Device:', device)\n",
    "print('Current cuda device:', torch.cuda.current_device())\n",
    "print('Count of using GPUs:', torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "##torch.cuda.set_device(1)\n",
    "#print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad1b947",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xs_0=list()\n",
    "xs_0_=list()\n",
    "xs_1=list()\n",
    "ys_0=list()\n",
    "data_number= 20\n",
    "batch_size = 4\n",
    "epochs = 20000\n",
    "#100장정도.. 램 가능\n",
    "with open ('data/Data_narrow.txt', 'rt' ) as r_n:\n",
    "    target_r = r_n.readline()\n",
    "    for j in range(data_number): \n",
    "        print(j)\n",
    "        xs_0=list()\n",
    "        for i in range(20): \n",
    "            temp_red=list()\n",
    "            temp_blue=list()\n",
    "            temp_green=list()\n",
    "            \n",
    "            r=open ('data/'+str(i+20*j)+'_building_r.csv', 'r' )\n",
    "            rdr=csv.reader(r)\n",
    "            for target in rdr:\n",
    "                temp_red.append(target)\n",
    "                \n",
    "            r=open ('data/'+str(i+20*j)+'_building_g.csv', 'r' )\n",
    "            rdr=csv.reader(r)\n",
    "            for target in rdr:\n",
    "                temp_green.append(target)\n",
    "                \n",
    "            r=open ('data/'+str(i+20*j)+'_building_b.csv', 'r' )\n",
    "            rdr=csv.reader(r)\n",
    "            for target in rdr:\n",
    "                temp_blue.append(target)\n",
    "                \n",
    "            temp_red=np.array(temp_red, dtype=np.float64)\n",
    "            temp_greed=np.array(temp_green, dtype=np.float64)\n",
    "            temp_blue=np.array(temp_blue, dtype=np.float64)\n",
    "\n",
    "            xs_1=np.stack((temp_red, temp_green, temp_blue), axis=0)\n",
    "            xs_1=list(xs_1) \n",
    "            xs_0.append(xs_1)\n",
    "            \n",
    "            target_r = r_n.readline()\n",
    "            if i<20:\n",
    "                A_r,B_r,C_r,D_r,E_r,F_r,G_r,H_r,I_r,J_r,K_r=target_r.split(',')  \n",
    "\n",
    "                if i==0:\n",
    "                    pass\n",
    "\n",
    "                else:\n",
    "                    if i==1:\n",
    "                        ys_0.append([float(E_r)])\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        ys_0=ys_0[:-1]+[ys_0[-1]+[float(E_r)]]\n",
    "\n",
    "        xs_0_.append(xs_0)\n",
    "\n",
    "x_train = np.array(xs_0_, dtype=np.float64)\n",
    "y_train = np.array(ys_0, dtype=np.float64)\n",
    "#y_train = np.zeros_like(y_train)\n",
    "x_train = torch.from_numpy(x_train).cuda()\n",
    "y_train = torch.from_numpy(y_train).cuda()\n",
    "#print(y_train)\n",
    "xs_0=list()\n",
    "xs_0_=list()\n",
    "xs_1=list()\n",
    "\n",
    "for j in range(data_number): \n",
    "    xs_0=list()\n",
    "    for i in range(20): \n",
    "        temp_red=list()\n",
    "        temp_blue=list()\n",
    "        temp_green=list()\n",
    "\n",
    "        r=open ('data/'+str(i+20*j)+'_r.csv', 'r' )\n",
    "        rdr=csv.reader(r)\n",
    "        for target in rdr:\n",
    "            temp_red.append(target)\n",
    "\n",
    "        r=open ('data/'+str(i+20*j)+'_g.csv', 'r' )\n",
    "        rdr=csv.reader(r)\n",
    "        for target in rdr:\n",
    "            temp_green.append(target)\n",
    "\n",
    "        r=open ('data/'+str(i+20*j)+'_b.csv', 'r' )\n",
    "        rdr=csv.reader(r)\n",
    "        for target in rdr:\n",
    "            temp_blue.append(target)\n",
    "\n",
    "        temp_red=np.array(temp_red, dtype=np.float64)\n",
    "        temp_greed=np.array(temp_green, dtype=np.float64)\n",
    "        temp_blue=np.array(temp_blue, dtype=np.float64)\n",
    "\n",
    "        xs_1=np.stack((temp_red, temp_green, temp_blue), axis=0)\n",
    "        xs_1=list(xs_1) \n",
    "        xs_0.append(xs_1)\n",
    "    \n",
    "    xs_0_.append(xs_0)\n",
    "        \n",
    "x_test = np.array(xs_0_, dtype=np.float64)\n",
    "x_test = torch.from_numpy(x_test).cuda()\n",
    "\n",
    "print(x_train.shape,y_train.shape)\n",
    "dataset = TensorDataset(x_train, y_train)\n",
    "#dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "sampler_1=torch.utils.data.RandomSampler(dataset)\n",
    "batch_1=torch.utils.data.BatchSampler(sampler_1,batch_size,False)\n",
    "\n",
    "dataset_test = TensorDataset(x_test, y_train)\n",
    "#dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "sampler_2=torch.utils.data.RandomSampler(dataset_test)\n",
    "batch_2=torch.utils.data.BatchSampler(sampler_2,batch_size,False)\n",
    "#print(x_test.shape)\n",
    "\n",
    "xs_0=list()\n",
    "xs_0_=list()\n",
    "xs_1=list()\n",
    "ys_0=list()\n",
    "temp_red=list()\n",
    "temp_blue=list()\n",
    "temp_green=list()\n",
    "\n",
    "print(\"data_ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198c0c0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class LRCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LRCN, self).__init__()\n",
    "        self.layer_1 = nn.Conv2d(3,15,5,stride=2,dtype=torch.float64)\n",
    "        self.layer_2 = nn.Conv2d(15,13,5,stride=2,dtype=torch.float64)\n",
    "        self.layer_3 = nn.Conv2d(13,7,5,stride=2,dtype=torch.float64)\n",
    "        self.layer_4 = nn.Conv2d(7,3,5,stride=2,dtype=torch.float64)\n",
    "        self.layer_5 = nn.LSTM(81,40,2, batch_first = True,dtype=torch.float64)\n",
    "        self.layer_6 = nn.Linear(40, 1,dtype=torch.float64)\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.length = x_train.shape[1]\n",
    "        self.relu = nn.ReLU()\n",
    "        self.glob_flag=0\n",
    "        self.batch_number=0\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.reshape((-1, 3, 100, 200))\n",
    "        x = self.layer_1(x)\n",
    "        self.a = self.relu(x)\n",
    "        x = self.layer_2(self.a)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer_3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer_4(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.reshape((self.batch_size, self.length, x.shape[-3],x.shape[-2],x.shape[-1]))\n",
    "        x = x.reshape((self.batch_size, self.length, x.shape[-3]*x.shape[-2]*x.shape[-1]))\n",
    "        x, (h_n, c_n) = self.layer_5(x)\n",
    "        #print(x.shape,h_n.shape,c_n.shape)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer_6(x)\n",
    "        x = torch.squeeze(x,dim=2)\n",
    "        #print(x.shape)\n",
    "        return x[:,1:], x[:,0]\n",
    "\n",
    "model = LRCN().cuda()\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.MultiplicativeLR(optimizer=optimizer,\n",
    "                                        lr_lambda=lambda epoch: 1 ,\n",
    "                                        last_epoch=-1,\n",
    "                                        verbose=False)\n",
    "def image_out(feature,batch,name):\n",
    "    width_ = feature.grad.shape[-1]\n",
    "    #ttt=feature.grad.detach()\n",
    "    #ttt=torch.sum(ttt,-1)\n",
    "    #print(ttt.shape,feature.grad.shape)\n",
    "    #result_temp = torch.sum(feature.grad.detach(),-1)\n",
    "    #important\n",
    "    result_temp = torch.sum(torch.abs(feature.grad.detach()),-1)\n",
    "    #print(torch.where(result_temp>=0))\n",
    "    height_ = result_temp.shape[-1]\n",
    "    result_temp = torch.sum(result_temp,-1)\n",
    "    channel=result_temp.shape[1]\n",
    "    result_temp = result_temp/channel\n",
    "    #print(result_temp.shape)\n",
    "    temp_ = feature.detach().reshape((model.batch_size*model.length, channel, height_,width_))\n",
    "    #print(torch.min(temp_))\n",
    "    #print(result_temp.shape,temp_.shape)\n",
    "    for i in range(model.length):\n",
    "        temp_sum=0\n",
    "        for j in range(result_temp.shape[1]):\n",
    "            #print(i,j,result_temp.shape[1])\n",
    "            temp_sum += result_temp[batch*model.length+i,j]*(temp_[batch*model.length+i,j,:,:])\n",
    "        #temp_sum=temp_sum\n",
    "        temp_sum = temp_sum.detach().cpu().numpy()\n",
    "        #print(np.min(temp_sum))\n",
    "        temp_positive = np.where(temp_sum>0, temp_sum,0)\n",
    "        temp_negative = np.where(temp_sum<0, temp_sum,0)\n",
    "        \n",
    "        #print(np.min(temp_sum))\n",
    "        min_= np.min(temp_sum)\n",
    "        temp_sum=temp_sum-min_\n",
    "        max_ = np.max(temp_sum)\n",
    "        result_ = np.around(((255*temp_sum)/max_)).astype(np.uint8)\n",
    "        pil_image=Image.fromarray(result_)\n",
    "        name_final = name+str(i)+'.png'\n",
    "        pil_image.save(name_final)\n",
    "        pil_image.close()\n",
    "\n",
    "        max_ = np.max(temp_positive)\n",
    "        result_ = np.around(((255*temp_positive)/max_)).astype(np.uint8)\n",
    "        pil_image=Image.fromarray(result_)\n",
    "        name_final = name+str(i)+'_positive.png'\n",
    "        pil_image.save(name_final)\n",
    "        pil_image.close()\n",
    "        \n",
    "        temp_negative=np.abs(temp_negative)\n",
    "        max_ = np.max(temp_negative)\n",
    "        result_ = np.around(((255*temp_sum)/max_)).astype(np.uint8)\n",
    "        pil_image=Image.fromarray(result_)\n",
    "        name_final = name+str(i)+'_negative.png'\n",
    "        pil_image.save(name_final)\n",
    "        pil_image.close()\n",
    "    \n",
    "def train(dataloader, model, loss, optimizer):\n",
    "    loss_sum=0\n",
    "    total_number=len(dataloader)\n",
    "    #print(dataloader)\n",
    "    for batch, batch_number in enumerate(dataloader):\n",
    "        #print(X)\n",
    "        model.batch_number=batch_number\n",
    "        X = dataset[batch_number][0]\n",
    "        y = dataset[batch_number][1]\n",
    "        pred,first_ = model(X)\n",
    "        #print(first_)\n",
    "        #print(pred)\n",
    "        #print(\"-------\")\n",
    "        #print(y)\n",
    "        #print(pred.shape,y.shape)\n",
    "        optimizer.zero_grad()\n",
    "        loss_result = loss(pred, y)\n",
    "        \n",
    "        if total_number == batch + 1:\n",
    "            model.a.retain_grad()\n",
    "        loss_result.backward()\n",
    "        if torch.mean(first_) >0.2:\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            X_test=dataset_test[batch_number][0]\n",
    "            X_test[:,0]=X[:,0]\n",
    "            print(\"yes\",first_)\n",
    "            \n",
    "            pred,first_ = model(X_test)\n",
    "            loss_result = loss(pred, y)\n",
    "            if total_number == batch + 1:\n",
    "                model.a.retain_grad()\n",
    "            loss_result.backward()\n",
    "        else:\n",
    "            print(\"no\",first_,torch.mean(first_))\n",
    "        \n",
    "        optimizer.step()\n",
    "        loss_sum+=loss_result\n",
    "    loss_sum/(batch+1)\n",
    "    \n",
    "    print(\"train_loss\",loss_sum)\n",
    "    \n",
    "    if model.glob_flag==10:\n",
    "        model.glob_flag=0\n",
    "        image_out(model.a,0,\"training_\")\n",
    "\"\"\"\n",
    "def test(dataloader, model, loss):\n",
    "    loss_sum=0\n",
    "    total_number=len(dataloader)\n",
    "    for batch, _ in enumerate(dataloader):\n",
    "        X = dataset_test[batch_number][0]\n",
    "        y = dataset[batch_number][1]\n",
    "        pred = model(X)\n",
    "        loss_result = loss(pred, y)\n",
    "        #print(pred.shape,y.shape)\n",
    "        if total_number == batch + 1:\n",
    "            optimizer.zero_grad()\n",
    "            model.a.retain_grad()\n",
    "        loss_result.backward()\n",
    "        loss_sum+=loss_result\n",
    "    loss_sum/(batch+1)\n",
    "    print(\"test_loss\",loss_sum)\n",
    "    if model.glob_flag==10:\n",
    "        model.glob_flag=0\n",
    "        image_out(model.a,0,\"test_\")\n",
    "\"\"\"\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(batch_1, model, loss, optimizer)\n",
    "    #test(batch_2, model, loss)\n",
    "    model.glob_flag+=1\n",
    "    scheduler.step()\n",
    "    \n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
