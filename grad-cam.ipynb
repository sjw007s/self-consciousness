{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x0000025B8282BB50>\n"
     ]
    }
   ],
   "source": [
    "xs_0=list()\n",
    "xs_0_=list()\n",
    "xs_1=list()\n",
    "ys_0=list()\n",
    "with open ('data/Data_narrow.txt', 'rt' ) as r_n:\n",
    "    target_r = r_n.readline()\n",
    "    for j in range(1): \n",
    "        xs_0=list()\n",
    "        ys_0=list()\n",
    "        for i in range(10): \n",
    "            temp_red=list()\n",
    "            temp_blue=list()\n",
    "            temp_green=list()\n",
    "            \n",
    "            r=open ('data/'+str(i+10*j)+'_building_r.csv', 'r' )\n",
    "            rdr=csv.reader(r)\n",
    "            for target in rdr:\n",
    "                temp_red.append(target)\n",
    "                \n",
    "            r=open ('data/'+str(i+10*j)+'_building_g.csv', 'r' )\n",
    "            rdr=csv.reader(r)\n",
    "            for target in rdr:\n",
    "                temp_green.append(target)\n",
    "                \n",
    "            r=open ('data/'+str(i+10*j)+'_building_b.csv', 'r' )\n",
    "            rdr=csv.reader(r)\n",
    "            for target in rdr:\n",
    "                temp_blue.append(target)\n",
    "                \n",
    "            temp_red=np.array(temp_red, dtype=np.float32)\n",
    "            temp_greed=np.array(temp_green, dtype=np.float32)\n",
    "            temp_blue=np.array(temp_blue, dtype=np.float32)\n",
    "\n",
    "            xs_1=np.stack((temp_red, temp_green, temp_blue), axis=2)\n",
    "            xs_1=list(xs_1) \n",
    "            xs_0.append(xs_1)\n",
    "            \n",
    "            target_r = r_n.readline()\n",
    "            if i<10:\n",
    "                A_r,B_r,C_r,D_r,E_r,F_r,G_r,H_r,I_r,J_r,K_r=target_r.split(',')  \n",
    "\n",
    "                if i==0:\n",
    "                    pass\n",
    "\n",
    "                if i==1:\n",
    "                    ys_0.append([float(E_r)])\n",
    "\n",
    "                if i>=2 and i<10:\n",
    "\n",
    "                    ys_0=ys_0[:-1]+[ys_0[-1]+[float(E_r)]]\n",
    "                \n",
    "                \n",
    "\n",
    "        xs_0_.append(xs_0)\n",
    "\n",
    "\n",
    "x_train = np.array(xs_0_, dtype=np.float32)\n",
    "y_train = np.array(ys_0, dtype=np.float32)\n",
    "x_train = torch.from_numpy(x_train)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "dataset = TensorDataset(x_train, y_train)\n",
    "batch_size = 1\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "print(dataloader)\n",
    "\n",
    "xs_0=list()\n",
    "xs_0_=list()\n",
    "xs_1=list()\n",
    "ys_0=list()\n",
    "temp_red=list()\n",
    "temp_blue=list()\n",
    "temp_green=list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b50659ffcf6e46cd98a8ddd06bc5fa05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=26421880.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "974f4223a7f54453a62e944e515be4f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=29515.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7808570c491e4962a8d0d251a0f0812d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4422102.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b95f6c9d20a4fd5abe4121519807c1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5148.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
      "Shape of y:  torch.Size([64]) torch.int64\n",
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.299516  [    0/60000]\n",
      "loss: 2.291182  [ 6400/60000]\n",
      "loss: 2.273744  [12800/60000]\n",
      "loss: 2.268947  [19200/60000]\n",
      "loss: 2.249958  [25600/60000]\n",
      "loss: 2.220845  [32000/60000]\n",
      "loss: 2.230830  [38400/60000]\n",
      "loss: 2.195443  [44800/60000]\n",
      "loss: 2.191133  [51200/60000]\n",
      "loss: 2.163878  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 2.155694 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.165143  [    0/60000]\n",
      "loss: 2.156482  [ 6400/60000]\n",
      "loss: 2.094890  [12800/60000]\n",
      "loss: 2.113179  [19200/60000]\n",
      "loss: 2.062320  [25600/60000]\n",
      "loss: 2.002541  [32000/60000]\n",
      "loss: 2.038827  [38400/60000]\n",
      "loss: 1.956526  [44800/60000]\n",
      "loss: 1.960134  [51200/60000]\n",
      "loss: 1.891402  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 1.887394 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.924790  [    0/60000]\n",
      "loss: 1.893642  [ 6400/60000]\n",
      "loss: 1.771734  [12800/60000]\n",
      "loss: 1.810654  [19200/60000]\n",
      "loss: 1.703983  [25600/60000]\n",
      "loss: 1.662377  [32000/60000]\n",
      "loss: 1.695073  [38400/60000]\n",
      "loss: 1.594814  [44800/60000]\n",
      "loss: 1.618869  [51200/60000]\n",
      "loss: 1.518749  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.532883 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.605655  [    0/60000]\n",
      "loss: 1.569815  [ 6400/60000]\n",
      "loss: 1.418897  [12800/60000]\n",
      "loss: 1.480262  [19200/60000]\n",
      "loss: 1.364707  [25600/60000]\n",
      "loss: 1.367602  [32000/60000]\n",
      "loss: 1.390352  [38400/60000]\n",
      "loss: 1.313570  [44800/60000]\n",
      "loss: 1.348080  [51200/60000]\n",
      "loss: 1.253346  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.0%, Avg loss: 1.276118 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.356119  [    0/60000]\n",
      "loss: 1.338019  [ 6400/60000]\n",
      "loss: 1.173296  [12800/60000]\n",
      "loss: 1.264605  [19200/60000]\n",
      "loss: 1.138371  [25600/60000]\n",
      "loss: 1.171568  [32000/60000]\n",
      "loss: 1.198887  [38400/60000]\n",
      "loss: 1.134495  [44800/60000]\n",
      "loss: 1.175846  [51200/60000]\n",
      "loss: 1.094219  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.4%, Avg loss: 1.112625 \n",
      "\n",
      "Done!\n",
      "Saved PyTorch Model State to model.pth\n",
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "# 모델을 정의합니다.\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 예측 오류 계산\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # 역전파\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    \n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")\n",
    "\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")\n",
    "\n",
    "model = NeuralNetwork()\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "\n",
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class ModelOutputs_resnet():\n",
    "    def __init__(self, model, target_layers, target_sub_layers):\n",
    "        self.model = model\n",
    "        self.target_layers = target_layers\n",
    "        self.target_sub_layers = target_sub_layers\n",
    "        self.gradients = []\n",
    "\n",
    "    def save_gradient(self, grad):\n",
    "        self.gradients.append(grad)\n",
    "\n",
    "    def get_gradients(self):\n",
    "        return self.gradients\n",
    "\n",
    "    def __call__(self, x):\n",
    "        self.gradients = []\n",
    "        for name, module in self.model.named_children(): # 모든 layer에 대해서 직접 접근\n",
    "            x = module(x)\n",
    "            if name== 'avgpool': # avgpool이후 fully connect하기 전 data shape을 flatten시킴\n",
    "                x = torch.flatten(x,1)\n",
    "            if name in self.target_layers: # target_layer라면 해당 layer에서의 gradient를 저장\n",
    "                for sub_name, sub_module in module[len(module)-1].named_children():\n",
    "                    if sub_name in self.target_sub_layers:\n",
    "                        x.register_hook(self.save_gradient) #\n",
    "                        target_feature_maps = x # x's shape = 512X14X14(C,W,H) feature map\n",
    "        return target_feature_maps, x # target_activation : target_activation_layer's feature maps // output : classification ( ImageNet's classes : 1000 )\n",
    "\n",
    "\n",
    "class GradCam_resnet:\n",
    "    def __init__(self, model, target_layer_names,target_sub_layer_names, use_cuda):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.cuda = use_cuda\n",
    "        if self.cuda:  # GPU일 경우 model을 cuda로 설정\n",
    "            self.model = model.cuda()\n",
    "\n",
    "        self.extractor = ModelOutputs_resnet(self.model, target_layer_names,target_sub_layer_names)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "\n",
    "    def __call__(self, input, index=None):\n",
    "\n",
    "        if self.cuda:  # GPU일 경우 input을 cuda로 변환하여 전달\n",
    "            features, output = self.extractor(input.cuda())\n",
    "        else:\n",
    "            features, output = self.extractor(input)\n",
    "\n",
    "        probs,idx = 0, 0\n",
    "        if index == None:\n",
    "            index = np.argmax(output.cpu().data.numpy())  # index = 정답이라고 추측한 class index\n",
    "            h_x = F.softmax(output,dim=1).data.squeeze()\n",
    "            probs, idx = h_x.sort(0,True)\n",
    "\n",
    "\n",
    "        one_hot = np.zeros((1, output.size()[-1]), dtype=np.float32)\n",
    "        one_hot[0][index] = 1  # 정답이라고 생각하는 class의 index 리스트 위치의 값만 1로\n",
    "        one_hot = torch.from_numpy(one_hot).requires_grad_(True)  # numpy배열을 tensor로 변환\n",
    "        # requires_grad == True 텐서의 모든 연산에 대하여 추적\n",
    "        if self.cuda:\n",
    "            one_hot = torch.sum(one_hot.cuda() * output)\n",
    "        else:\n",
    "            one_hot = torch.sum(one_hot * output)\n",
    "\n",
    "        self.model.zero_grad()\n",
    "        one_hot.backward(retain_graph=True)\n",
    "\n",
    "        grads_val = self.extractor.get_gradients()[-1].cpu().data.numpy()\n",
    "\n",
    "        target = features  # A^k\n",
    "\n",
    "        target_cam = target.cpu().data.numpy()\n",
    "        bz, nc, h,w = target_cam.shape\n",
    "\n",
    "        target = target.cpu().data.numpy()[0, :]\n",
    "\n",
    "        params = list(self.model.parameters())\n",
    "\n",
    "        weight_softmax = np.squeeze(params[-2].data.cpu().numpy())\n",
    "\n",
    "        cam = weight_softmax[index].dot(target_cam.reshape((nc,h*w)))\n",
    "        cam = cam.reshape(h,w)\n",
    "        cam = np.maximum(cam, 0)\n",
    "        cam = cv2.resize(cam, (224, 224))  # 224X224크기로 변환\n",
    "        cam = cam - np.min(cam)\n",
    "        cam = cam / np.max(cam)\n",
    "\n",
    "\n",
    "        weights = np.mean(grads_val, axis=(2, 3))[0, :]  # 논문에서의 global average pooling 식에 해당하는 부분\n",
    "        grad_cam = np.zeros(target.shape[1:], dtype=np.float32)  # 14X14\n",
    "\n",
    "        for i, w in enumerate(weights): # calcul grad_cam\n",
    "            grad_cam += w * target[i, :, :]  # linear combination L^c_{Grad-CAM}에 해당하는 식에서 ReLU를 제외한 식\n",
    "\n",
    "        grad_cam = np.maximum(grad_cam, 0)  # 0보다 작은 값을 제거\n",
    "        grad_cam = cv2.resize(grad_cam, (224, 224))  # 224X224크기로 변환\n",
    "        grad_cam = grad_cam - np.min(grad_cam)  #\n",
    "        grad_cam = grad_cam / np.max(grad_cam)  # 위의 것과 해당 줄의 것은 0~1사이의 값으로 정규화하기 위한 정리\n",
    "        return grad_cam, cam ,index,probs,idx ,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class FeatureExtractor_vgg():\n",
    "    \"\"\" Class for extracting activations and\n",
    "    registering gradients from targetted intermediate layers \"\"\"\n",
    "\n",
    "    def __init__(self, model, target_layers): # target_layers = 35 ==> VGG19에서 가장 마지막 MaxPool2D전 ReLU함수\n",
    "        self.model = model\n",
    "        self.target_layers = target_layers\n",
    "        self.gradients = []\n",
    "\n",
    "    def save_gradient(self, grad):\n",
    "        self.gradients.append(grad)\n",
    "\n",
    "\n",
    "    def __call__(self, x):\n",
    "        self.gradients = []\n",
    "        for name, module in self.model._modules.items(): # 모든 layer에 대해서 직접 접근\n",
    "            x = module(x)\n",
    "            if name in self.target_layers: # target_layer라면 해당 layer에서의 gradient를 저장\n",
    "                x.register_hook(self.save_gradient) #\n",
    "                target_feature_maps = x # x's shape = 512X14X14(C,W,H) feature map\n",
    "        return target_feature_maps, x\n",
    "\n",
    "\n",
    "class ModelOutputs_vgg():\n",
    "    \"\"\" Class for making a forward pass, and getting:\n",
    "    1. The network output.\n",
    "    2. Activations from intermeddiate targetted layers.\n",
    "    3. Gradients from intermeddiate targetted layers. \"\"\"\n",
    "\n",
    "    def __init__(self, model, target_layers):\n",
    "        self.model = model\n",
    "        self.feature_extractor = FeatureExtractor_vgg(self.model.features, target_layers)\n",
    "\n",
    "    def get_gradients(self):\n",
    "        return self.feature_extractor.gradients\n",
    "\n",
    "    def __call__(self, x):\n",
    "        target_activations, output = self.feature_extractor(x)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        output = self.model.classifier(output) # feature extract를 통해서 나온 값을 활용하여 classification 진행\n",
    "        #print(\"ModelOutputs().output.shape : \",output[0])\n",
    "        #print(\"ModelOutputs().target_activations.shape :\",target_activations[0])\n",
    "        return target_activations, output\n",
    "\n",
    "class GradCam_vgg:\n",
    "    def __init__(self, model, target_layer_names, use_cuda):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.cuda = use_cuda\n",
    "        if self.cuda: # GPU일 경우 model을 cuda로 설정\n",
    "            self.model = model.cuda()\n",
    "\n",
    "        self.extractor = ModelOutputs_vgg(self.model, target_layer_names)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "\n",
    "    def __call__(self, input, index=None):\n",
    "        if self.cuda: # GPU일 경우 input을 cuda로 변환하여 전달\n",
    "            features, output = self.extractor(input.cuda())\n",
    "        else:\n",
    "            features, output = self.extractor(input)\n",
    "        #print(\"features : \",features.cpu().data.numpy().shape) # 해당 위치에서 추출된 feature map ( 512,14,14 ) (ChannelX14X14)\n",
    "        #print(\"output : \",output.cpu().data.numpy().shape) # class를 의미함\n",
    "        probs, idx = 0,0\n",
    "        #print(\"index : \", index)\n",
    "        if index == None:\n",
    "            index = np.argmax(output.cpu().data.numpy())  # index = 정답이라고 추측한 class index\n",
    "            h_x = F.softmax(output,dim=1).data.squeeze()\n",
    "            probs, idx = h_x.sort(0,True)\n",
    "        #print(\"index : \", index)\n",
    "        one_hot = np.zeros((1, output.size()[-1]), dtype=np.float32)\n",
    "        one_hot[0][index] = 1 # 정답이라고 생각하는 class의 index 리스트 위치의 값만 1로\n",
    "        one_hot = torch.from_numpy(one_hot).requires_grad_(True) # numpy배열을 tensor로 변환\n",
    "        # requires_grad == True 텐서의 모든 연산에 대하여 추적\n",
    "        if self.cuda:\n",
    "            one_hot = torch.sum(one_hot.cuda() * output)\n",
    "        else:\n",
    "            one_hot = torch.sum(one_hot * output)\n",
    "\n",
    "        self.model.features.zero_grad()\n",
    "        self.model.classifier.zero_grad()\n",
    "        one_hot.backward(retain_graph=True)\n",
    "\n",
    "        grads_val = self.extractor.get_gradients()[-1].cpu().data.numpy()\n",
    "        #print(\"grads_val : \",grads_val.shape) # 512 X 14 X 14\n",
    "        target = features  # A^k\n",
    "        target = target.cpu().data.numpy()[0, :]\n",
    "\n",
    "        cam = None\n",
    "\n",
    "        weights = np.mean(grads_val, axis=(2, 3))[0, :]  # 논문에서의 global average pooling 식에 해당하는 부분\n",
    "        grad_cam = np.zeros(target.shape[1:], dtype=np.float32)  # 14X14\n",
    "\n",
    "        for i, w in enumerate(weights):  # calcul grad_cam\n",
    "            grad_cam += w * target[i, :, :]  # linear combination L^c_{Grad-CAM}에 해당하는 식에서 ReLU를 제외한 식\n",
    "\n",
    "        grad_cam = np.maximum(grad_cam, 0)  # 0보다 작은 값을 제거\n",
    "        grad_cam = cv2.resize(grad_cam, (224, 224))  # 224X224크기로 변환\n",
    "        grad_cam = grad_cam - np.min(grad_cam)  #\n",
    "        grad_cam = grad_cam / np.max(grad_cam)  # 위의 것과 해당 줄의 것은 0~1사이의 값으로 정규화하기 위한 정리\n",
    "        return grad_cam, cam, index, probs, idx,"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
