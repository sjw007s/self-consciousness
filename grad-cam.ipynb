{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_ready\n"
     ]
    }
   ],
   "source": [
    "xs_0=list()\n",
    "xs_0_=list()\n",
    "xs_1=list()\n",
    "ys_0=list()\n",
    "data_number= 20\n",
    "batch_size = 4\n",
    "epochs = 2000\n",
    "#100장정도.. 램 가능\n",
    "with open ('data/Data_narrow.txt', 'rt' ) as r_n:\n",
    "    target_r = r_n.readline()\n",
    "    for j in range(data_number): \n",
    "        #print(data_number)\n",
    "        xs_0=list()\n",
    "        for i in range(20): \n",
    "            temp_red=list()\n",
    "            temp_blue=list()\n",
    "            temp_green=list()\n",
    "            \n",
    "            r=open ('data/'+str(i+20*j)+'_building_r.csv', 'r' )\n",
    "            rdr=csv.reader(r)\n",
    "            for target in rdr:\n",
    "                temp_red.append(target)\n",
    "                \n",
    "            r=open ('data/'+str(i+20*j)+'_building_g.csv', 'r' )\n",
    "            rdr=csv.reader(r)\n",
    "            for target in rdr:\n",
    "                temp_green.append(target)\n",
    "                \n",
    "            r=open ('data/'+str(i+20*j)+'_building_b.csv', 'r' )\n",
    "            rdr=csv.reader(r)\n",
    "            for target in rdr:\n",
    "                temp_blue.append(target)\n",
    "                \n",
    "            temp_red=np.array(temp_red, dtype=np.float32)\n",
    "            temp_greed=np.array(temp_green, dtype=np.float32)\n",
    "            temp_blue=np.array(temp_blue, dtype=np.float32)\n",
    "\n",
    "            xs_1=np.stack((temp_red, temp_green, temp_blue), axis=0)\n",
    "            xs_1=list(xs_1) \n",
    "            xs_0.append(xs_1)\n",
    "            \n",
    "            target_r = r_n.readline()\n",
    "            if i<20:\n",
    "                A_r,B_r,C_r,D_r,E_r,F_r,G_r,H_r,I_r,J_r,K_r=target_r.split(',')  \n",
    "\n",
    "                if i==0:\n",
    "                    pass\n",
    "\n",
    "                else:\n",
    "                    if i==1:\n",
    "                        ys_0.append([float(E_r)])\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        ys_0=ys_0[:-1]+[ys_0[-1]+[float(E_r)]]\n",
    "\n",
    "        xs_0_.append(xs_0)\n",
    "\n",
    "x_train = np.array(xs_0_, dtype=np.float32)\n",
    "y_train = np.array(ys_0, dtype=np.float32)\n",
    "x_train = torch.from_numpy(x_train).cuda()\n",
    "y_train = torch.from_numpy(y_train).cuda()\n",
    "\n",
    "xs_0=list()\n",
    "xs_0_=list()\n",
    "xs_1=list()\n",
    "\"\"\"\n",
    "for j in range(data_number): \n",
    "    xs_0=list()\n",
    "    for i in range(10): \n",
    "        temp_red=list()\n",
    "        temp_blue=list()\n",
    "        temp_green=list()\n",
    "\n",
    "        r=open ('data/'+str(i+10*j)+'_r.csv', 'r' )\n",
    "        rdr=csv.reader(r)\n",
    "        for target in rdr:\n",
    "            temp_red.append(target)\n",
    "\n",
    "        r=open ('data/'+str(i+10*j)+'_g.csv', 'r' )\n",
    "        rdr=csv.reader(r)\n",
    "        for target in rdr:\n",
    "            temp_green.append(target)\n",
    "\n",
    "        r=open ('data/'+str(i+10*j)+'_b.csv', 'r' )\n",
    "        rdr=csv.reader(r)\n",
    "        for target in rdr:\n",
    "            temp_blue.append(target)\n",
    "\n",
    "        temp_red=np.array(temp_red, dtype=np.float32)\n",
    "        temp_greed=np.array(temp_green, dtype=np.float32)\n",
    "        temp_blue=np.array(temp_blue, dtype=np.float32)\n",
    "\n",
    "        xs_1=np.stack((temp_red, temp_green, temp_blue), axis=0)\n",
    "        xs_1=list(xs_1) \n",
    "        xs_0.append(xs_1)\n",
    "    \n",
    "    xs_0_.append(xs_0)\n",
    "        \n",
    "x_test = np.array(xs_0_, dtype=np.float32)\n",
    "x_test = torch.from_numpy(x_test).cuda()\n",
    "\"\"\"\n",
    "#print(x_train.shape,y_train.shape)\n",
    "dataset = TensorDataset(x_train, y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#dataset_test = TensorDataset(x_test, y_train)\n",
    "#dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "#print(x_test.shape)\n",
    "\n",
    "xs_0=list()\n",
    "xs_0_=list()\n",
    "xs_1=list()\n",
    "ys_0=list()\n",
    "temp_red=list()\n",
    "temp_blue=list()\n",
    "temp_green=list()\n",
    "\n",
    "print(\"data_ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "tensor([-0.0226,  0.0257,  0.0002,  0.0287, -0.0086], device='cuda:0')\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "tensor([-0.0197,  0.0058,  0.0136,  0.0231, -0.0162], device='cuda:0')\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "tensor([-0.0157, -0.0003,  0.0145,  0.0172, -0.0152], device='cuda:0')\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "tensor([-0.0227,  0.0036,  0.0172,  0.0241, -0.0193], device='cuda:0')\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "tensor([-0.0110,  0.0091,  0.0019,  0.0114, -0.0049], device='cuda:0')\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "tensor([ 0.0010,  0.0039, -0.0042, -0.0008,  0.0031], device='cuda:0')\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "tensor([ 0.0142,  0.0050, -0.0162, -0.0136,  0.0155], device='cuda:0')\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "tensor([-0.0031,  0.0028,  0.0003,  0.0032, -0.0012], device='cuda:0')\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "tensor([ 0.0088,  0.0185, -0.0237, -0.0090,  0.0190], device='cuda:0')\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "tensor([-0.0073,  0.0040,  0.0029,  0.0077, -0.0044], device='cuda:0')\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "tensor([-0.0149,  0.0032,  0.0102,  0.0157, -0.0119], device='cuda:0')\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "tensor([ 0.0013,  0.0090, -0.0092, -0.0017,  0.0068], device='cuda:0')\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "tensor([ 0.0021, -0.0151,  0.0121, -0.0009, -0.0077], device='cuda:0')\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "tensor([-0.0009,  0.0122, -0.0102,  0.0006,  0.0067], device='cuda:0')\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "tensor([-0.0008, -0.0065,  0.0067,  0.0013, -0.0049], device='cuda:0')\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "tensor([ 0.0062,  0.0045, -0.0094, -0.0066,  0.0085], device='cuda:0')\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "tensor([-0.0069, -0.0012,  0.0070,  0.0074, -0.0071], device='cuda:0')\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "tensor([ 0.0003, -0.0012,  0.0009, -0.0002, -0.0005], device='cuda:0')\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "tensor([ 0.0017, -0.0060,  0.0040, -0.0016, -0.0022], device='cuda:0')\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "tensor([-2.8872e-03,  4.1913e-03, -1.2889e-03,  2.9349e-03, -3.9993e-05],\n",
      "       device='cuda:0')\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "tensor([ 0.0073,  0.0003, -0.0065, -0.0077,  0.0068], device='cuda:0')\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "tensor([-0.0051, -0.0014,  0.0057,  0.0055, -0.0055], device='cuda:0')\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "tensor([-0.0103,  0.0065,  0.0030,  0.0108, -0.0054], device='cuda:0')\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "tensor([-0.0132,  0.0047,  0.0069,  0.0135, -0.0089], device='cuda:0')\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "tensor([ 0.0246, -0.0087, -0.0126, -0.0246,  0.0163], device='cuda:0')\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "tensor([-0.0082,  0.0037,  0.0036,  0.0086, -0.0051], device='cuda:0')\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "tensor([ 0.0110, -0.0006, -0.0088, -0.0116,  0.0096], device='cuda:0')\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "tensor([-0.0148, -0.0054,  0.0178,  0.0164, -0.0170], device='cuda:0')\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "tensor([ 0.0113,  0.0172, -0.0251, -0.0118,  0.0208], device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-c72731c5cc63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Epoch {t+1}\\n-------------------------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m     \u001b[1;31m#test(dataloader_test, model, loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Done!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-c72731c5cc63>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(dataloader, model, loss, optimizer)\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[1;31m#print(min_,max_,result_)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[0mpil_image\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m         \u001b[0mpil_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"_r.csv\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0maa\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m             \u001b[0mwriter_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(self, title, command)\u001b[0m\n\u001b[0;32m   2224\u001b[0m             )\n\u001b[0;32m   2225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2226\u001b[1;33m         \u001b[0m_show\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2228\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36m_show\u001b[1;34m(image, **options)\u001b[0m\n\u001b[0;32m   3189\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_show\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3190\u001b[0m     \u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"_internal_pillow\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3191\u001b[1;33m     \u001b[0m_showxv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36m_showxv\u001b[1;34m(image, title, **options)\u001b[0m\n\u001b[0;32m   3203\u001b[0m             \u001b[0mDeprecationWarning\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3204\u001b[0m         )\n\u001b[1;32m-> 3205\u001b[1;33m     \u001b[0mImageShow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\ImageShow.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(image, title, **options)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \"\"\"\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mviewer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_viewers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mviewer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\ImageShow.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(self, image, **options)\u001b[0m\n\u001b[0;32m     78\u001b[0m                 \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;31m# hook methods\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\ImageShow.py\u001b[0m in \u001b[0;36mshow_image\u001b[1;34m(self, image, **options)\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mshow_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[1;34m\"\"\"Display the given image.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mshow_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\ImageShow.py\u001b[0m in \u001b[0;36mshow_file\u001b[1;34m(self, file, **options)\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mshow_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[1;34m\"\"\"Display the given file.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class LRCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LRCN, self).__init__()\n",
    "        self.layer_1 = nn.Conv2d(3,5,5,stride=1)\n",
    "        self.layer_2 = nn.Conv2d(5,2,5,stride=2)\n",
    "        #self.layer_3 = nn.Conv2d(13,20,7,stride=3)\n",
    "        #self.layer_4 = nn.Conv2d(20,30,5,stride=2)\n",
    "        #self.layer_5 = nn.Conv2d(30,40,5,stride=2)\n",
    "        self.layer_6 = nn.LSTM(8832,100,1, batch_first = True)\n",
    "        self.layer_7 = nn.Linear(100, 1)\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.length = x_train.shape[1]\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.a=0\n",
    "        self.b=0\n",
    "        self.c=0\n",
    "        #self.d=0\n",
    "        #self.e=0\n",
    "        self.count_=0\n",
    "        self.o=0\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.reshape((-1, 3, 100, 200))\n",
    "        x = self.layer_1(x)\n",
    "        self.a = self.relu(x)\n",
    "        x = self.layer_2(self.a)\n",
    "        self.b = self.relu(x)\n",
    "        #x = self.layer_3(self.b)\n",
    "        #self.c = self.relu(x)\n",
    "        #x = self.layer_4(self.c)\n",
    "        #self.d = self.relu(x)\n",
    "        #x = self.layer_5(self.d)\n",
    "        #self.e = self.relu(x)\n",
    "        x = self.b.reshape((self.batch_size, self.length, x.shape[-3],x.shape[-2],x.shape[-1]))\n",
    "        x = x.reshape((self.batch_size, self.length, x.shape[-3]*x.shape[-2]*x.shape[-1]))\n",
    "        self.o, (h_n, c_n) = self.layer_6(x)\n",
    "        #print(x.shape)\n",
    "        \n",
    "        #x = self.relu(h_n[-1,:,:].reshape((self.batch_size,-1)))\n",
    "        x = self.layer_7(self.o[:,1:,:]).reshape((self.batch_size,-1))\n",
    "        #print(x.shape)\n",
    "        #x.retain_grad()\n",
    "        self.count_+=1\n",
    "        #print(\"종우\",x.grad)\n",
    "        return x\n",
    "\n",
    "model = LRCN().cuda()\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)\n",
    "#print(\"서\",model.parameters().shape)\n",
    "      \n",
    "def train(dataloader, model, loss, optimizer):\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        pred = model(X)\n",
    "        \n",
    "        #print(pred.shape,y.shape)\n",
    "        loss_result = loss(pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        model.a.retain_grad()\n",
    "        model.b.retain_grad()\n",
    "        #model.c.retain_grad()\n",
    "        #model.d.retain_grad()\n",
    "        #model.e.retain_grad()\n",
    "        model.o.retain_grad()\n",
    "        #print(model.e.grad)\n",
    "        loss_result.backward()\n",
    "        #print(model.e.requires_grad)\n",
    "        #print(model.e.grad)\n",
    "        #print(model.b.grad)\n",
    "        #print(model.c.grad)\n",
    "        #print(model.d.grad)\n",
    "        #print(model.e.grad)\n",
    "        #print(loss_result.sum())\n",
    "        \n",
    "        \n",
    "        \n",
    "        #print(\"종우\",loss_result.register_hook())\n",
    "    \n",
    "    #print(result_temp.shape, result_temp)\n",
    "    #print(result_temp)\n",
    "    #print(param.shape)\n",
    "    #print(result_temp.shape)\n",
    "    #print(model.)\n",
    "    #print(model.e.grad.shape, result_temp.shape)\n",
    "    if model.count_==5:\n",
    "        temp_sum=0\n",
    "        #print(model.a.grad.shape)\n",
    "        width_ = model.a.grad.shape[-1]\n",
    "        #print(width_)\n",
    "        result_temp = torch.sum(model.a.grad,-1)\n",
    "        #print(result_temp)\n",
    "        height_ = result_temp.shape[-1]\n",
    "        #print(height_)\n",
    "        result_temp = torch.sum(result_temp,-1)\n",
    "        #print(result_temp.shape, result_temp)\n",
    "        #result_temp_=0\n",
    "        #for i in range(model.batch_size):\n",
    "        #    result_temp_ += result_temp[15+i]\n",
    "        result_temp_ = torch.sum(result_temp,0)\n",
    "        result_temp = result_temp_/5\n",
    "        #print(result_temp.shape,model.a.grad.shape)\n",
    "        #print(result_temp.shape, result_temp)\n",
    "        model.count_=0\n",
    "        print(result_temp)\n",
    "        temp_sum=0\n",
    "        for k in range(model.batch_size):  \n",
    "        #for j in range(1):\n",
    "            #print(result_temp.shape[1])\n",
    "            #print(result_temp.shape[1])\n",
    "            #j=10\n",
    "            #for k in range(1): \n",
    "            #temp_sum=0\n",
    "            #print(model.a.grad.shape)\n",
    "            for j in range(result_temp.shape[0]):\n",
    "                k=10\n",
    "                #print(result_temp[k,j].shape, model.a.grad.shape)\n",
    "                #print(model.a.grad[j].shape)\n",
    "                #print(i,j,k)\n",
    "                #print(result_temp[k,j].shape,model.e.grad[k,j,:,:].shape)\n",
    "                temp_sum += result_temp[j]*(model.a.grad[15+k,j,:,:])\n",
    "            #print(result_temp.shape)\n",
    "        result_ = model.relu(temp_sum)\n",
    "        result_ = result_.cpu().numpy()\n",
    "        min_= np.min(result_)\n",
    "        max_ = np.max(result_)\n",
    "        #print(model.o.grad)\n",
    "        #print(model.b.grad)\n",
    "        #print(model.a.grad)\n",
    "        #print(min_,max_,np.sum(result_))\n",
    "        #print(result_)\n",
    "        result_ = ((255*result_)/max_)  #.astype(np.uint8)\n",
    "        min_= np.min(result_)\n",
    "        max_ = np.max(result_)\n",
    "        #print(model.o.grad)\n",
    "        #print(model.b.grad)\n",
    "        #print(model.a.grad)\n",
    "        #print(min_,max_,result_)\n",
    "        pil_image=Image.fromarray(result_)\n",
    "        pil_image.show()\n",
    "        with open(\"data/\"+str(i)+\"_r.csv\",'a',newline='') as aa:\n",
    "            writer_a = csv.writer(aa, delimiter=',')\n",
    "\n",
    "            #print(temp_sum)\n",
    "    #print(temp_sum.shape, temp_sum)\n",
    "    #result_ = model.relu(temp_sum)\n",
    "    #print(result_.shape)\n",
    "    #temp_sum= self.relu(temp_sum)\n",
    "    #result_ = result_.cpu().numpy()\n",
    "    #min_= np.min(result_)\n",
    "    #max_ = np.max(result_)\n",
    "    #print(min_,max_)\n",
    "    #pil_image=Image.fromarray(result_)\n",
    "    #pil_image.show()\n",
    "    #print(result_)\n",
    "    #print(model.e.grad)\n",
    "    \n",
    "        \n",
    "    optimizer.step()\n",
    "            \n",
    "def test(dataloader, model, loss):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss(pred, y).item()\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Test Error: \\n Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(dataloader, model, loss, optimizer)\n",
    "    #test(dataloader_test, model, loss)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class ModelOutputs_resnet():\n",
    "    def __init__(self, model, target_layers, target_sub_layers):\n",
    "        self.model = model\n",
    "        self.target_layers = target_layers\n",
    "        self.target_sub_layers = target_sub_layers\n",
    "        self.gradients = []\n",
    "\n",
    "    def save_gradient(self, grad):\n",
    "        self.gradients.append(grad)\n",
    "\n",
    "    def get_gradients(self):\n",
    "        return self.gradients\n",
    "\n",
    "    def __call__(self, x):\n",
    "        self.gradients = []\n",
    "        for name, module in self.model.named_children(): # 모든 layer에 대해서 직접 접근\n",
    "            x = module(x)\n",
    "            if name== 'avgpool': # avgpool이후 fully connect하기 전 data shape을 flatten시킴\n",
    "                x = torch.flatten(x,1)\n",
    "            if name in self.target_layers: # target_layer라면 해당 layer에서의 gradient를 저장\n",
    "                for sub_name, sub_module in module[len(module)-1].named_children():\n",
    "                    if sub_name in self.target_sub_layers:\n",
    "                        x.register_hook(self.save_gradient) #\n",
    "                        target_feature_maps = x # x's shape = 512X14X14(C,W,H) feature map\n",
    "        return target_feature_maps, x # target_activation : target_activation_layer's feature maps // output : classification ( ImageNet's classes : 1000 )\n",
    "\n",
    "\n",
    "class GradCam_resnet:\n",
    "    def __init__(self, model, target_layer_names,target_sub_layer_names, use_cuda):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.cuda = use_cuda\n",
    "        if self.cuda:  # GPU일 경우 model을 cuda로 설정\n",
    "            self.model = model.cuda()\n",
    "\n",
    "        self.extractor = ModelOutputs_resnet(self.model, target_layer_names,target_sub_layer_names)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "\n",
    "    def __call__(self, input, index=None):\n",
    "\n",
    "        if self.cuda:  # GPU일 경우 input을 cuda로 변환하여 전달\n",
    "            features, output = self.extractor(input.cuda())\n",
    "        else:\n",
    "            features, output = self.extractor(input)\n",
    "\n",
    "        probs,idx = 0, 0\n",
    "        if index == None:\n",
    "            index = np.argmax(output.cpu().data.numpy())  # index = 정답이라고 추측한 class index\n",
    "            h_x = F.softmax(output,dim=1).data.squeeze()\n",
    "            probs, idx = h_x.sort(0,True)\n",
    "\n",
    "\n",
    "        one_hot = np.zeros((1, output.size()[-1]), dtype=np.float32)\n",
    "        one_hot[0][index] = 1  # 정답이라고 생각하는 class의 index 리스트 위치의 값만 1로\n",
    "        one_hot = torch.from_numpy(one_hot).requires_grad_(True)  # numpy배열을 tensor로 변환\n",
    "        # requires_grad == True 텐서의 모든 연산에 대하여 추적\n",
    "        if self.cuda:\n",
    "            one_hot = torch.sum(one_hot.cuda() * output)\n",
    "        else:\n",
    "            one_hot = torch.sum(one_hot * output)\n",
    "\n",
    "        self.model.zero_grad()\n",
    "        one_hot.backward(retain_graph=True)\n",
    "\n",
    "        grads_val = self.extractor.get_gradients()[-1].cpu().data.numpy()\n",
    "\n",
    "        target = features  # A^k\n",
    "\n",
    "        target_cam = target.cpu().data.numpy()\n",
    "        bz, nc, h,w = target_cam.shape\n",
    "\n",
    "        target = target.cpu().data.numpy()[0, :]\n",
    "\n",
    "        params = list(self.model.parameters())\n",
    "\n",
    "        weight_softmax = np.squeeze(params[-2].data.cpu().numpy())\n",
    "\n",
    "        cam = weight_softmax[index].dot(target_cam.reshape((nc,h*w)))\n",
    "        cam = cam.reshape(h,w)\n",
    "        cam = np.maximum(cam, 0)\n",
    "        cam = cv2.resize(cam, (224, 224))  # 224X224크기로 변환\n",
    "        cam = cam - np.min(cam)\n",
    "        cam = cam / np.max(cam)\n",
    "\n",
    "\n",
    "        weights = np.mean(grads_val, axis=(2, 3))[0, :]  # 논문에서의 global average pooling 식에 해당하는 부분\n",
    "        grad_cam = np.zeros(target.shape[1:], dtype=np.float32)  # 14X14\n",
    "\n",
    "        for i, w in enumerate(weights): # calcul grad_cam\n",
    "            grad_cam += w * target[i, :, :]  # linear combination L^c_{Grad-CAM}에 해당하는 식에서 ReLU를 제외한 식\n",
    "\n",
    "        grad_cam = np.maximum(grad_cam, 0)  # 0보다 작은 값을 제거\n",
    "        grad_cam = cv2.resize(grad_cam, (224, 224))  # 224X224크기로 변환\n",
    "        grad_cam = grad_cam - np.min(grad_cam)  #\n",
    "        grad_cam = grad_cam / np.max(grad_cam)  # 위의 것과 해당 줄의 것은 0~1사이의 값으로 정규화하기 위한 정리\n",
    "        return grad_cam, cam ,index,probs,idx ,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class FeatureExtractor_vgg():\n",
    "    \"\"\" Class for extracting activations and\n",
    "    registering gradients from targetted intermediate layers \"\"\"\n",
    "\n",
    "    def __init__(self, model, target_layers): # target_layers = 35 ==> VGG19에서 가장 마지막 MaxPool2D전 ReLU함수\n",
    "        self.model = model\n",
    "        self.target_layers = target_layers\n",
    "        self.gradients = []\n",
    "\n",
    "    def save_gradient(self, grad):\n",
    "        self.gradients.append(grad)\n",
    "\n",
    "\n",
    "    def __call__(self, x):\n",
    "        self.gradients = []\n",
    "        for name, module in self.model._modules.items(): # 모든 layer에 대해서 직접 접근\n",
    "            x = module(x)\n",
    "            if name in self.target_layers: # target_layer라면 해당 layer에서의 gradient를 저장\n",
    "                x.register_hook(self.save_gradient) #\n",
    "                target_feature_maps = x # x's shape = 512X14X14(C,W,H) feature map\n",
    "        return target_feature_maps, x\n",
    "\n",
    "\n",
    "class ModelOutputs_vgg():\n",
    "    \"\"\" Class for making a forward pass, and getting:\n",
    "    1. The network output.\n",
    "    2. Activations from intermeddiate targetted layers.\n",
    "    3. Gradients from intermeddiate targetted layers. \"\"\"\n",
    "\n",
    "    def __init__(self, model, target_layers):\n",
    "        self.model = model\n",
    "        self.feature_extractor = FeatureExtractor_vgg(self.model.features, target_layers)\n",
    "\n",
    "    def get_gradients(self):\n",
    "        return self.feature_extractor.gradients\n",
    "\n",
    "    def __call__(self, x):\n",
    "        target_activations, output = self.feature_extractor(x)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        output = self.model.classifier(output) # feature extract를 통해서 나온 값을 활용하여 classification 진행\n",
    "        #print(\"ModelOutputs().output.shape : \",output[0])\n",
    "        #print(\"ModelOutputs().target_activations.shape :\",target_activations[0])\n",
    "        return target_activations, output\n",
    "\n",
    "class GradCam_vgg:\n",
    "    def __init__(self, model, target_layer_names, use_cuda):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.cuda = use_cuda\n",
    "        if self.cuda: # GPU일 경우 model을 cuda로 설정\n",
    "            self.model = model.cuda()\n",
    "\n",
    "        self.extractor = ModelOutputs_vgg(self.model, target_layer_names)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "\n",
    "    def __call__(self, input, index=None):\n",
    "        if self.cuda: # GPU일 경우 input을 cuda로 변환하여 전달\n",
    "            features, output = self.extractor(input.cuda())\n",
    "        else:\n",
    "            features, output = self.extractor(input)\n",
    "        #print(\"features : \",features.cpu().data.numpy().shape) # 해당 위치에서 추출된 feature map ( 512,14,14 ) (ChannelX14X14)\n",
    "        #print(\"output : \",output.cpu().data.numpy().shape) # class를 의미함\n",
    "        probs, idx = 0,0\n",
    "        #print(\"index : \", index)\n",
    "        if index == None:\n",
    "            index = np.argmax(output.cpu().data.numpy())  # index = 정답이라고 추측한 class index\n",
    "            h_x = F.softmax(output,dim=1).data.squeeze()\n",
    "            probs, idx = h_x.sort(0,True)\n",
    "        #print(\"index : \", index)\n",
    "        one_hot = np.zeros((1, output.size()[-1]), dtype=np.float32)\n",
    "        one_hot[0][index] = 1 # 정답이라고 생각하는 class의 index 리스트 위치의 값만 1로\n",
    "        one_hot = torch.from_numpy(one_hot).requires_grad_(True) # numpy배열을 tensor로 변환\n",
    "        # requires_grad == True 텐서의 모든 연산에 대하여 추적\n",
    "        if self.cuda:\n",
    "            one_hot = torch.sum(one_hot.cuda() * output)\n",
    "        else:\n",
    "            one_hot = torch.sum(one_hot * output)\n",
    "\n",
    "        self.model.features.zero_grad()\n",
    "        self.model.classifier.zero_grad()\n",
    "        one_hot.backward(retain_graph=True)\n",
    "\n",
    "        grads_val = self.extractor.get_gradients()[-1].cpu().data.numpy()\n",
    "        #print(\"grads_val : \",grads_val.shape) # 512 X 14 X 14\n",
    "        target = features  # A^k\n",
    "        target = target.cpu().data.numpy()[0, :]\n",
    "\n",
    "        cam = None\n",
    "\n",
    "        weights = np.mean(grads_val, axis=(2, 3))[0, :]  # 논문에서의 global average pooling 식에 해당하는 부분\n",
    "        grad_cam = np.zeros(target.shape[1:], dtype=np.float32)  # 14X14\n",
    "\n",
    "        for i, w in enumerate(weights):  # calcul grad_cam\n",
    "            grad_cam += w * target[i, :, :]  # linear combination L^c_{Grad-CAM}에 해당하는 식에서 ReLU를 제외한 식\n",
    "\n",
    "        grad_cam = np.maximum(grad_cam, 0)  # 0보다 작은 값을 제거\n",
    "        grad_cam = cv2.resize(grad_cam, (224, 224))  # 224X224크기로 변환\n",
    "        grad_cam = grad_cam - np.min(grad_cam)  #\n",
    "        grad_cam = grad_cam / np.max(grad_cam)  # 위의 것과 해당 줄의 것은 0~1사이의 값으로 정규화하기 위한 정리\n",
    "        return grad_cam, cam, index, probs, idx,"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
