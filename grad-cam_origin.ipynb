{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Device: cuda\n",
      "Current cuda device: 0\n",
      "Count of using GPUs: 2\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "from PIL import Image\n",
    "import time\n",
    "import cv2 as cv\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print('Device:', device)\n",
    "print('Current cuda device:', torch.cuda.current_device())\n",
    "print('Count of using GPUs:', torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "torch.cuda.set_device(1)\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "data_ready\n"
     ]
    }
   ],
   "source": [
    "xs_0=list()\n",
    "xs_0_=list()\n",
    "xs_1=list()\n",
    "ys_0=list()\n",
    "data_number= 20\n",
    "batch_size = 4\n",
    "epochs = 20000\n",
    "#100장정도.. 램 가능\n",
    "with open ('data/Data_narrow.txt', 'rt' ) as r_n:\n",
    "    target_r = r_n.readline()\n",
    "    for j in range(data_number): \n",
    "        print(j)\n",
    "        xs_0=list()\n",
    "        for i in range(20): \n",
    "            temp_red=list()\n",
    "            temp_blue=list()\n",
    "            temp_green=list()\n",
    "            \n",
    "            r=open ('data/'+str(i+20*j)+'_r.csv', 'r' )\n",
    "            rdr=csv.reader(r)\n",
    "            for target in rdr:\n",
    "                temp_red.append(target)\n",
    "                \n",
    "            r=open ('data/'+str(i+20*j)+'_g.csv', 'r' )\n",
    "            rdr=csv.reader(r)\n",
    "            for target in rdr:\n",
    "                temp_green.append(target)\n",
    "                \n",
    "            r=open ('data/'+str(i+20*j)+'_b.csv', 'r' )\n",
    "            rdr=csv.reader(r)\n",
    "            for target in rdr:\n",
    "                temp_blue.append(target)\n",
    "                \n",
    "            temp_red=np.array(temp_red, dtype=np.float32)\n",
    "            temp_greed=np.array(temp_green, dtype=np.float32)\n",
    "            temp_blue=np.array(temp_blue, dtype=np.float32)\n",
    "\n",
    "            xs_1=np.stack((temp_red, temp_green, temp_blue), axis=0)\n",
    "            xs_1=list(xs_1) \n",
    "            xs_0.append(xs_1)\n",
    "            \n",
    "            target_r = r_n.readline()\n",
    "            if i<20:\n",
    "                A_r,B_r,C_r,D_r,E_r,F_r,G_r,H_r,I_r,J_r,K_r=target_r.split(',')  \n",
    "\n",
    "                if i==0:\n",
    "                    pass\n",
    "\n",
    "                else:\n",
    "                    if i==1:\n",
    "                        ys_0.append([float(E_r)])\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        ys_0=ys_0[:-1]+[ys_0[-1]+[float(E_r)]]\n",
    "\n",
    "        xs_0_.append(xs_0)\n",
    "\n",
    "x_train = np.array(xs_0_, dtype=np.float32)\n",
    "y_train = np.array(ys_0, dtype=np.float32)\n",
    "x_train = torch.from_numpy(x_train).cuda()\n",
    "y_train = torch.from_numpy(y_train).cuda()\n",
    "\n",
    "xs_0=list()\n",
    "xs_0_=list()\n",
    "xs_1=list()\n",
    "\"\"\"\n",
    "for j in range(data_number): \n",
    "    xs_0=list()\n",
    "    for i in range(10): \n",
    "        temp_red=list()\n",
    "        temp_blue=list()\n",
    "        temp_green=list()\n",
    "\n",
    "        r=open ('data/'+str(i+10*j)+'_r.csv', 'r' )\n",
    "        rdr=csv.reader(r)\n",
    "        for target in rdr:\n",
    "            temp_red.append(target)\n",
    "\n",
    "        r=open ('data/'+str(i+10*j)+'_g.csv', 'r' )\n",
    "        rdr=csv.reader(r)\n",
    "        for target in rdr:\n",
    "            temp_green.append(target)\n",
    "\n",
    "        r=open ('data/'+str(i+10*j)+'_b.csv', 'r' )\n",
    "        rdr=csv.reader(r)\n",
    "        for target in rdr:\n",
    "            temp_blue.append(target)\n",
    "\n",
    "        temp_red=np.array(temp_red, dtype=np.float32)\n",
    "        temp_greed=np.array(temp_green, dtype=np.float32)\n",
    "        temp_blue=np.array(temp_blue, dtype=np.float32)\n",
    "\n",
    "        xs_1=np.stack((temp_red, temp_green, temp_blue), axis=0)\n",
    "        xs_1=list(xs_1) \n",
    "        xs_0.append(xs_1)\n",
    "    \n",
    "    xs_0_.append(xs_0)\n",
    "        \n",
    "x_test = np.array(xs_0_, dtype=np.float32)\n",
    "x_test = torch.from_numpy(x_test).cuda()\n",
    "\"\"\"\n",
    "#print(x_train.shape,y_train.shape)\n",
    "dataset = TensorDataset(x_train, y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#dataset_test = TensorDataset(x_test, y_train)\n",
    "#dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "#print(x_test.shape)\n",
    "\n",
    "xs_0=list()\n",
    "xs_0_=list()\n",
    "xs_1=list()\n",
    "ys_0=list()\n",
    "temp_red=list()\n",
    "temp_blue=list()\n",
    "temp_green=list()\n",
    "\n",
    "print(\"data_ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "tensor(12.6150, device='cuda:1', grad_fn=<MseLossBackward0>)\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "tensor(15.0436, device='cuda:1', grad_fn=<MseLossBackward0>)\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "tensor(13.0629, device='cuda:1', grad_fn=<MseLossBackward0>)\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "tensor(13.7532, device='cuda:1', grad_fn=<MseLossBackward0>)\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "tensor(11.2109, device='cuda:1', grad_fn=<MseLossBackward0>)\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "Epoch 104\n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-ce22f26d6e99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Epoch {t+1}\\n-------------------------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m     \u001b[1;31m#test(dataloader_test, model, loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Done!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-ce22f26d6e99>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(dataloader, model, loss, optimizer)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtemp_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;31m#print(pred.shape,y.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-ce22f26d6e99>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;31m#x = self.relu(h_n[-1,:,:].reshape((self.batch_size,-1)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_7\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;31m#print(x.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;31m#x.retain_grad()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1846\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class LRCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LRCN, self).__init__()\n",
    "        self.layer_1 = nn.Conv2d(3,10,5,stride=1)\n",
    "        self.layer_2 = nn.Conv2d(10,10,5,stride=2)\n",
    "        self.layer_3 = nn.Conv2d(10,10,5,stride=2)\n",
    "        self.layer_4 = nn.Conv2d(10,10,5,stride=2)\n",
    "        self.layer_5 = nn.Conv2d(10,5,5,stride=2)\n",
    "        self.layer_6 = nn.LSTM(135,50,1, batch_first = True)\n",
    "        self.layer_7 = nn.Linear(50, 1)\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.length = x_train.shape[1]\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.a=0\n",
    "        self.b=0\n",
    "        self.c=0\n",
    "        self.d=0\n",
    "        self.e=0\n",
    "        self.count_=0\n",
    "        self.o=0\n",
    "        self.temp_data=0\n",
    "        self.temp_result=0\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.reshape((-1, 3, 100, 200))\n",
    "        x = self.layer_1(x)\n",
    "        self.a = self.relu(x)\n",
    "        x = self.layer_2(self.a)\n",
    "        self.b = self.relu(x)\n",
    "        x = self.layer_3(self.b)\n",
    "        self.c = self.relu(x)\n",
    "        x = self.layer_4(self.c)\n",
    "        self.d = self.relu(x)\n",
    "        x = self.layer_5(self.d)\n",
    "        self.e = self.relu(x)\n",
    "        x = self.e.reshape((self.batch_size, self.length, x.shape[-3],x.shape[-2],x.shape[-1]))\n",
    "        x = x.reshape((self.batch_size, self.length, x.shape[-3]*x.shape[-2]*x.shape[-1]))\n",
    "        self.o, (h_n, c_n) = self.layer_6(x)\n",
    "        #print(x.shape)\n",
    "        \n",
    "        #x = self.relu(h_n[-1,:,:].reshape((self.batch_size,-1)))\n",
    "        x = self.layer_7(self.o[:,1:,:]).reshape((self.batch_size,-1))\n",
    "        #print(x.shape)\n",
    "        #x.retain_grad()\n",
    "        self.count_+=1\n",
    "        #print(\"종우\",x.grad)\n",
    "        return x\n",
    "\n",
    "model = LRCN().cuda()\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)\n",
    "#print(\"서\",model.parameters().shape)\n",
    "      \n",
    "def train(dataloader, model, loss, optimizer):\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        pred = model(X)\n",
    "        model.temp_data = X[0]\n",
    "        #print(pred.shape,y.shape)\n",
    "        loss_result = loss(pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        model.temp_result=loss_result\n",
    "        model.a.retain_grad()\n",
    "        model.b.retain_grad()\n",
    "        model.c.retain_grad()\n",
    "        model.d.retain_grad()\n",
    "        model.e.retain_grad()\n",
    "        model.o.retain_grad()\n",
    "        #print(model.e.grad)\n",
    "        loss_result.backward()\n",
    "        #print(model.e.requires_grad)\n",
    "        #print(model.e.grad)\n",
    "        #print(model.b.grad)\n",
    "        #print(model.c.grad)\n",
    "        #print(model.d.grad)\n",
    "        #print(model.e.grad)\n",
    "        #print(loss_result.sum())\n",
    "        \n",
    "        \n",
    "        \n",
    "        #print(\"종우\",loss_result.register_hook())\n",
    "    \n",
    "    #print(result_temp.shape, result_temp)\n",
    "    #print(result_temp)\n",
    "    #print(param.shape)\n",
    "    #print(result_temp.shape)\n",
    "    #print(model.)\n",
    "    #print(model.e.grad.shape, result_temp.shape)\n",
    "    if model.count_==100:\n",
    "        temp_sum=0\n",
    "        width_ = model.a.grad.shape[-1]\n",
    "        result_temp = torch.sum(model.a.grad.detach(),-1)\n",
    "        height_ = result_temp.shape[-1]\n",
    "        result_temp = torch.sum(result_temp,-1)\n",
    "        result_temp_ = torch.sum(result_temp,0)\n",
    "        result_temp = result_temp_/10\n",
    "        model.count_=0\n",
    "        temp_sum=0\n",
    "        for k in range(1):  \n",
    "            for j in range(result_temp.shape[0]):\n",
    "                k=10\n",
    "                temp_grad = model.a.grad.detach().reshape((model.batch_size, model.length, 10, model.a.grad.shape[-2],model.a.grad.shape[-1]))\n",
    "                temp_sum += result_temp[j]*(temp_grad[0,k,j,:,:])\n",
    "            result_ = model.relu(temp_sum.detach()).cpu().numpy()\n",
    "            min_= np.min(result_)\n",
    "            result_=result_-min_\n",
    "            max_ = np.max(result_)\n",
    "            result_ = ((255*result_)/max_).astype(np.uint8)\n",
    "            min_= np.min(result_)\n",
    "            max_ = np.max(result_)\n",
    "            pil_image=Image.fromarray(result_)\n",
    "            pil_name=str(k)+str(j)+\".png\"\n",
    "            pil_image.save(\"name.png\")\n",
    "    \n",
    "        temp_sum=0\n",
    "        width_ = model.c.grad.shape[-1]\n",
    "        result_temp = torch.sum(model.c.grad.detach(),-1)\n",
    "        height_ = result_temp.shape[-1]\n",
    "        result_temp = torch.sum(result_temp,-1)\n",
    "        result_temp_ = torch.sum(result_temp,0)\n",
    "        result_temp = result_temp_/10\n",
    "        model.count_=0\n",
    "        temp_sum=0\n",
    "        for k in range(1):  \n",
    "            for j in range(result_temp.shape[0]):\n",
    "                k=10\n",
    "                temp_grad = model.c.grad.detach().reshape((model.batch_size, model.length, 10, model.c.grad.shape[-2],model.c.grad.shape[-1]))\n",
    "                temp_sum += result_temp[j]*(temp_grad[0,k,j,:,:])\n",
    "            result_ = model.relu(temp_sum.detach()).cpu().numpy()\n",
    "            min_= np.min(result_)\n",
    "            result_=result_-min_\n",
    "            max_ = np.max(result_)\n",
    "            result_ = ((255*result_)/max_).astype(np.uint8)\n",
    "            min_= np.min(result_)\n",
    "            max_ = np.max(result_)\n",
    "            pil_image=Image.fromarray(result_)\n",
    "            pil_name=str(k)+str(j)+\".png\"\n",
    "            pil_image.save(\"name_middle.png\")\n",
    "        \n",
    "        temp_sum=0\n",
    "        width_ = model.e.grad.shape[-1]\n",
    "        result_temp = torch.sum(model.e.grad.detach(),-1)\n",
    "        height_ = result_temp.shape[-1]\n",
    "        result_temp = torch.sum(result_temp,-1)\n",
    "        result_temp_ = torch.sum(result_temp,0)\n",
    "        result_temp = result_temp_/5\n",
    "        model.count_=0\n",
    "        temp_sum=0\n",
    "        for k in range(1):  \n",
    "            for j in range(result_temp.shape[0]):\n",
    "                k=10\n",
    "                temp_grad = model.e.grad.detach().reshape((model.batch_size, model.length, 5, model.e.grad.shape[-2],model.e.grad.shape[-1]))\n",
    "                temp_sum += result_temp[j]*(temp_grad[0,k,j,:,:])\n",
    "            result_ = model.relu(temp_sum.detach()).cpu().numpy()\n",
    "            min_= np.min(result_)\n",
    "            result_=result_-min_\n",
    "            max_ = np.max(result_)\n",
    "            result_ = ((255*result_)/max_).astype(np.uint8)\n",
    "            #min_= np.min(result_)\n",
    "            #max_ = np.max(result_)\n",
    "            #result_ = np.concatenate((result_,np.model.temp_data)\n",
    "            pil_image=Image.fromarray(result_)\n",
    "            pil_image=pil_image.resize((200,100))\n",
    "            pil_image_origin=model.temp_data.detach().cpu().numpy().astype(np.uint8)[10].squeeze()\n",
    "            #print(pil_image_origin.transpose((1,2,0)).shape)\n",
    "            #print(pil_image_origin.shape)\n",
    "           # print(pil_image_origin.shape)\n",
    "            \n",
    "            pil_image=np.array(pil_image)[:,:, np.newaxis]\n",
    "            pil_image_origin=Image.fromarray(pil_image_origin.transpose((1,2,0)))\n",
    "            pil_image_new = np.concatenate((pil_image_origin,pil_image),axis=2)\n",
    "            pil_image=Image.fromarray(pil_image.squeeze())\n",
    "            #print(pil_image_new.shape)\n",
    "            pil_name=str(k)+str(j)+\".png\"\n",
    "            #pil_image=pil_image.resize((200,100))\n",
    "            pil_image.save(\"name_last.png\")\n",
    "            pil_image_origin.save(\"name_last_origin.png\")\n",
    "            \n",
    "            #conca=np.hstack((pil_image, pil_image_origin))\n",
    "            #print(conca.shape)\n",
    "            pil_image_new=Image.fromarray(pil_image_new)\n",
    "            pil_image_new.save(\"name_last_new.png\")\n",
    "            print(model.temp_result)\n",
    "            #time.sleep(0.001)\n",
    "        \n",
    "    optimizer.step()\n",
    "            \n",
    "def test(dataloader, model, loss):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss(pred, y).item()\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Test Error: \\n Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(dataloader, model, loss, optimizer)\n",
    "    #test(dataloader_test, model, loss)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
