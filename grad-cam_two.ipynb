{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "from PIL import Image\n",
    "import time\n",
    "import cv2 as cv\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print('Device:', device)\n",
    "print('Current cuda device:', torch.cuda.current_device())\n",
    "print('Count of using GPUs:', torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "torch.cuda.set_device(1)\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xs_0=list()\n",
    "xs_0_=list()\n",
    "xs_1=list()\n",
    "ys_0=list()\n",
    "data_number= 1\n",
    "batch_size = 1\n",
    "epochs = 20000\n",
    "#100장정도.. 램 가능\n",
    "with open ('data/Data_narrow.txt', 'rt' ) as r_n:\n",
    "    target_r = r_n.readline()\n",
    "    for j in range(data_number): \n",
    "        print(j)\n",
    "        xs_0=list()\n",
    "        for i in range(2): \n",
    "            temp_red=list()\n",
    "            temp_blue=list()\n",
    "            temp_green=list()\n",
    "            \n",
    "            r=open ('data/'+str(i+20*j)+'_building_r.csv', 'r' )\n",
    "            rdr=csv.reader(r)\n",
    "            for target in rdr:\n",
    "                temp_red.append(target)\n",
    "                \n",
    "            r=open ('data/'+str(i+20*j)+'_building_g.csv', 'r' )\n",
    "            rdr=csv.reader(r)\n",
    "            for target in rdr:\n",
    "                temp_green.append(target)\n",
    "                \n",
    "            r=open ('data/'+str(i+20*j)+'_building_b.csv', 'r' )\n",
    "            rdr=csv.reader(r)\n",
    "            for target in rdr:\n",
    "                temp_blue.append(target)\n",
    "                \n",
    "            temp_red=np.array(temp_red, dtype=np.float32)\n",
    "            temp_greed=np.array(temp_green, dtype=np.float32)\n",
    "            temp_blue=np.array(temp_blue, dtype=np.float32)\n",
    "\n",
    "            xs_1=np.stack((temp_red, temp_green, temp_blue), axis=0)\n",
    "            xs_1=list(xs_1) \n",
    "            xs_0.append(xs_1)\n",
    "            \n",
    "            target_r = r_n.readline()\n",
    "            if i<20:\n",
    "                A_r,B_r,C_r,D_r,E_r,F_r,G_r,H_r,I_r,J_r,K_r=target_r.split(',')  \n",
    "\n",
    "                if i==0:\n",
    "                    pass\n",
    "\n",
    "                else:\n",
    "                    if i==1:\n",
    "                        ys_0.append([float(E_r)])\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        ys_0=ys_0[:-1]+[ys_0[-1]+[float(E_r)]]\n",
    "\n",
    "        xs_0_.append(xs_0)\n",
    "\n",
    "x_train = np.array(xs_0_, dtype=np.float32)\n",
    "y_train = np.array(ys_0, dtype=np.float32)\n",
    "x_train = torch.from_numpy(x_train).cuda()\n",
    "y_train = torch.from_numpy(y_train).cuda()\n",
    "\n",
    "xs_0=list()\n",
    "xs_0_=list()\n",
    "xs_1=list()\n",
    "\"\"\"\n",
    "for j in range(data_number): \n",
    "    xs_0=list()\n",
    "    for i in range(10): \n",
    "        temp_red=list()\n",
    "        temp_blue=list()\n",
    "        temp_green=list()\n",
    "\n",
    "        r=open ('data/'+str(i+10*j)+'_r.csv', 'r' )\n",
    "        rdr=csv.reader(r)\n",
    "        for target in rdr:\n",
    "            temp_red.append(target)\n",
    "\n",
    "        r=open ('data/'+str(i+10*j)+'_g.csv', 'r' )\n",
    "        rdr=csv.reader(r)\n",
    "        for target in rdr:\n",
    "            temp_green.append(target)\n",
    "\n",
    "        r=open ('data/'+str(i+10*j)+'_b.csv', 'r' )\n",
    "        rdr=csv.reader(r)\n",
    "        for target in rdr:\n",
    "            temp_blue.append(target)\n",
    "\n",
    "        temp_red=np.array(temp_red, dtype=np.float32)\n",
    "        temp_greed=np.array(temp_green, dtype=np.float32)\n",
    "        temp_blue=np.array(temp_blue, dtype=np.float32)\n",
    "\n",
    "        xs_1=np.stack((temp_red, temp_green, temp_blue), axis=0)\n",
    "        xs_1=list(xs_1) \n",
    "        xs_0.append(xs_1)\n",
    "    \n",
    "    xs_0_.append(xs_0)\n",
    "        \n",
    "x_test = np.array(xs_0_, dtype=np.float32)\n",
    "x_test = torch.from_numpy(x_test).cuda()\n",
    "\"\"\"\n",
    "print(x_train.shape,y_train.shape)\n",
    "dataset = TensorDataset(x_train, y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#dataset_test = TensorDataset(x_test, y_train)\n",
    "#dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "#print(x_test.shape)\n",
    "\n",
    "xs_0=list()\n",
    "xs_0_=list()\n",
    "xs_1=list()\n",
    "ys_0=list()\n",
    "temp_red=list()\n",
    "temp_blue=list()\n",
    "temp_green=list()\n",
    "\n",
    "print(\"data_ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class LRCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LRCN, self).__init__()\n",
    "        self.layer_1 = nn.Conv2d(3,2,5,stride=1)\n",
    "        self.layer_2 = nn.Conv2d(3,2,5,stride=1)\n",
    "        #self.layer_3 = nn.Conv2d(10,10,5,stride=2)\n",
    "        #self.layer_4 = nn.Conv2d(10,10,5,stride=2)\n",
    "        #self.layer_5 = nn.Conv2d(10,5,5,stride=2)\n",
    "        #self.layer_6 = nn.LSTM(135,50,1, batch_first = True)\n",
    "        self.layer_7 = nn.Linear(75264, 1)\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.length = x_train.shape[1]\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.a=0\n",
    "        self.b=0\n",
    "        self.c=0\n",
    "        self.d=0\n",
    "        self.e=0\n",
    "        self.count_=0\n",
    "        self.o=0\n",
    "        self.temp_data=0\n",
    "        self.temp_result=0\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x = x.reshape((-1, 3, 100, 200))\n",
    "        x_1 = self.layer_1(x[:,0,:,:,:])\n",
    "        self.a = self.relu(x_1)\n",
    "        x_2 = self.layer_2(x[:,1,:,:,:])\n",
    "        self.b = self.relu(x_2)\n",
    "        #print(self.a.shape)\n",
    "        \n",
    "        self.c = torch.cat((self.a.reshape((self.batch_size, -1)),self.b.reshape((self.batch_size, -1))),axis=1)\n",
    "        #print(x_3.shape,x_2.shape)\n",
    "        #reshape((self.batch_size, self.length, x.shape[-3]*x.shape[-2]*x.shape[-1]))\n",
    "        x= self.layer_7(self.c)\n",
    "        #print(x.shape)\n",
    "        \n",
    "        #x = self.relu(h_n[-1,:,:].reshape((self.batch_size,-1)))\n",
    "        #x = self.layer_7(self.o[:,1:,:]).reshape((self.batch_size,-1))\n",
    "        #print(x.shape)\n",
    "        #x.retain_grad()\n",
    "        self.count_+=1\n",
    "        #print(\"종우\",x.grad)\n",
    "        return x\n",
    "\n",
    "model = LRCN().cuda()\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
    "#print(\"서\",model.parameters().shape)\n",
    "      \n",
    "def train(dataloader, model, loss, optimizer):\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        pred = model(X)\n",
    "        model.temp_data = X[0]\n",
    "        print(pred,y)\n",
    "        loss_result = loss(pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        model.temp_result=loss_result\n",
    "        model.a.retain_grad()\n",
    "        model.b.retain_grad()\n",
    "        model.c.retain_grad()\n",
    "        #model.d.retain_grad()\n",
    "        #model.e.retain_grad()\n",
    "        #model.o.retain_grad()\n",
    "        #print(model.e.grad)\n",
    "        loss_result.backward()\n",
    "        #print(model.e.requires_grad)\n",
    "        #print(model.e.grad)\n",
    "        #print(model.b.grad)\n",
    "        #print(model.c.grad)\n",
    "        #print(model.d.grad)\n",
    "        #print(model.e.grad)\n",
    "        #print(loss_result.sum())\n",
    "        \n",
    "        \n",
    "        \n",
    "        #print(\"종우\",loss_result.register_hook())\n",
    "    \n",
    "    #print(result_temp.shape, result_temp)\n",
    "    #print(result_temp)\n",
    "    #print(param.shape)\n",
    "    #print(result_temp.shape)\n",
    "    #print(model.)\n",
    "    #print(model.e.grad.shape, result_temp.shape)\n",
    "    if model.count_==100:\n",
    "        temp_sum=0\n",
    "        #print(model.a.grad.shape)\n",
    "        width_ = model.a.grad.shape[-1]\n",
    "        result_temp = torch.sum(model.a.grad.detach(),-1)\n",
    "        height_ = result_temp.shape[-1]\n",
    "        result_temp = torch.sum(result_temp,-1)\n",
    "        result_temp_ = torch.sum(result_temp,0)\n",
    "        result_temp = result_temp_/2\n",
    "        model.count_=0\n",
    "        temp_sum=0\n",
    "        print(result_temp.shape)\n",
    "        for k in range(1):  \n",
    "            for j in range(result_temp.shape[0]):\n",
    "                k=0\n",
    "                temp_grad = model.a.grad.detach().reshape((model.batch_size, 2, model.a.grad.shape[-2],model.a.grad.shape[-1]))\n",
    "                temp_sum += result_temp[j]*(temp_grad[0,j,:,:])\n",
    "            result_ = temp_sum.detach().cpu().numpy()\n",
    "            min_= np.min(result_)\n",
    "            result_=result_-min_\n",
    "            max_ = np.max(result_)\n",
    "            result_ = ((255*result_)/max_).astype(np.uint8)\n",
    "            \n",
    "            pil_image=Image.fromarray(result_)\n",
    "            #pil_name=str(k)+str(j)+\".png\"\n",
    "            result_=pil_image.resize((200,100))\n",
    "            pil_image.save(\"name.png\")\n",
    "    \n",
    "        temp_sum=0\n",
    "        width_ = model.b.grad.shape[-1]\n",
    "        result_temp = torch.sum(model.b.grad.detach(),-1)\n",
    "        height_ = result_temp.shape[-1]\n",
    "        result_temp = torch.sum(result_temp,-1)\n",
    "        result_temp_ = torch.sum(result_temp,0)\n",
    "        result_temp = result_temp_/2\n",
    "        model.count_=0\n",
    "        temp_sum=0\n",
    "        for k in range(1):  \n",
    "            for j in range(result_temp.shape[0]):\n",
    "                k=1\n",
    "                temp_grad = model.b.grad.detach().reshape((model.batch_size, 2, model.b.grad.shape[-2],model.b.grad.shape[-1]))\n",
    "                temp_sum += result_temp[j]*(temp_grad[0,j,:,:])\n",
    "            result_ = temp_sum.detach().cpu().numpy()\n",
    "            min_= np.min(result_)\n",
    "            result_=result_-min_\n",
    "            max_ = np.max(result_)\n",
    "            result_ = ((255*result_)/max_).astype(np.uint8)\n",
    "            \n",
    "            pil_image=Image.fromarray(result_)\n",
    "            #pil_name=str(k)+str(j)+\".png\"\n",
    "            result_=pil_image.resize((200,100))\n",
    "            pil_image.save(\"name_middle.png\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        #time.sleep(0.001)\n",
    "        \n",
    "    optimizer.step()\n",
    "            \n",
    "def test(dataloader, model, loss):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss(pred, y).item()\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Test Error: \\n Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(dataloader, model, loss, optimizer)\n",
    "    #test(dataloader_test, model, loss)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
