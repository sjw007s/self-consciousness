{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9b5c8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Device: cuda\n",
      "Current cuda device: 0\n",
      "Count of using GPUs: 2\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "from PIL import Image\n",
    "import time\n",
    "import cv2 as cv\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print('Device:', device)\n",
    "print('Current cuda device:', torch.cuda.current_device())\n",
    "print('Count of using GPUs:', torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "#torch.cuda.set_device(1)\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ad1b947",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "data_ready\n"
     ]
    }
   ],
   "source": [
    "xs_0=list()\n",
    "xs_0_=list()\n",
    "xs_1=list()\n",
    "ys_0=list()\n",
    "data_number= 200\n",
    "batch_size = 20\n",
    "epochs = 3000\n",
    "#100장정도.. 램 가능\n",
    "with open ('data/Data_narrow.txt', 'rt' ) as r_n:\n",
    "    target_r = r_n.readline()\n",
    "    for j in range(data_number): \n",
    "        print(j)\n",
    "        xs_0=list()\n",
    "        for i in range(20): \n",
    "            temp_red=list()\n",
    "            temp_blue=list()\n",
    "            temp_green=list()\n",
    "            \n",
    "            r=open ('data/'+str(i+20*j)+'_building_r.csv', 'r' )\n",
    "            rdr=csv.reader(r)\n",
    "            for target in rdr:\n",
    "                temp_red.append(target)\n",
    "                \n",
    "            r=open ('data/'+str(i+20*j)+'_building_g.csv', 'r' )\n",
    "            rdr=csv.reader(r)\n",
    "            for target in rdr:\n",
    "                temp_green.append(target)\n",
    "                \n",
    "            r=open ('data/'+str(i+20*j)+'_building_b.csv', 'r' )\n",
    "            rdr=csv.reader(r)\n",
    "            for target in rdr:\n",
    "                temp_blue.append(target)\n",
    "                \n",
    "            temp_red=np.array(temp_red, dtype=np.float64)\n",
    "            temp_greed=np.array(temp_green, dtype=np.float64)\n",
    "            temp_blue=np.array(temp_blue, dtype=np.float64)\n",
    "\n",
    "            xs_1=np.stack((temp_red, temp_green, temp_blue), axis=0)\n",
    "            xs_1=list(xs_1) \n",
    "            xs_0.append(xs_1)\n",
    "            \n",
    "            target_r = r_n.readline()\n",
    "            if i<20:\n",
    "                A_r,B_r,C_r,D_r,E_r,F_r,G_r,H_r,I_r,J_r,K_r=target_r.split(',')  \n",
    "\n",
    "                if i==0:\n",
    "                    pass\n",
    "\n",
    "                else:\n",
    "                    if i==1:\n",
    "                        ys_0.append([float(E_r)])\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        ys_0=ys_0[:-1]+[ys_0[-1]+[float(E_r)]]\n",
    "\n",
    "        xs_0_.append(xs_0)\n",
    "\n",
    "x_train_ = np.array(xs_0_, dtype=np.float64)\n",
    "y_train_ = np.array(ys_0, dtype=np.float64)\n",
    "#y_train = np.zeros_like(y_train)\n",
    "\n",
    "y_train = torch.from_numpy(y_train_[:100]).cuda()\n",
    "y_test_1 = torch.from_numpy(y_train_[100:]).cuda()\n",
    "x_test_1= torch.from_numpy(x_train_[100:]).cuda()\n",
    "#print(y_train)\n",
    "xs_0=list()\n",
    "xs_0_=list()\n",
    "xs_1=list()\n",
    "\n",
    "for j in range(data_number): \n",
    "    xs_0=list()\n",
    "    for i in range(20): \n",
    "        temp_red=list()\n",
    "        temp_blue=list()\n",
    "        temp_green=list()\n",
    "\n",
    "        r=open ('data/'+str(i+20*j)+'_r.csv', 'r' )\n",
    "        rdr=csv.reader(r)\n",
    "        for target in rdr:\n",
    "            temp_red.append(target)\n",
    "\n",
    "        r=open ('data/'+str(i+20*j)+'_g.csv', 'r' )\n",
    "        rdr=csv.reader(r)\n",
    "        for target in rdr:\n",
    "            temp_green.append(target)\n",
    "\n",
    "        r=open ('data/'+str(i+20*j)+'_b.csv', 'r' )\n",
    "        rdr=csv.reader(r)\n",
    "        for target in rdr:\n",
    "            temp_blue.append(target)\n",
    "\n",
    "        temp_red=np.array(temp_red, dtype=np.float64)\n",
    "        temp_greed=np.array(temp_green, dtype=np.float64)\n",
    "        temp_blue=np.array(temp_blue, dtype=np.float64)\n",
    "\n",
    "        xs_1=np.stack((temp_red, temp_green, temp_blue), axis=0)\n",
    "        xs_1=list(xs_1) \n",
    "        xs_0.append(xs_1)\n",
    "    \n",
    "    xs_0_.append(xs_0)\n",
    "        \n",
    "x_test_ = np.array(xs_0_, dtype=np.float64)\n",
    "x_test = torch.from_numpy(x_test_[:100]).cuda()\n",
    "x_train = torch.from_numpy(x_test_[100:]).cuda()\n",
    "\n",
    "#print(x_train.shape,y_train.shape)\n",
    "dataset = TensorDataset(x_test, y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "#print(x_test_1.shape,y_train[100:].shape)\n",
    "dataset_test_1 = TensorDataset(x_train, y_test_1)\n",
    "dataloader_test_1 = DataLoader(dataset_test_1, batch_size=batch_size, shuffle=True)\n",
    "#print(x_test.shape)\n",
    "#print(x_test.shape,y_train.shape)\n",
    "dataset_test = TensorDataset(x_test_1, y_test_1)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "xs_0=list()\n",
    "xs_0_=list()\n",
    "xs_1=list()\n",
    "ys_0=list()\n",
    "temp_red=list()\n",
    "temp_blue=list()\n",
    "temp_green=list()\n",
    "\n",
    "print(\"data_ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "198c0c0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "train_loss tensor(77.1272, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(79.5315, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(79.6412, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "train_loss tensor(76.3613, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(78.7405, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(78.9254, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "train_loss tensor(75.5433, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(77.8342, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(78.2558, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "train_loss tensor(74.6201, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(76.8229, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(77.4018, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "train_loss tensor(73.6561, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(75.8225, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(76.4635, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "train_loss tensor(72.6788, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(74.8227, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(75.0824, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "train_loss tensor(71.6340, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(73.6707, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(74.4467, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "train_loss tensor(70.4935, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(72.5721, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(72.8653, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "train_loss tensor(69.4133, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(71.4811, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(71.9559, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "train_loss tensor(68.4706, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(70.6361, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(71.0582, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "train_loss tensor(67.6291, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(69.8711, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(70.1212, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "train_loss tensor(66.8581, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(69.0574, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(69.2711, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "train_loss tensor(66.0855, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(68.2844, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(68.4635, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "train_loss tensor(65.3685, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(67.5264, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(67.7041, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "train_loss tensor(64.6149, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(66.7449, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(66.9013, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "train_loss tensor(63.8138, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(65.9193, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(66.1024, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "train_loss tensor(63.0142, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(65.1383, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(65.2503, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "train_loss tensor(62.2279, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(64.2696, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(64.4044, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "train_loss tensor(61.3805, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(63.4234, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(63.5600, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "train_loss tensor(60.5499, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(62.5886, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(62.6995, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "train_loss tensor(59.7462, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(61.7792, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(61.8387, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "train_loss tensor(58.9529, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(60.9902, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(61.0290, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "train_loss tensor(58.2015, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(60.2421, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(60.2533, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "train_loss tensor(57.4601, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(59.4934, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(59.5277, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "train_loss tensor(56.7546, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(58.7947, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(58.8035, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "train_loss tensor(56.0595, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(58.0521, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(58.0817, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "train_loss tensor(55.3160, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss tensor(57.2896, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(57.3379, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "train_loss tensor(54.5851, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(56.5756, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(56.6195, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "train_loss tensor(53.9134, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(55.9119, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(55.9537, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "train_loss tensor(53.2790, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(55.2911, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(55.3245, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "train_loss tensor(52.6870, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(54.6939, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(54.7180, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "train_loss tensor(52.1127, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(54.1248, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(54.1401, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "train_loss tensor(51.5715, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(53.5773, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(53.5888, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "train_loss tensor(51.0431, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(53.0517, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(53.0605, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "train_loss tensor(50.5390, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(52.5417, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(52.5482, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "train_loss tensor(50.0471, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(52.0475, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(52.0536, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "train_loss tensor(49.5694, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(51.5679, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(51.5742, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "train_loss tensor(49.1072, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(51.1005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(51.1057, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "train_loss tensor(48.6580, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(50.6450, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(50.6495, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "train_loss tensor(48.2193, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(50.2008, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(50.2058, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "train_loss tensor(47.7888, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(49.7675, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(49.7719, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "train_loss tensor(47.3746, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(49.3426, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(49.3465, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "train_loss tensor(46.9614, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(48.9291, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(48.9329, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "train_loss tensor(46.5607, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(48.5247, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(48.5284, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "train_loss tensor(46.1716, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(48.1278, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(48.1310, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "train_loss tensor(45.7894, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(47.7389, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(47.7421, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "train_loss tensor(45.4140, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(47.3586, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(47.3617, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "train_loss tensor(45.0471, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(46.9866, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(46.9893, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "train_loss tensor(44.6851, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(46.6231, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(46.6258, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "train_loss tensor(44.3347, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(46.2656, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(46.2680, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "train_loss tensor(43.9924, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(45.9134, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(45.9155, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "train_loss tensor(43.6510, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(45.5689, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(45.5706, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "train_loss tensor(43.3202, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(45.2297, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(45.2307, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "train_loss tensor(42.9918, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(44.8968, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(44.8974, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "train_loss tensor(42.6692, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(44.5687, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(44.5684, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "train_loss tensor(42.3515, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(44.2406, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(44.2410, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "train_loss tensor(42.0295, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(43.9104, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(43.9141, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "train_loss tensor(41.7109, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(43.5832, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(43.5883, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "train_loss tensor(41.3976, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(43.2714, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(43.2750, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "train_loss tensor(41.0980, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(42.9666, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(42.9701, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "train_loss tensor(40.8046, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(42.6671, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(42.6709, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "train_loss tensor(40.5168, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(42.3730, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(42.3769, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "train_loss tensor(40.2331, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(42.0854, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(42.0889, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "train_loss tensor(39.9556, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(41.8032, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(41.8067, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "train_loss tensor(39.6839, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(41.5258, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(41.5294, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "train_loss tensor(39.4178, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(41.2525, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(41.2567, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "train_loss tensor(39.1529, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(40.9850, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(40.9905, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "train_loss tensor(38.8962, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(40.7205, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(40.7259, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "train_loss tensor(38.6410, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(40.4601, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(40.4664, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "train_loss tensor(38.3884, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(40.2037, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(40.2112, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "train_loss tensor(38.1438, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(39.9484, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(39.9577, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "train_loss tensor(37.8958, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(39.6970, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(39.7100, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "train_loss tensor(37.6539, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(39.4479, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(39.4657, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "train_loss tensor(37.4127, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(39.2008, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(39.2198, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "train_loss tensor(37.1759, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(38.9568, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(38.9762, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "train_loss tensor(36.9382, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(38.7196, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(38.7321, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "train_loss tensor(36.7125, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(38.4840, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(38.4924, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "train_loss tensor(36.4861, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(38.2526, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(38.2584, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "train_loss tensor(36.2636, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(38.0251, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(38.0294, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 80\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(36.0425, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(37.8020, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(37.8055, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "train_loss tensor(35.8311, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(37.5804, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(37.5833, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "train_loss tensor(35.6169, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(37.3629, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(37.3651, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "train_loss tensor(35.4077, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(37.1486, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(37.1506, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "train_loss tensor(35.2018, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(36.9373, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(36.9392, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "train_loss tensor(34.9980, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(36.7295, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(36.7316, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "train_loss tensor(34.7991, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(36.5239, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(36.5252, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "train_loss tensor(34.5993, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(36.3225, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(36.3242, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "train_loss tensor(34.4051, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(36.1232, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(36.1245, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "train_loss tensor(34.2103, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(35.9299, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(35.9274, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "train_loss tensor(34.0227, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(35.7358, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(35.7317, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "train_loss tensor(33.8323, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(35.5395, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(35.5399, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "train_loss tensor(33.6469, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(35.3501, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(35.3507, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "train_loss tensor(33.4631, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(35.1649, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(35.1674, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "train_loss tensor(33.2854, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(34.9831, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(34.9799, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "train_loss tensor(33.1067, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(34.7951, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(34.7982, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "train_loss tensor(32.9299, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(34.6210, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(34.7012, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "train_loss tensor(32.7544, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(34.4348, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(34.4442, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "train_loss tensor(32.5811, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(34.2610, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(34.2744, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "train_loss tensor(32.4103, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(34.0890, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(34.0853, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "train_loss tensor(32.2447, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(33.9149, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(33.9129, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "train_loss tensor(32.0775, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(33.7460, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(33.7401, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "train_loss tensor(31.9112, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(33.5760, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(33.5710, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "train_loss tensor(31.7479, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(33.4094, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(33.4447, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "train_loss tensor(31.5875, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(33.2421, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(33.2467, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "train_loss tensor(31.4311, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(33.0815, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(33.0800, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "train_loss tensor(31.2723, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss tensor(32.9199, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(32.9169, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "train_loss tensor(31.1127, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(32.7571, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(32.7554, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "train_loss tensor(30.9586, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(32.5986, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(32.5950, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "train_loss tensor(30.8061, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(32.4377, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(32.4381, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "train_loss tensor(30.6515, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(32.2830, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(32.2785, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "train_loss tensor(30.4999, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(32.1293, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(32.1226, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "train_loss tensor(30.3474, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(31.9702, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(31.9696, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "train_loss tensor(30.2015, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(31.8167, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(31.8146, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "train_loss tensor(30.0515, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(31.6705, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(31.6618, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "train_loss tensor(29.9036, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(31.5156, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(31.5111, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "train_loss tensor(29.7578, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(31.3641, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(31.3632, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "train_loss tensor(29.6148, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(31.2175, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(31.2144, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "train_loss tensor(29.4699, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(31.0736, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(31.0678, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "train_loss tensor(29.3288, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(30.9286, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(30.9237, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "train_loss tensor(29.1886, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(30.7844, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(30.7807, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "train_loss tensor(29.0526, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(30.6412, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(30.6404, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "train_loss tensor(28.9155, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(30.5035, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(30.4986, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "train_loss tensor(28.7774, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(30.3645, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(30.3617, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "train_loss tensor(28.6443, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(30.2248, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(30.2236, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "train_loss tensor(28.5057, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(30.0895, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(30.0864, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "train_loss tensor(28.3745, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(29.9507, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(29.9506, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "train_loss tensor(28.2410, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(29.8169, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(29.8175, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "train_loss tensor(28.1103, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(29.6842, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(29.6855, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "train_loss tensor(27.9799, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(29.5534, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(29.5528, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "train_loss tensor(27.8635, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(29.4183, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(29.4268, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "train_loss tensor(27.7329, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(29.2942, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(29.2907, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "train_loss tensor(27.6059, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(29.1614, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(29.1658, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "train_loss tensor(27.4787, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(29.0413, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(29.0349, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "train_loss tensor(27.3526, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(28.9111, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(28.9100, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "train_loss tensor(27.2299, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(28.7934, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(28.7846, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "train_loss tensor(27.1076, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(28.6589, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(28.6595, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "train_loss tensor(26.9901, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(28.5378, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(28.5341, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "train_loss tensor(26.8746, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(28.4129, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(28.4138, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "train_loss tensor(26.7531, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(28.2942, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(28.2890, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "train_loss tensor(26.6297, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(28.1739, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(28.1706, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "train_loss tensor(26.5120, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(28.0499, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(28.0640, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "train_loss tensor(26.3936, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(27.9335, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(27.9586, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "train_loss tensor(26.2767, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(27.8162, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(27.8342, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "train_loss tensor(26.1598, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(27.6968, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(27.7728, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "train_loss tensor(26.0429, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(27.6664, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(27.7658, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "train_loss tensor(25.9365, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(27.4580, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(27.4967, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "train_loss tensor(25.8269, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(27.3519, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(27.3453, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "train_loss tensor(25.7099, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(27.2305, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(27.2314, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "train_loss tensor(25.5988, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(27.1252, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(27.1174, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "train_loss tensor(25.4956, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(27.0024, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(27.0063, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "train_loss tensor(25.3794, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(26.8963, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(26.8908, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "train_loss tensor(25.2636, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(26.7814, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(26.7789, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "train_loss tensor(25.1560, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(26.6683, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(26.6678, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "train_loss tensor(25.0452, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(26.5615, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(26.5556, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "train_loss tensor(24.9421, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(26.4445, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(26.4481, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "train_loss tensor(24.8306, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(26.3478, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(26.3371, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "train_loss tensor(24.7284, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(26.2257, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(26.2291, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "train_loss tensor(24.6201, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(26.1277, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(26.1190, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 159\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(24.5102, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(26.0112, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(26.0124, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "train_loss tensor(24.4074, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(25.9132, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(25.9049, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "train_loss tensor(24.3051, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(25.8011, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(25.7990, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "train_loss tensor(24.1986, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(25.7080, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(25.6979, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "train_loss tensor(24.0957, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(25.5917, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(25.5946, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "train_loss tensor(23.9965, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(25.4936, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(25.4855, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "train_loss tensor(23.8926, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(25.3893, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(25.3935, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "train_loss tensor(23.7909, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(25.2837, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(25.2970, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "train_loss tensor(23.6926, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(25.1875, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(25.1817, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "train_loss tensor(23.5930, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(25.0773, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(25.0928, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "train_loss tensor(23.4961, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(24.9826, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(24.9759, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "train_loss tensor(23.3972, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(24.8817, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(24.8865, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "train_loss tensor(23.3001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(24.7914, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(24.8086, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "train_loss tensor(23.2019, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(24.6837, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(24.6994, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "train_loss tensor(23.1023, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(24.5848, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(24.5988, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "train_loss tensor(23.0083, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(24.4872, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(24.5088, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "train_loss tensor(22.9146, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(24.3904, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(24.4252, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "train_loss tensor(22.8179, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(24.3016, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(24.3480, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "train_loss tensor(22.7301, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(24.1895, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(24.2445, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "train_loss tensor(22.6276, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(24.1109, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(24.1752, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "train_loss tensor(22.5331, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(24.0073, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(24.1116, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "train_loss tensor(22.4476, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(23.9183, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(24.0163, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "train_loss tensor(22.3471, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(23.8174, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(23.8770, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "train_loss tensor(22.2597, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(23.7295, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(23.8030, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "train_loss tensor(22.1662, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(23.6316, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(23.7097, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "train_loss tensor(22.0723, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(23.5457, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(23.6088, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "train_loss tensor(21.9799, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss tensor(23.4486, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(23.5223, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "train_loss tensor(21.8971, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(23.3725, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(23.4113, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "train_loss tensor(21.8083, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(23.2666, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(23.3022, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "train_loss tensor(21.7152, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(23.1833, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(23.2249, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "train_loss tensor(21.6265, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(23.0996, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(23.1416, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "train_loss tensor(21.5377, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(23.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(23.0592, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "train_loss tensor(21.4505, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(22.9126, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(22.9720, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "train_loss tensor(21.3628, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(22.8209, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(22.8875, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "train_loss tensor(21.2752, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(22.7378, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(22.8095, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "train_loss tensor(21.1967, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(22.6615, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(22.6797, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "train_loss tensor(21.1088, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(22.5564, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(22.5608, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "train_loss tensor(21.0287, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(22.4801, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(22.4794, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "train_loss tensor(20.9450, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(22.4037, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(22.4138, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "train_loss tensor(20.8518, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(22.2846, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(22.2902, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "train_loss tensor(20.7794, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(22.2215, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(22.2148, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "train_loss tensor(20.7112, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(22.1208, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(22.1226, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "train_loss tensor(20.5983, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(22.0491, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(22.0669, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "train_loss tensor(20.5232, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(21.9620, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(21.9682, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "train_loss tensor(20.4442, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(21.8769, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(21.8784, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "train_loss tensor(20.3552, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(21.7999, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(21.8093, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "train_loss tensor(20.2833, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(21.7139, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(21.7234, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "train_loss tensor(20.2044, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(21.6429, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(21.6475, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "train_loss tensor(20.1143, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(21.5347, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(21.5521, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "train_loss tensor(20.0428, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(21.4848, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(21.4851, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "train_loss tensor(19.9673, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(21.3829, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(21.3933, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "train_loss tensor(19.8879, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(21.3114, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(21.3271, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "train_loss tensor(19.7997, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(21.2293, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(21.2253, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "train_loss tensor(19.7264, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(21.1475, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(21.1421, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "train_loss tensor(19.6469, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(21.0826, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(21.0915, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "train_loss tensor(19.5744, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(20.9911, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(21.0140, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "train_loss tensor(19.5056, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(20.9451, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(20.9361, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "train_loss tensor(19.4234, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(20.8318, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(20.8661, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "train_loss tensor(19.3496, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(20.7881, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(20.8158, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "train_loss tensor(19.2696, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(20.7030, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(20.7035, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "train_loss tensor(19.1890, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(20.6038, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(20.6117, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "train_loss tensor(19.1228, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(20.5637, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(20.5650, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "train_loss tensor(19.0475, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(20.4804, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(20.5002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "train_loss tensor(18.9820, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(20.3864, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(20.4034, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "train_loss tensor(18.9062, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(20.3400, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(20.3369, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "train_loss tensor(18.8381, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(20.2341, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(20.3013, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "train_loss tensor(18.7617, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(20.1763, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(20.1771, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "train_loss tensor(18.7019, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(20.1183, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(20.1625, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "train_loss tensor(18.6225, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(20.0176, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(20.0927, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "train_loss tensor(18.5486, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(19.9616, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(19.9776, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "train_loss tensor(18.4732, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(19.8906, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(19.8955, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "train_loss tensor(18.4060, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(19.8149, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(19.8835, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "train_loss tensor(18.3338, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(19.7446, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(19.7348, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "train_loss tensor(18.2665, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(19.6851, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(19.6779, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "train_loss tensor(18.2151, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(19.6031, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(19.5981, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "train_loss tensor(18.1332, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(19.5550, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(19.5855, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "train_loss tensor(18.0631, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(19.4749, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(19.5065, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "train_loss tensor(18.0000, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(19.4227, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(19.4464, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "train_loss tensor(17.9306, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(19.3242, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(19.3436, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 238\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(17.8558, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(19.2719, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(19.3070, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "train_loss tensor(17.7949, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(19.1908, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(19.2444, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "train_loss tensor(17.7272, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(19.1260, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(19.1560, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "train_loss tensor(17.6652, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(19.0726, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(19.1030, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "train_loss tensor(17.5971, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(18.9972, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(19.0781, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "train_loss tensor(17.5288, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(18.9272, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(19.0075, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "train_loss tensor(17.4667, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(18.8736, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(18.9205, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "train_loss tensor(17.4066, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(18.8265, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(18.8880, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "train_loss tensor(17.3395, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(18.7353, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(18.8008, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "train_loss tensor(17.2745, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(18.6717, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(18.6885, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "train_loss tensor(17.2335, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(18.6219, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(18.6785, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "train_loss tensor(17.1631, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(18.5596, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(18.6486, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "train_loss tensor(17.1106, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(18.4808, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(18.5689, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "train_loss tensor(17.0320, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(18.3987, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(18.4284, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "train_loss tensor(16.9690, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(18.3597, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(18.4292, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "train_loss tensor(16.9132, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(18.2905, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(18.3733, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "train_loss tensor(16.8529, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(18.2290, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(18.2976, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "train_loss tensor(16.7821, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(18.1829, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(18.1956, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "train_loss tensor(16.7224, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(18.1112, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(18.0995, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "train_loss tensor(16.6577, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(18.0317, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(18.0165, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "train_loss tensor(16.6043, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(18.0119, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(18.0016, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "train_loss tensor(16.5692, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(17.9600, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(18.0518, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "train_loss tensor(16.4855, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(17.8563, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(17.8722, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "train_loss tensor(16.4255, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(17.8275, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(17.8929, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "train_loss tensor(16.3745, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(17.7567, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(17.8344, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "train_loss tensor(16.3097, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(17.7000, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(17.7945, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "train_loss tensor(16.2703, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss tensor(17.6298, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(17.6812, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "train_loss tensor(16.2011, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(17.5920, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(17.6303, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "train_loss tensor(16.1395, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(17.4992, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(17.5143, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "train_loss tensor(16.0778, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(17.4597, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(17.4618, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "train_loss tensor(16.0303, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(17.3891, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(17.3893, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "train_loss tensor(15.9678, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(17.3426, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(17.3795, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "train_loss tensor(15.9173, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(17.2928, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(17.3401, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "train_loss tensor(15.8641, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(17.2245, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(17.2320, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "train_loss tensor(15.8006, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(17.1905, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(17.1985, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "train_loss tensor(15.7406, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(17.1015, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(17.1118, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "train_loss tensor(15.6869, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(17.0457, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(17.0553, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "train_loss tensor(15.6395, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(17.0014, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(17.0380, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "train_loss tensor(15.5779, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(16.9549, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(17.0154, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "train_loss tensor(15.5241, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(16.8709, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(16.8839, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "train_loss tensor(15.4671, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(16.8289, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(16.8317, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "train_loss tensor(15.4163, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(16.7694, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(16.7731, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "train_loss tensor(15.3671, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(16.6996, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(16.6997, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "train_loss tensor(15.3136, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(16.6771, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(16.6838, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "train_loss tensor(15.2544, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(16.5936, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(16.5959, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "train_loss tensor(15.2220, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(16.5520, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(16.5849, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "train_loss tensor(15.1625, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(16.4804, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(16.4911, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "train_loss tensor(15.1045, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(16.4928, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(16.4968, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "train_loss tensor(15.0678, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(16.3803, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(16.3953, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "train_loss tensor(14.9900, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(16.3428, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(16.3630, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "train_loss tensor(14.9460, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(16.2690, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(16.2843, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "train_loss tensor(14.8916, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(16.2461, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(16.2774, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "train_loss tensor(14.8477, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(16.1799, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(16.2033, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "train_loss tensor(14.7921, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(16.1225, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(16.1578, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "train_loss tensor(14.7373, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(16.0555, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(16.0716, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "train_loss tensor(14.6817, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(16.0149, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(16.0269, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "train_loss tensor(14.6526, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(16.0012, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(16.0437, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "train_loss tensor(14.5835, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(15.8933, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(15.9290, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "train_loss tensor(14.5395, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(15.8766, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(15.9385, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "train_loss tensor(14.4839, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(15.8018, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(15.8298, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "train_loss tensor(14.4465, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(15.8237, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(15.8360, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "train_loss tensor(14.4073, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(15.6812, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(15.7298, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "train_loss tensor(14.3555, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(15.6748, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(15.7127, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "train_loss tensor(14.2853, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(15.5961, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(15.6244, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "train_loss tensor(14.2475, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(15.5578, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(15.6363, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "train_loss tensor(14.2045, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(15.4921, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(15.5493, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "train_loss tensor(14.1376, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(15.4723, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(15.5057, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "train_loss tensor(14.0885, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(15.3788, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(15.4188, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "train_loss tensor(14.0448, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(15.3263, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(15.3672, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "train_loss tensor(13.9905, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(15.3001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(15.3432, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "train_loss tensor(13.9623, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(15.2508, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(15.3497, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "train_loss tensor(13.9072, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(15.1659, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(15.2151, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "train_loss tensor(13.8528, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(15.1593, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(15.1914, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "train_loss tensor(13.7949, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(15.0735, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(15.1139, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "train_loss tensor(13.7427, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(15.0692, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(15.0866, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "train_loss tensor(13.7001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(14.9898, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(15.0303, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "train_loss tensor(13.7006, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(14.9603, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(15.0308, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "train_loss tensor(13.6525, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(14.8905, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(14.9573, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "train_loss tensor(13.6046, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(14.8381, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(14.9285, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 317\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(13.5034, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(14.7558, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(14.8013, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "train_loss tensor(13.4839, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(14.7437, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(14.7484, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "train_loss tensor(13.4379, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(14.7685, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(14.8081, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "train_loss tensor(13.3697, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(14.5726, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(14.6173, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "train_loss tensor(13.3214, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(14.5972, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(14.6650, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "train_loss tensor(13.2507, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(14.5273, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(14.5796, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "train_loss tensor(13.2092, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(14.4549, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(14.5422, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "train_loss tensor(13.1646, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(14.3973, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(14.4968, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "train_loss tensor(13.1270, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(14.4301, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(14.5256, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "train_loss tensor(13.0763, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(14.3140, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(14.3759, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "train_loss tensor(13.0147, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(14.2718, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(14.3777, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "train_loss tensor(12.9685, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(14.1944, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(14.3114, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "train_loss tensor(12.9135, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(14.1675, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(14.2882, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "train_loss tensor(12.8585, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(14.1492, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(14.2610, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "train_loss tensor(12.8087, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(14.0574, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(14.1496, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "train_loss tensor(12.7646, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(14.0006, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(14.0815, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "train_loss tensor(12.7128, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(14.0167, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(14.0918, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "train_loss tensor(12.6863, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(13.8901, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(13.9770, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "train_loss tensor(12.6335, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(13.8926, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(13.9781, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "train_loss tensor(12.5797, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(13.8223, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(13.9058, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "train_loss tensor(12.5363, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(13.7997, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(13.8877, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "train_loss tensor(12.4810, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(13.7272, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(13.8170, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "train_loss tensor(12.4380, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(13.6633, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(13.7539, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "train_loss tensor(12.3959, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(13.6438, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(13.7276, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "train_loss tensor(12.3848, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(13.6165, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(13.7007, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "train_loss tensor(12.3247, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(13.5698, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(13.6645, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "train_loss tensor(12.2792, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss tensor(13.5004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(13.6028, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "train_loss tensor(12.2389, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(13.4468, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(13.5599, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "train_loss tensor(12.1799, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(13.3936, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(13.5149, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "train_loss tensor(12.1441, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(13.3628, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(13.4785, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "train_loss tensor(12.0854, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(13.3640, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(13.4795, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "train_loss tensor(12.0479, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(13.2556, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(13.3926, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "train_loss tensor(11.9958, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(13.2439, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(13.3560, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "train_loss tensor(11.9589, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(13.1958, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(13.3174, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "train_loss tensor(11.9111, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(13.1921, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(13.3223, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "train_loss tensor(11.8887, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(13.0690, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(13.2245, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "train_loss tensor(11.8367, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(13.0602, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(13.2046, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "train_loss tensor(11.7927, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(13.0553, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(13.1720, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "train_loss tensor(11.7390, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(12.9388, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(13.1177, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "train_loss tensor(11.7002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(12.9756, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(13.1074, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "train_loss tensor(11.6670, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(12.8959, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(13.0641, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "train_loss tensor(11.6237, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(12.8387, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(13.0106, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "train_loss tensor(11.5813, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(12.7964, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(12.9752, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "train_loss tensor(11.5501, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(12.7818, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(12.9374, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "train_loss tensor(11.4881, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(12.7012, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(12.8872, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "train_loss tensor(11.4614, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(12.6875, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(12.8782, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "train_loss tensor(11.4423, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(12.6772, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(12.8359, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "train_loss tensor(11.3655, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(12.5658, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(12.7937, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "train_loss tensor(11.3356, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(12.6062, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(12.7699, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "train_loss tensor(11.3000, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(12.5238, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(12.7416, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "train_loss tensor(11.2426, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(12.4671, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(12.6867, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "train_loss tensor(11.2034, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(12.4322, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(12.6563, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "train_loss tensor(11.1632, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(12.3993, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(12.6291, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "train_loss tensor(11.1206, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(12.3509, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(12.5810, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "train_loss tensor(11.0843, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(12.3187, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(12.5556, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "train_loss tensor(11.0550, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(12.2833, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(12.5463, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "train_loss tensor(11.0091, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(12.2255, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(12.5187, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "train_loss tensor(10.9883, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(12.2561, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(12.5004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "train_loss tensor(10.9609, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(12.1830, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(12.4694, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "train_loss tensor(10.9214, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(12.1900, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(12.4759, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "train_loss tensor(11.1262, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(12.0515, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(12.4052, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "train_loss tensor(11.0997, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(12.2712, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(12.3445, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "train_loss tensor(11.2544, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(12.4455, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(12.2930, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "train_loss tensor(11.2502, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(12.2250, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(12.3117, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "train_loss tensor(11.1793, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(12.1409, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(12.2743, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "train_loss tensor(11.0953, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(12.0699, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(12.0859, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "train_loss tensor(11.0278, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(12.0320, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(11.9986, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "train_loss tensor(10.9824, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(11.9841, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(11.9725, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "train_loss tensor(10.9480, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(11.9352, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(11.9340, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "train_loss tensor(10.9070, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(11.8969, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(11.9016, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "train_loss tensor(10.8610, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(11.8673, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(11.8950, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "train_loss tensor(10.8197, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(11.8241, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(11.9203, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "train_loss tensor(10.7796, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(11.7818, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(11.9379, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "train_loss tensor(10.7270, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(11.7515, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(11.8930, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "train_loss tensor(10.6958, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(11.7354, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(11.7501, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "train_loss tensor(10.6145, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(11.7091, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(11.7007, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "train_loss tensor(10.5706, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(11.6320, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(11.7235, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "train_loss tensor(10.5437, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(11.5935, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(11.6491, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "train_loss tensor(10.4974, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(11.5651, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(11.6375, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 396\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(10.4914, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(11.5337, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(11.5794, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "train_loss tensor(10.4305, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(11.5142, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(11.5929, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "train_loss tensor(10.3977, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(11.4607, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(11.6813, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "train_loss tensor(10.3563, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(11.4756, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(11.4999, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "train_loss tensor(10.3080, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(11.3736, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(11.5606, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "train_loss tensor(10.2721, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(11.3418, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(11.4640, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "train_loss tensor(10.2329, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(11.2892, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(11.4857, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "train_loss tensor(10.1823, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(11.2706, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(11.4120, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "train_loss tensor(10.1382, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(11.2298, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(11.4201, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "train_loss tensor(10.1017, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(11.2111, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(11.3130, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "train_loss tensor(10.0680, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(11.1671, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(11.4417, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "train_loss tensor(10.0281, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(11.1360, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(11.4161, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "train_loss tensor(9.9759, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(11.0948, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(11.4057, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "train_loss tensor(9.9394, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(11.0746, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(11.3448, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "train_loss tensor(9.9010, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(11.0439, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(11.3421, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "train_loss tensor(9.8815, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(10.9868, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(11.3795, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "train_loss tensor(9.8612, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(11.0122, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(11.2631, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "train_loss tensor(9.8096, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(10.9426, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(11.2684, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "train_loss tensor(9.7558, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(10.9115, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(11.2230, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "train_loss tensor(9.7222, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(10.8962, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(11.2116, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "train_loss tensor(9.6876, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(10.8266, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(11.2115, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "train_loss tensor(9.6583, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(10.8186, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(11.1981, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "train_loss tensor(9.6190, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(10.7734, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(11.1582, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "train_loss tensor(9.5931, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(10.7569, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(11.0962, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "train_loss tensor(9.5623, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(10.7372, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(11.1428, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "train_loss tensor(9.5511, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(10.7025, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.9694, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "train_loss tensor(9.5207, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss tensor(10.6702, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.9685, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "train_loss tensor(9.4699, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(10.6392, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.9119, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "train_loss tensor(9.4358, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(10.6028, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.9024, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "train_loss tensor(9.4086, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(10.5846, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.8753, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "train_loss tensor(9.3829, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(10.5448, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.9200, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "train_loss tensor(9.3548, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(10.5461, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.8074, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "train_loss tensor(9.3570, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(10.5258, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.8297, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "train_loss tensor(9.3217, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(10.4634, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.7659, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "train_loss tensor(9.2940, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(10.4387, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.8049, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "train_loss tensor(9.2643, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(10.4514, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.7917, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "train_loss tensor(9.2395, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(10.3579, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.7855, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "train_loss tensor(9.1952, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(10.3552, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.6705, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "train_loss tensor(9.1712, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(10.3515, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.6164, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "train_loss tensor(9.1537, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(10.2880, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.7500, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "train_loss tensor(9.1365, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(10.3221, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.5297, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "train_loss tensor(9.1292, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(10.2852, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.6974, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "train_loss tensor(9.1017, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(10.2858, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.4676, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "train_loss tensor(9.0843, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(10.2367, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.5610, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "train_loss tensor(9.0138, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(10.1873, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.5384, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "train_loss tensor(8.9782, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(10.1420, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.5804, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "train_loss tensor(8.9465, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(10.1129, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.5132, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "train_loss tensor(8.9187, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(10.0764, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.5443, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "train_loss tensor(8.9042, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(10.0594, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.4878, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "train_loss tensor(8.8670, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(10.0609, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.4459, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "train_loss tensor(8.8511, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(10.0083, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.4488, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "train_loss tensor(8.8177, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.9630, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.4507, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "train_loss tensor(8.7898, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.9674, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(10.3637, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "train_loss tensor(8.7625, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.9247, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.3611, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "train_loss tensor(8.7298, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.9076, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.3121, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "train_loss tensor(8.7144, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.8821, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.2798, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "train_loss tensor(8.6907, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.8566, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.3050, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "train_loss tensor(8.6999, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.8712, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.1963, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "train_loss tensor(8.6928, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.8850, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.2194, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "train_loss tensor(8.6476, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.7792, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.2806, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "train_loss tensor(8.6306, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.7954, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.2464, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "train_loss tensor(8.5961, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.7661, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.1740, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "train_loss tensor(8.5845, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.6944, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.2807, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "train_loss tensor(8.5578, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.7703, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.0431, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "train_loss tensor(8.5232, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.6564, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.1006, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "train_loss tensor(8.4923, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.6342, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.0377, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "train_loss tensor(8.4533, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.6569, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.9994, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "train_loss tensor(8.4323, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.5627, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.0586, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "train_loss tensor(8.4503, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.5601, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.0048, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "train_loss tensor(8.4354, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.6549, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.9647, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "train_loss tensor(8.4051, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.5265, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.9792, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "train_loss tensor(8.3578, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.4894, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.9999, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "train_loss tensor(8.3304, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.4961, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.9063, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "train_loss tensor(8.2940, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.4349, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.0062, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "train_loss tensor(8.2753, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.4253, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.9230, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "train_loss tensor(8.2521, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.4253, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.8806, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "train_loss tensor(8.2253, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.3981, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.8383, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "train_loss tensor(8.2087, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.3554, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.8717, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "train_loss tensor(8.1829, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.3374, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.8397, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 475\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(8.1595, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.2993, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.8525, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "train_loss tensor(8.1346, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.3054, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.7764, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "train_loss tensor(8.1186, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.2875, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.7801, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "train_loss tensor(8.1105, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.2546, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.7374, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "train_loss tensor(8.0823, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.2383, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.7315, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "train_loss tensor(8.0626, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.1894, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.7517, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "train_loss tensor(8.0212, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.2098, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.6510, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "train_loss tensor(8.0120, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.1807, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.6668, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "train_loss tensor(7.9939, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.1312, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.6768, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "train_loss tensor(7.9744, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.1219, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.6194, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "train_loss tensor(7.9591, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.1534, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.6066, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "train_loss tensor(7.9704, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.0698, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.5966, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "train_loss tensor(7.9588, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.0947, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.5842, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "train_loss tensor(7.9301, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.0605, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.5069, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "train_loss tensor(7.8743, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.0059, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.5410, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "train_loss tensor(7.8490, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.9962, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.5041, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "train_loss tensor(7.8324, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.9469, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.5418, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "train_loss tensor(7.8432, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(9.0092, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.4143, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "train_loss tensor(7.8171, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.9299, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.4677, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "train_loss tensor(7.8135, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.9164, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.4243, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "train_loss tensor(7.7598, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.9132, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.3494, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "train_loss tensor(7.7415, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.8621, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.3792, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "train_loss tensor(7.7300, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.8983, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.2815, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "train_loss tensor(7.6791, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.8261, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.3282, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "train_loss tensor(7.6849, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.8142, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.2907, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "train_loss tensor(7.6662, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.8339, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.2717, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 501\n",
      "-------------------------------\n",
      "train_loss tensor(7.6574, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.7559, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(9.2709, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 502\n",
      "-------------------------------\n",
      "train_loss tensor(7.6247, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.7338, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.2742, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 503\n",
      "-------------------------------\n",
      "train_loss tensor(7.5922, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.7562, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.2352, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 504\n",
      "-------------------------------\n",
      "train_loss tensor(7.5715, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.6934, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.2681, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 505\n",
      "-------------------------------\n",
      "train_loss tensor(7.5579, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.7062, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.1963, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 506\n",
      "-------------------------------\n",
      "train_loss tensor(7.5410, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.6938, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.1879, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 507\n",
      "-------------------------------\n",
      "train_loss tensor(7.5310, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.6449, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.1838, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 508\n",
      "-------------------------------\n",
      "train_loss tensor(7.5097, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.6282, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.1927, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 509\n",
      "-------------------------------\n",
      "train_loss tensor(7.5109, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.6184, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.1475, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 510\n",
      "-------------------------------\n",
      "train_loss tensor(7.4726, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.5883, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.1425, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 511\n",
      "-------------------------------\n",
      "train_loss tensor(7.4686, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.5948, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.1259, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 512\n",
      "-------------------------------\n",
      "train_loss tensor(7.4312, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.5874, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.0860, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 513\n",
      "-------------------------------\n",
      "train_loss tensor(7.4180, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.5685, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.1192, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 514\n",
      "-------------------------------\n",
      "train_loss tensor(7.4213, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.5903, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9944, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 515\n",
      "-------------------------------\n",
      "train_loss tensor(7.3720, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.4875, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.0919, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 516\n",
      "-------------------------------\n",
      "train_loss tensor(7.3537, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.5056, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9822, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 517\n",
      "-------------------------------\n",
      "train_loss tensor(7.3347, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.4677, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.0466, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 518\n",
      "-------------------------------\n",
      "train_loss tensor(7.3244, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.4654, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9549, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 519\n",
      "-------------------------------\n",
      "train_loss tensor(7.3143, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.4254, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9819, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 520\n",
      "-------------------------------\n",
      "train_loss tensor(7.2723, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.4543, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9177, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 521\n",
      "-------------------------------\n",
      "train_loss tensor(7.2620, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.3819, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9735, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 522\n",
      "-------------------------------\n",
      "train_loss tensor(7.2429, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.3810, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9246, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 523\n",
      "-------------------------------\n",
      "train_loss tensor(7.2348, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.3558, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9269, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 524\n",
      "-------------------------------\n",
      "train_loss tensor(7.2230, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.3360, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9148, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 525\n",
      "-------------------------------\n",
      "train_loss tensor(7.1885, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.3485, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9157, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 526\n",
      "-------------------------------\n",
      "train_loss tensor(7.1925, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.3104, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8902, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 527\n",
      "-------------------------------\n",
      "train_loss tensor(7.1682, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.2735, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9416, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 528\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(7.1624, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.3471, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7604, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 529\n",
      "-------------------------------\n",
      "train_loss tensor(7.1456, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.2352, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8926, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 530\n",
      "-------------------------------\n",
      "train_loss tensor(7.1210, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.2415, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9564, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 531\n",
      "-------------------------------\n",
      "train_loss tensor(7.0929, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.2052, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9838, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 532\n",
      "-------------------------------\n",
      "train_loss tensor(7.0676, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.1851, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9488, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 533\n",
      "-------------------------------\n",
      "train_loss tensor(7.0511, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.2231, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8173, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 534\n",
      "-------------------------------\n",
      "train_loss tensor(7.0405, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.1385, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9306, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 535\n",
      "-------------------------------\n",
      "train_loss tensor(7.0045, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.1516, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8031, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 536\n",
      "-------------------------------\n",
      "train_loss tensor(6.9927, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.1200, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8320, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 537\n",
      "-------------------------------\n",
      "train_loss tensor(6.9680, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.1017, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8546, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 538\n",
      "-------------------------------\n",
      "train_loss tensor(6.9599, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.0993, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8875, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 539\n",
      "-------------------------------\n",
      "train_loss tensor(6.9706, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.1929, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6177, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 540\n",
      "-------------------------------\n",
      "train_loss tensor(6.9907, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.0456, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7809, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 541\n",
      "-------------------------------\n",
      "train_loss tensor(6.9293, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.0649, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6426, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 542\n",
      "-------------------------------\n",
      "train_loss tensor(6.8893, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.0021, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7489, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 543\n",
      "-------------------------------\n",
      "train_loss tensor(6.8711, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(8.0135, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6424, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 544\n",
      "-------------------------------\n",
      "train_loss tensor(6.8666, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.9800, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7017, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 545\n",
      "-------------------------------\n",
      "train_loss tensor(6.8572, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.9669, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7169, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 546\n",
      "-------------------------------\n",
      "train_loss tensor(6.8349, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.9756, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5784, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 547\n",
      "-------------------------------\n",
      "train_loss tensor(6.8107, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.9436, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6168, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 548\n",
      "-------------------------------\n",
      "train_loss tensor(6.7818, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.9241, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6058, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 549\n",
      "-------------------------------\n",
      "train_loss tensor(6.7799, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.8996, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6779, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 550\n",
      "-------------------------------\n",
      "train_loss tensor(6.7793, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.8958, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5812, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 551\n",
      "-------------------------------\n",
      "train_loss tensor(6.7628, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.8698, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5824, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 552\n",
      "-------------------------------\n",
      "train_loss tensor(6.7392, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.8809, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5719, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 553\n",
      "-------------------------------\n",
      "train_loss tensor(6.7207, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.8774, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5227, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 554\n",
      "-------------------------------\n",
      "train_loss tensor(6.6819, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.8029, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(8.7091, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 555\n",
      "-------------------------------\n",
      "train_loss tensor(6.6905, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.8556, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4374, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 556\n",
      "-------------------------------\n",
      "train_loss tensor(6.6714, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.8120, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5566, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 557\n",
      "-------------------------------\n",
      "train_loss tensor(6.6821, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.8262, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4596, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 558\n",
      "-------------------------------\n",
      "train_loss tensor(6.6747, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.8329, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4257, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 559\n",
      "-------------------------------\n",
      "train_loss tensor(6.6394, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.7603, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4124, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 560\n",
      "-------------------------------\n",
      "train_loss tensor(6.6247, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.7353, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4896, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 561\n",
      "-------------------------------\n",
      "train_loss tensor(6.6052, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.7527, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4375, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 562\n",
      "-------------------------------\n",
      "train_loss tensor(6.5764, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.7039, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4097, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 563\n",
      "-------------------------------\n",
      "train_loss tensor(6.5838, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.6843, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4449, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 564\n",
      "-------------------------------\n",
      "train_loss tensor(6.5754, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.6911, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4917, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 565\n",
      "-------------------------------\n",
      "train_loss tensor(6.5761, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.7001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2851, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 566\n",
      "-------------------------------\n",
      "train_loss tensor(6.5283, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.6248, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4140, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 567\n",
      "-------------------------------\n",
      "train_loss tensor(6.5023, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.6410, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3607, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 568\n",
      "-------------------------------\n",
      "train_loss tensor(6.4944, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.6260, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3835, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 569\n",
      "-------------------------------\n",
      "train_loss tensor(6.4719, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.5776, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4179, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 570\n",
      "-------------------------------\n",
      "train_loss tensor(6.4516, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.5955, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2944, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 571\n",
      "-------------------------------\n",
      "train_loss tensor(6.4421, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.5750, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3755, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 572\n",
      "-------------------------------\n",
      "train_loss tensor(6.4242, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.5527, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3181, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 573\n",
      "-------------------------------\n",
      "train_loss tensor(6.4095, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.5440, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2812, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 574\n",
      "-------------------------------\n",
      "train_loss tensor(6.3983, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.5341, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3313, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 575\n",
      "-------------------------------\n",
      "train_loss tensor(6.3828, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.5456, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1978, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 576\n",
      "-------------------------------\n",
      "train_loss tensor(6.3749, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.4997, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2888, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 577\n",
      "-------------------------------\n",
      "train_loss tensor(6.3511, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.4934, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2210, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 578\n",
      "-------------------------------\n",
      "train_loss tensor(6.3389, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.4816, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3368, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 579\n",
      "-------------------------------\n",
      "train_loss tensor(6.3456, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.4897, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1954, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 580\n",
      "-------------------------------\n",
      "train_loss tensor(6.3338, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.4455, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2357, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 581\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(6.3044, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.4363, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1628, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 582\n",
      "-------------------------------\n",
      "train_loss tensor(6.2897, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.4330, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1890, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 583\n",
      "-------------------------------\n",
      "train_loss tensor(6.2779, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.3928, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2483, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 584\n",
      "-------------------------------\n",
      "train_loss tensor(6.2604, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.4134, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1134, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 585\n",
      "-------------------------------\n",
      "train_loss tensor(6.2382, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.3687, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1986, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 586\n",
      "-------------------------------\n",
      "train_loss tensor(6.2478, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.3720, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1407, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 587\n",
      "-------------------------------\n",
      "train_loss tensor(6.2178, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.3533, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1671, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 588\n",
      "-------------------------------\n",
      "train_loss tensor(6.2005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.3407, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1527, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 589\n",
      "-------------------------------\n",
      "train_loss tensor(6.1888, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.3459, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0577, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 590\n",
      "-------------------------------\n",
      "train_loss tensor(6.1860, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.2998, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2146, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 591\n",
      "-------------------------------\n",
      "train_loss tensor(6.1825, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.3355, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0360, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 592\n",
      "-------------------------------\n",
      "train_loss tensor(6.1500, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.3170, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0961, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 593\n",
      "-------------------------------\n",
      "train_loss tensor(6.1605, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.2877, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0241, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 594\n",
      "-------------------------------\n",
      "train_loss tensor(6.1189, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.2534, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1502, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 595\n",
      "-------------------------------\n",
      "train_loss tensor(6.1229, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.2578, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0211, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 596\n",
      "-------------------------------\n",
      "train_loss tensor(6.0959, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.2215, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0804, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 597\n",
      "-------------------------------\n",
      "train_loss tensor(6.0965, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.2221, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0399, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 598\n",
      "-------------------------------\n",
      "train_loss tensor(6.0840, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.2472, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9365, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 599\n",
      "-------------------------------\n",
      "train_loss tensor(6.0879, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.2029, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0376, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 600\n",
      "-------------------------------\n",
      "train_loss tensor(6.0804, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.2720, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7894, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 601\n",
      "-------------------------------\n",
      "train_loss tensor(6.0442, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.1582, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1401, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 602\n",
      "-------------------------------\n",
      "train_loss tensor(6.0442, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.1687, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9391, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 603\n",
      "-------------------------------\n",
      "train_loss tensor(6.0141, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.1616, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8864, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 604\n",
      "-------------------------------\n",
      "train_loss tensor(6.0046, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.1295, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9025, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 605\n",
      "-------------------------------\n",
      "train_loss tensor(5.9917, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.0984, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9680, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 606\n",
      "-------------------------------\n",
      "train_loss tensor(5.9859, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.1241, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8134, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 607\n",
      "-------------------------------\n",
      "train_loss tensor(5.9724, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.1064, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(7.9241, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 608\n",
      "-------------------------------\n",
      "train_loss tensor(5.9644, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.0633, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9709, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 609\n",
      "-------------------------------\n",
      "train_loss tensor(5.9740, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.1598, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7125, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 610\n",
      "-------------------------------\n",
      "train_loss tensor(5.9704, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.0842, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1099, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 611\n",
      "-------------------------------\n",
      "train_loss tensor(5.9572, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.1234, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7049, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 612\n",
      "-------------------------------\n",
      "train_loss tensor(5.9325, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.0476, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7762, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 613\n",
      "-------------------------------\n",
      "train_loss tensor(5.9208, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.9908, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8830, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 614\n",
      "-------------------------------\n",
      "train_loss tensor(5.9155, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.0990, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.6088, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 615\n",
      "-------------------------------\n",
      "train_loss tensor(5.9281, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.0429, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8672, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 616\n",
      "-------------------------------\n",
      "train_loss tensor(5.9017, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.0737, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.5790, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 617\n",
      "-------------------------------\n",
      "train_loss tensor(5.9165, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.9837, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7179, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 618\n",
      "-------------------------------\n",
      "train_loss tensor(5.8419, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(7.0040, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.6744, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 619\n",
      "-------------------------------\n",
      "train_loss tensor(5.8269, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.9500, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7724, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 620\n",
      "-------------------------------\n",
      "train_loss tensor(5.8154, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.9424, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7234, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 621\n",
      "-------------------------------\n",
      "train_loss tensor(5.8105, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.9782, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.5495, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 622\n",
      "-------------------------------\n",
      "train_loss tensor(5.7974, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.9167, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7972, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 623\n",
      "-------------------------------\n",
      "train_loss tensor(5.7877, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.9417, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.6230, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 624\n",
      "-------------------------------\n",
      "train_loss tensor(5.7823, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.8977, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.6278, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 625\n",
      "-------------------------------\n",
      "train_loss tensor(5.7844, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.8989, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7966, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 626\n",
      "-------------------------------\n",
      "train_loss tensor(5.7870, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.9312, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.5547, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 627\n",
      "-------------------------------\n",
      "train_loss tensor(5.7655, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.8701, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.6799, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 628\n",
      "-------------------------------\n",
      "train_loss tensor(5.7400, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.8524, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.5558, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 629\n",
      "-------------------------------\n",
      "train_loss tensor(5.7524, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.8741, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.4522, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 630\n",
      "-------------------------------\n",
      "train_loss tensor(5.7208, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.8482, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.6509, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 631\n",
      "-------------------------------\n",
      "train_loss tensor(5.6965, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.8238, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.5714, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 632\n",
      "-------------------------------\n",
      "train_loss tensor(5.6821, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.8034, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.5619, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 633\n",
      "-------------------------------\n",
      "train_loss tensor(5.7204, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.8805, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.3823, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 634\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(5.6847, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.7908, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.6579, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 635\n",
      "-------------------------------\n",
      "train_loss tensor(5.7435, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.8173, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.5263, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 636\n",
      "-------------------------------\n",
      "train_loss tensor(5.6950, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.8057, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.5080, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 637\n",
      "-------------------------------\n",
      "train_loss tensor(5.6489, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.7615, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.4521, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 638\n",
      "-------------------------------\n",
      "train_loss tensor(5.6330, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.7508, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.5010, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 639\n",
      "-------------------------------\n",
      "train_loss tensor(5.6102, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.7512, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.4876, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 640\n",
      "-------------------------------\n",
      "train_loss tensor(5.5955, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.7364, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.3866, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 641\n",
      "-------------------------------\n",
      "train_loss tensor(5.5949, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.7244, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.4051, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 642\n",
      "-------------------------------\n",
      "train_loss tensor(5.5763, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.7107, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.4000, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 643\n",
      "-------------------------------\n",
      "train_loss tensor(5.5590, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.6876, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.4334, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 644\n",
      "-------------------------------\n",
      "train_loss tensor(5.5587, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.6946, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.3869, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 645\n",
      "-------------------------------\n",
      "train_loss tensor(5.5393, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.6680, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.4441, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 646\n",
      "-------------------------------\n",
      "train_loss tensor(5.5307, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.6725, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.4278, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 647\n",
      "-------------------------------\n",
      "train_loss tensor(5.5191, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.6567, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.3797, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 648\n",
      "-------------------------------\n",
      "train_loss tensor(5.5094, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.6473, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.3406, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 649\n",
      "-------------------------------\n",
      "train_loss tensor(5.5078, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.6545, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.3629, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 650\n",
      "-------------------------------\n",
      "train_loss tensor(5.4907, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.6270, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.3409, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 651\n",
      "-------------------------------\n",
      "train_loss tensor(5.4782, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.6092, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.3519, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 652\n",
      "-------------------------------\n",
      "train_loss tensor(5.4697, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.6166, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.3131, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 653\n",
      "-------------------------------\n",
      "train_loss tensor(5.4600, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.5936, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.3238, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 654\n",
      "-------------------------------\n",
      "train_loss tensor(5.4622, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.6169, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.2409, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 655\n",
      "-------------------------------\n",
      "train_loss tensor(5.4395, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.5637, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.3587, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 656\n",
      "-------------------------------\n",
      "train_loss tensor(5.4460, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.5729, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.2775, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 657\n",
      "-------------------------------\n",
      "train_loss tensor(5.4394, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.5926, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.1880, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 658\n",
      "-------------------------------\n",
      "train_loss tensor(5.4271, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.5398, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.3587, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 659\n",
      "-------------------------------\n",
      "train_loss tensor(5.4174, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.5352, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.3389, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 660\n",
      "-------------------------------\n",
      "train_loss tensor(5.4222, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.5123, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(7.3528, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 661\n",
      "-------------------------------\n",
      "train_loss tensor(5.4332, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.6417, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.0885, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 662\n",
      "-------------------------------\n",
      "train_loss tensor(5.4142, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.5321, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.3136, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 663\n",
      "-------------------------------\n",
      "train_loss tensor(5.4199, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.5267, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.1718, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 664\n",
      "-------------------------------\n",
      "train_loss tensor(5.3867, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.4807, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.1754, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 665\n",
      "-------------------------------\n",
      "train_loss tensor(5.3834, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.5114, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.0545, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 666\n",
      "-------------------------------\n",
      "train_loss tensor(5.3515, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.4347, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.2525, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 667\n",
      "-------------------------------\n",
      "train_loss tensor(5.3468, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.4883, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.1436, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 668\n",
      "-------------------------------\n",
      "train_loss tensor(5.3186, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.4297, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.1892, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 669\n",
      "-------------------------------\n",
      "train_loss tensor(5.3055, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.4674, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.0290, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 670\n",
      "-------------------------------\n",
      "train_loss tensor(5.2958, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.4228, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.0899, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 671\n",
      "-------------------------------\n",
      "train_loss tensor(5.2784, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.4178, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.0902, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 672\n",
      "-------------------------------\n",
      "train_loss tensor(5.2734, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.4073, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.0957, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 673\n",
      "-------------------------------\n",
      "train_loss tensor(5.2717, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.3863, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.0835, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 674\n",
      "-------------------------------\n",
      "train_loss tensor(5.2666, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.3841, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.0440, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 675\n",
      "-------------------------------\n",
      "train_loss tensor(5.2383, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.4363, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.9479, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 676\n",
      "-------------------------------\n",
      "train_loss tensor(5.2421, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.3653, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.0610, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 677\n",
      "-------------------------------\n",
      "train_loss tensor(5.2228, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.3657, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.0009, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 678\n",
      "-------------------------------\n",
      "train_loss tensor(5.2179, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.3546, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.9947, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 679\n",
      "-------------------------------\n",
      "train_loss tensor(5.2207, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.3408, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.0163, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 680\n",
      "-------------------------------\n",
      "train_loss tensor(5.2167, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.3742, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.9606, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 681\n",
      "-------------------------------\n",
      "train_loss tensor(5.2371, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.3166, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.0595, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 682\n",
      "-------------------------------\n",
      "train_loss tensor(5.2439, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.3815, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.8535, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 683\n",
      "-------------------------------\n",
      "train_loss tensor(5.1817, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.3026, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.0812, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 684\n",
      "-------------------------------\n",
      "train_loss tensor(5.1916, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.3293, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.9330, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 685\n",
      "-------------------------------\n",
      "train_loss tensor(5.1518, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.2931, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.9172, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 686\n",
      "-------------------------------\n",
      "train_loss tensor(5.1534, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.2643, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.9534, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 687\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(5.1787, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.3417, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.8801, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 688\n",
      "-------------------------------\n",
      "train_loss tensor(5.1494, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.2266, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.0901, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 689\n",
      "-------------------------------\n",
      "train_loss tensor(5.1373, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.3428, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.8084, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 690\n",
      "-------------------------------\n",
      "train_loss tensor(5.1051, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.2201, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.0085, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 691\n",
      "-------------------------------\n",
      "train_loss tensor(5.1119, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.2660, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.8355, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 692\n",
      "-------------------------------\n",
      "train_loss tensor(5.0826, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.2145, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.8807, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 693\n",
      "-------------------------------\n",
      "train_loss tensor(5.0851, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.2443, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.7775, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 694\n",
      "-------------------------------\n",
      "train_loss tensor(5.0889, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.2567, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.8114, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 695\n",
      "-------------------------------\n",
      "train_loss tensor(5.0749, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.1761, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.8877, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 696\n",
      "-------------------------------\n",
      "train_loss tensor(5.0501, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.2241, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.7420, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 697\n",
      "-------------------------------\n",
      "train_loss tensor(5.0360, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.1884, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.8187, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 698\n",
      "-------------------------------\n",
      "train_loss tensor(5.0257, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.1603, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.8298, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 699\n",
      "-------------------------------\n",
      "train_loss tensor(5.0357, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.2328, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.7436, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 700\n",
      "-------------------------------\n",
      "train_loss tensor(5.0044, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.1200, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.9371, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 701\n",
      "-------------------------------\n",
      "train_loss tensor(4.9999, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.1923, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.7425, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 702\n",
      "-------------------------------\n",
      "train_loss tensor(4.9712, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.1064, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.8379, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 703\n",
      "-------------------------------\n",
      "train_loss tensor(4.9842, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.1950, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.7096, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 704\n",
      "-------------------------------\n",
      "train_loss tensor(4.9592, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.0839, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.8004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 705\n",
      "-------------------------------\n",
      "train_loss tensor(4.9525, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.1987, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.6944, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 706\n",
      "-------------------------------\n",
      "train_loss tensor(4.9483, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.0775, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.7692, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 707\n",
      "-------------------------------\n",
      "train_loss tensor(4.9115, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.1243, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.7033, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 708\n",
      "-------------------------------\n",
      "train_loss tensor(4.9170, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.0755, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.7314, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 709\n",
      "-------------------------------\n",
      "train_loss tensor(4.9052, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.0662, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.7351, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 710\n",
      "-------------------------------\n",
      "train_loss tensor(4.8882, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.0639, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.7452, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 711\n",
      "-------------------------------\n",
      "train_loss tensor(4.8749, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.0567, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.7212, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 712\n",
      "-------------------------------\n",
      "train_loss tensor(4.8652, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.0660, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.6781, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 713\n",
      "-------------------------------\n",
      "train_loss tensor(4.8546, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.0332, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(6.7787, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 714\n",
      "-------------------------------\n",
      "train_loss tensor(4.8583, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.0493, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.7042, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 715\n",
      "-------------------------------\n",
      "train_loss tensor(4.8370, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.0253, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.6991, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 716\n",
      "-------------------------------\n",
      "train_loss tensor(4.8294, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.0028, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.7207, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 717\n",
      "-------------------------------\n",
      "train_loss tensor(4.8394, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.0632, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.6560, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 718\n",
      "-------------------------------\n",
      "train_loss tensor(4.8155, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.9798, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.7464, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 719\n",
      "-------------------------------\n",
      "train_loss tensor(4.8206, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.0776, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5939, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 720\n",
      "-------------------------------\n",
      "train_loss tensor(4.8167, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.9563, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.8831, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 721\n",
      "-------------------------------\n",
      "train_loss tensor(4.8018, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(6.0392, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.6432, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 722\n",
      "-------------------------------\n",
      "train_loss tensor(4.8223, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.9634, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.7586, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 723\n",
      "-------------------------------\n",
      "train_loss tensor(4.7865, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.9653, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.6807, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 724\n",
      "-------------------------------\n",
      "train_loss tensor(4.7630, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.9520, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.6938, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 725\n",
      "-------------------------------\n",
      "train_loss tensor(4.7554, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.9661, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.6528, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 726\n",
      "-------------------------------\n",
      "train_loss tensor(4.7436, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.9184, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.6818, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 727\n",
      "-------------------------------\n",
      "train_loss tensor(4.7454, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.9870, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.6138, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 728\n",
      "-------------------------------\n",
      "train_loss tensor(4.7339, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.9206, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.6741, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 729\n",
      "-------------------------------\n",
      "train_loss tensor(4.7158, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.9160, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.6468, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 730\n",
      "-------------------------------\n",
      "train_loss tensor(4.7014, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.9008, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.6991, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 731\n",
      "-------------------------------\n",
      "train_loss tensor(4.7007, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.8790, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.6745, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 732\n",
      "-------------------------------\n",
      "train_loss tensor(4.6947, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.8819, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.6379, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 733\n",
      "-------------------------------\n",
      "train_loss tensor(4.6779, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.8963, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.6115, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 734\n",
      "-------------------------------\n",
      "train_loss tensor(4.6649, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.8629, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.6167, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 735\n",
      "-------------------------------\n",
      "train_loss tensor(4.6612, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.8664, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.6090, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 736\n",
      "-------------------------------\n",
      "train_loss tensor(4.6590, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.8313, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.7312, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 737\n",
      "-------------------------------\n",
      "train_loss tensor(4.6615, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.9152, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5533, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 738\n",
      "-------------------------------\n",
      "train_loss tensor(4.6707, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.8063, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.7970, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 739\n",
      "-------------------------------\n",
      "train_loss tensor(4.7022, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.8740, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5620, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 740\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(4.6600, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.8442, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.7569, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 741\n",
      "-------------------------------\n",
      "train_loss tensor(4.6842, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.8004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.7169, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 742\n",
      "-------------------------------\n",
      "train_loss tensor(4.6477, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.8843, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5393, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 743\n",
      "-------------------------------\n",
      "train_loss tensor(4.6292, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.7894, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.6617, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 744\n",
      "-------------------------------\n",
      "train_loss tensor(4.6173, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.8225, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5346, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 745\n",
      "-------------------------------\n",
      "train_loss tensor(4.5849, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.7599, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5718, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 746\n",
      "-------------------------------\n",
      "train_loss tensor(4.5869, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.8596, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5221, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 747\n",
      "-------------------------------\n",
      "train_loss tensor(4.6217, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.7807, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5516, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 748\n",
      "-------------------------------\n",
      "train_loss tensor(4.5866, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.7618, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5715, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 749\n",
      "-------------------------------\n",
      "train_loss tensor(4.6034, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.8980, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5854, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 750\n",
      "-------------------------------\n",
      "train_loss tensor(4.6004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.7443, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.6228, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 751\n",
      "-------------------------------\n",
      "train_loss tensor(4.5577, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.8488, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4617, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 752\n",
      "-------------------------------\n",
      "train_loss tensor(4.5571, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.7402, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5593, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 753\n",
      "-------------------------------\n",
      "train_loss tensor(4.5511, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.7511, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5230, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 754\n",
      "-------------------------------\n",
      "train_loss tensor(4.5170, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.7349, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4825, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 755\n",
      "-------------------------------\n",
      "train_loss tensor(4.5229, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.7608, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4709, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 756\n",
      "-------------------------------\n",
      "train_loss tensor(4.5213, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.7189, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5336, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 757\n",
      "-------------------------------\n",
      "train_loss tensor(4.4953, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.7454, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4559, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 758\n",
      "-------------------------------\n",
      "train_loss tensor(4.5041, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.7045, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5144, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 759\n",
      "-------------------------------\n",
      "train_loss tensor(4.5093, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.7004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5033, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 760\n",
      "-------------------------------\n",
      "train_loss tensor(4.4777, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.7542, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4504, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 761\n",
      "-------------------------------\n",
      "train_loss tensor(4.5079, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.6913, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5935, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 762\n",
      "-------------------------------\n",
      "train_loss tensor(4.5150, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.7094, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4635, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 763\n",
      "-------------------------------\n",
      "train_loss tensor(4.4613, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.7066, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4644, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 764\n",
      "-------------------------------\n",
      "train_loss tensor(4.4627, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.6704, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5381, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 765\n",
      "-------------------------------\n",
      "train_loss tensor(4.5223, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.7410, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4756, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 766\n",
      "-------------------------------\n",
      "train_loss tensor(4.4646, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.6683, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(6.5464, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 767\n",
      "-------------------------------\n",
      "train_loss tensor(4.5124, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.6493, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4906, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 768\n",
      "-------------------------------\n",
      "train_loss tensor(4.4656, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.6949, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4993, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 769\n",
      "-------------------------------\n",
      "train_loss tensor(4.4519, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.6289, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5301, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 770\n",
      "-------------------------------\n",
      "train_loss tensor(4.4822, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.6678, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4473, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 771\n",
      "-------------------------------\n",
      "train_loss tensor(4.4083, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.6090, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.6206, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 772\n",
      "-------------------------------\n",
      "train_loss tensor(4.4212, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.6427, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4634, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 773\n",
      "-------------------------------\n",
      "train_loss tensor(4.4007, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.6236, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4359, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 774\n",
      "-------------------------------\n",
      "train_loss tensor(4.3906, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.6344, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4446, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 775\n",
      "-------------------------------\n",
      "train_loss tensor(4.3903, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.5851, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4691, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 776\n",
      "-------------------------------\n",
      "train_loss tensor(4.3848, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.6094, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4043, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 777\n",
      "-------------------------------\n",
      "train_loss tensor(4.3720, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.6069, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4288, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 778\n",
      "-------------------------------\n",
      "train_loss tensor(4.3785, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.6158, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3906, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 779\n",
      "-------------------------------\n",
      "train_loss tensor(4.3732, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.6037, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4559, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 780\n",
      "-------------------------------\n",
      "train_loss tensor(4.3474, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.6206, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3864, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 781\n",
      "-------------------------------\n",
      "train_loss tensor(4.3526, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.5582, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4654, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 782\n",
      "-------------------------------\n",
      "train_loss tensor(4.3460, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.5781, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3891, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 783\n",
      "-------------------------------\n",
      "train_loss tensor(4.3461, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.6063, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3990, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 784\n",
      "-------------------------------\n",
      "train_loss tensor(4.3388, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.5592, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4402, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 785\n",
      "-------------------------------\n",
      "train_loss tensor(4.3426, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.5338, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4789, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 786\n",
      "-------------------------------\n",
      "train_loss tensor(4.3374, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.6580, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4658, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 787\n",
      "-------------------------------\n",
      "train_loss tensor(4.3405, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.5437, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4748, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 788\n",
      "-------------------------------\n",
      "train_loss tensor(4.3135, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.5588, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3925, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 789\n",
      "-------------------------------\n",
      "train_loss tensor(4.2989, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.5456, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3911, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 790\n",
      "-------------------------------\n",
      "train_loss tensor(4.2933, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.5111, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3704, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 791\n",
      "-------------------------------\n",
      "train_loss tensor(4.2865, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.5056, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4060, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 792\n",
      "-------------------------------\n",
      "train_loss tensor(4.2846, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.5260, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3585, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 793\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(4.2757, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.5106, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3902, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 794\n",
      "-------------------------------\n",
      "train_loss tensor(4.2721, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.5001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3924, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 795\n",
      "-------------------------------\n",
      "train_loss tensor(4.2644, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.4937, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4017, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 796\n",
      "-------------------------------\n",
      "train_loss tensor(4.2565, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.5342, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3567, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 797\n",
      "-------------------------------\n",
      "train_loss tensor(4.2694, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.4880, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4351, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 798\n",
      "-------------------------------\n",
      "train_loss tensor(4.2715, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.5276, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3739, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 799\n",
      "-------------------------------\n",
      "train_loss tensor(4.2876, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.5238, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3550, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 800\n",
      "-------------------------------\n",
      "train_loss tensor(4.2814, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.4687, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4761, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 801\n",
      "-------------------------------\n",
      "train_loss tensor(4.2661, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.5905, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5052, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 802\n",
      "-------------------------------\n",
      "train_loss tensor(4.2586, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.4627, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3976, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 803\n",
      "-------------------------------\n",
      "train_loss tensor(4.2484, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.4802, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3711, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 804\n",
      "-------------------------------\n",
      "train_loss tensor(4.2246, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.5228, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3926, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 805\n",
      "-------------------------------\n",
      "train_loss tensor(4.2269, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.4514, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3938, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 806\n",
      "-------------------------------\n",
      "train_loss tensor(4.2149, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.4475, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3328, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 807\n",
      "-------------------------------\n",
      "train_loss tensor(4.2108, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.5381, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4577, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 808\n",
      "-------------------------------\n",
      "train_loss tensor(4.2290, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.4290, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4134, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 809\n",
      "-------------------------------\n",
      "train_loss tensor(4.2231, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.4286, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3646, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 810\n",
      "-------------------------------\n",
      "train_loss tensor(4.2039, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.4994, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4036, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 811\n",
      "-------------------------------\n",
      "train_loss tensor(4.1863, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.4197, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4257, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 812\n",
      "-------------------------------\n",
      "train_loss tensor(4.2050, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.4750, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3194, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 813\n",
      "-------------------------------\n",
      "train_loss tensor(4.1966, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.4081, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3204, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 814\n",
      "-------------------------------\n",
      "train_loss tensor(4.2027, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.4186, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3708, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 815\n",
      "-------------------------------\n",
      "train_loss tensor(4.2163, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.5769, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4146, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 816\n",
      "-------------------------------\n",
      "train_loss tensor(4.2107, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.4063, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4095, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 817\n",
      "-------------------------------\n",
      "train_loss tensor(4.1632, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.4807, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3251, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 818\n",
      "-------------------------------\n",
      "train_loss tensor(4.1648, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.3813, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3640, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 819\n",
      "-------------------------------\n",
      "train_loss tensor(4.1611, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.4011, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(6.3470, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 820\n",
      "-------------------------------\n",
      "train_loss tensor(4.1428, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.4231, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3360, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 821\n",
      "-------------------------------\n",
      "train_loss tensor(4.1214, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.3753, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3272, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 822\n",
      "-------------------------------\n",
      "train_loss tensor(4.1269, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.3743, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3542, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 823\n",
      "-------------------------------\n",
      "train_loss tensor(4.1242, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.4364, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3956, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 824\n",
      "-------------------------------\n",
      "train_loss tensor(4.1427, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.4010, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3008, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 825\n",
      "-------------------------------\n",
      "train_loss tensor(4.1563, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.3776, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3175, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 826\n",
      "-------------------------------\n",
      "train_loss tensor(4.1579, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.4411, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3294, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 827\n",
      "-------------------------------\n",
      "train_loss tensor(4.1474, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.4007, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3620, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 828\n",
      "-------------------------------\n",
      "train_loss tensor(4.1191, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.4031, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3185, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 829\n",
      "-------------------------------\n",
      "train_loss tensor(4.1114, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.3298, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3136, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 830\n",
      "-------------------------------\n",
      "train_loss tensor(4.0998, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.3431, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3305, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 831\n",
      "-------------------------------\n",
      "train_loss tensor(4.0942, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.4828, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2970, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 832\n",
      "-------------------------------\n",
      "train_loss tensor(4.1311, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.3444, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4453, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 833\n",
      "-------------------------------\n",
      "train_loss tensor(4.1227, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.4434, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2857, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 834\n",
      "-------------------------------\n",
      "train_loss tensor(4.0818, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.3630, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3352, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 835\n",
      "-------------------------------\n",
      "train_loss tensor(4.0951, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.3543, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3046, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 836\n",
      "-------------------------------\n",
      "train_loss tensor(4.0786, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.3783, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2923, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 837\n",
      "-------------------------------\n",
      "train_loss tensor(4.0731, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.3110, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2678, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 838\n",
      "-------------------------------\n",
      "train_loss tensor(4.0505, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.3098, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2809, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 839\n",
      "-------------------------------\n",
      "train_loss tensor(4.0340, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.3141, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2910, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 840\n",
      "-------------------------------\n",
      "train_loss tensor(4.0305, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.3292, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2674, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 841\n",
      "-------------------------------\n",
      "train_loss tensor(4.0262, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.3045, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2857, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 842\n",
      "-------------------------------\n",
      "train_loss tensor(4.0227, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.3016, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2735, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 843\n",
      "-------------------------------\n",
      "train_loss tensor(4.0190, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.3393, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2925, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 844\n",
      "-------------------------------\n",
      "train_loss tensor(4.0208, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.2972, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3122, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 845\n",
      "-------------------------------\n",
      "train_loss tensor(4.0058, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.3781, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2676, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 846\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(4.0861, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.2887, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2460, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 847\n",
      "-------------------------------\n",
      "train_loss tensor(4.0156, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.3123, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3085, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 848\n",
      "-------------------------------\n",
      "train_loss tensor(4.0195, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.3073, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2478, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 849\n",
      "-------------------------------\n",
      "train_loss tensor(4.0267, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.2792, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3057, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 850\n",
      "-------------------------------\n",
      "train_loss tensor(3.9853, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.3130, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2743, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 851\n",
      "-------------------------------\n",
      "train_loss tensor(4.0016, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.2795, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2840, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 852\n",
      "-------------------------------\n",
      "train_loss tensor(3.9774, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.2590, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2503, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 853\n",
      "-------------------------------\n",
      "train_loss tensor(3.9859, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.2680, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2733, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 854\n",
      "-------------------------------\n",
      "train_loss tensor(3.9883, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.2734, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2981, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 855\n",
      "-------------------------------\n",
      "train_loss tensor(3.9776, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.2928, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2937, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 856\n",
      "-------------------------------\n",
      "train_loss tensor(3.9596, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.2341, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2832, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 857\n",
      "-------------------------------\n",
      "train_loss tensor(3.9639, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.2498, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2701, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 858\n",
      "-------------------------------\n",
      "train_loss tensor(3.9484, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.2522, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2683, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 859\n",
      "-------------------------------\n",
      "train_loss tensor(3.9338, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.3001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2901, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 860\n",
      "-------------------------------\n",
      "train_loss tensor(3.9996, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.2400, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2704, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 861\n",
      "-------------------------------\n",
      "train_loss tensor(3.9652, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.2516, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2931, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 862\n",
      "-------------------------------\n",
      "train_loss tensor(3.9712, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.3253, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2905, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 863\n",
      "-------------------------------\n",
      "train_loss tensor(3.9627, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.2352, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3272, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 864\n",
      "-------------------------------\n",
      "train_loss tensor(3.9658, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.2527, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2985, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 865\n",
      "-------------------------------\n",
      "train_loss tensor(3.9486, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.2918, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3299, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 866\n",
      "-------------------------------\n",
      "train_loss tensor(3.9135, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.2219, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3041, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 867\n",
      "-------------------------------\n",
      "train_loss tensor(3.9651, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.2524, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2871, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 868\n",
      "-------------------------------\n",
      "train_loss tensor(4.0352, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.2745, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3811, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 869\n",
      "-------------------------------\n",
      "train_loss tensor(4.0009, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.2591, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3512, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 870\n",
      "-------------------------------\n",
      "train_loss tensor(3.9958, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.3547, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3978, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 871\n",
      "-------------------------------\n",
      "train_loss tensor(3.9469, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.2230, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2887, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 872\n",
      "-------------------------------\n",
      "train_loss tensor(3.9579, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.2097, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(6.2364, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 873\n",
      "-------------------------------\n",
      "train_loss tensor(3.8970, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.2095, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2676, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 874\n",
      "-------------------------------\n",
      "train_loss tensor(3.8867, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.2186, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2441, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 875\n",
      "-------------------------------\n",
      "train_loss tensor(3.8860, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.1639, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2451, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 876\n",
      "-------------------------------\n",
      "train_loss tensor(3.8873, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.1797, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2054, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 877\n",
      "-------------------------------\n",
      "train_loss tensor(3.8700, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.1826, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2261, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 878\n",
      "-------------------------------\n",
      "train_loss tensor(3.8656, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.2096, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2484, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 879\n",
      "-------------------------------\n",
      "train_loss tensor(3.8596, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.1800, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2427, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 880\n",
      "-------------------------------\n",
      "train_loss tensor(3.8613, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.1988, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2585, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 881\n",
      "-------------------------------\n",
      "train_loss tensor(3.8624, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.1664, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2238, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 882\n",
      "-------------------------------\n",
      "train_loss tensor(3.8603, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.1856, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2641, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 883\n",
      "-------------------------------\n",
      "train_loss tensor(3.8457, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.1596, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2148, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 884\n",
      "-------------------------------\n",
      "train_loss tensor(3.8628, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.1979, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2837, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 885\n",
      "-------------------------------\n",
      "train_loss tensor(3.8642, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.2019, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2536, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 886\n",
      "-------------------------------\n",
      "train_loss tensor(3.8731, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.1610, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3066, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 887\n",
      "-------------------------------\n",
      "train_loss tensor(3.8718, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.3705, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5191, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 888\n",
      "-------------------------------\n",
      "train_loss tensor(3.9063, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.1917, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2666, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 889\n",
      "-------------------------------\n",
      "train_loss tensor(3.8459, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.2138, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3142, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 890\n",
      "-------------------------------\n",
      "train_loss tensor(3.9003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.1445, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2529, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 891\n",
      "-------------------------------\n",
      "train_loss tensor(3.8566, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.1612, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2078, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 892\n",
      "-------------------------------\n",
      "train_loss tensor(3.8417, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.1895, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2818, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 893\n",
      "-------------------------------\n",
      "train_loss tensor(3.8125, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.1429, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2260, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 894\n",
      "-------------------------------\n",
      "train_loss tensor(3.8515, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.1713, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2151, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 895\n",
      "-------------------------------\n",
      "train_loss tensor(3.7924, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.1284, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2382, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 896\n",
      "-------------------------------\n",
      "train_loss tensor(3.8026, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.1596, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2431, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 897\n",
      "-------------------------------\n",
      "train_loss tensor(3.7952, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.1272, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2705, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 898\n",
      "-------------------------------\n",
      "train_loss tensor(3.7922, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.1250, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2195, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 899\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(3.7957, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.1569, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2800, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 900\n",
      "-------------------------------\n",
      "train_loss tensor(3.7896, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.1307, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2112, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 901\n",
      "-------------------------------\n",
      "train_loss tensor(3.8040, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.1088, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.1971, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 902\n",
      "-------------------------------\n",
      "train_loss tensor(3.7803, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.1212, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2427, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 903\n",
      "-------------------------------\n",
      "train_loss tensor(3.7661, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.1048, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.1744, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 904\n",
      "-------------------------------\n",
      "train_loss tensor(3.7834, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.1192, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2441, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 905\n",
      "-------------------------------\n",
      "train_loss tensor(3.8018, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.1821, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3184, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 906\n",
      "-------------------------------\n",
      "train_loss tensor(3.7786, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0824, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2260, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 907\n",
      "-------------------------------\n",
      "train_loss tensor(3.7746, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.1191, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2021, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 908\n",
      "-------------------------------\n",
      "train_loss tensor(3.7584, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.1110, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3058, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 909\n",
      "-------------------------------\n",
      "train_loss tensor(3.7464, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.1142, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2064, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 910\n",
      "-------------------------------\n",
      "train_loss tensor(3.7613, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0821, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2175, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 911\n",
      "-------------------------------\n",
      "train_loss tensor(3.7411, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.1195, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2334, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 912\n",
      "-------------------------------\n",
      "train_loss tensor(3.7382, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.1447, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3098, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 913\n",
      "-------------------------------\n",
      "train_loss tensor(3.7522, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0805, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2586, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 914\n",
      "-------------------------------\n",
      "train_loss tensor(3.7733, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.1653, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3306, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 915\n",
      "-------------------------------\n",
      "train_loss tensor(3.7489, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.1102, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2966, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 916\n",
      "-------------------------------\n",
      "train_loss tensor(3.7462, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.1519, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2321, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 917\n",
      "-------------------------------\n",
      "train_loss tensor(3.7594, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0636, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2332, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 918\n",
      "-------------------------------\n",
      "train_loss tensor(3.7238, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0516, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2229, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 919\n",
      "-------------------------------\n",
      "train_loss tensor(3.7151, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0800, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2356, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 920\n",
      "-------------------------------\n",
      "train_loss tensor(3.7458, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.1173, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2876, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 921\n",
      "-------------------------------\n",
      "train_loss tensor(3.7397, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0955, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3273, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 922\n",
      "-------------------------------\n",
      "train_loss tensor(3.8125, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.2647, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3552, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 923\n",
      "-------------------------------\n",
      "train_loss tensor(3.8402, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0844, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2577, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 924\n",
      "-------------------------------\n",
      "train_loss tensor(3.7777, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0685, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2058, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 925\n",
      "-------------------------------\n",
      "train_loss tensor(3.7842, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.1415, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(6.2632, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 926\n",
      "-------------------------------\n",
      "train_loss tensor(3.7656, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0450, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2351, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 927\n",
      "-------------------------------\n",
      "train_loss tensor(3.7127, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0838, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2245, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 928\n",
      "-------------------------------\n",
      "train_loss tensor(3.7064, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0208, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2093, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 929\n",
      "-------------------------------\n",
      "train_loss tensor(3.7307, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0341, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2319, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 930\n",
      "-------------------------------\n",
      "train_loss tensor(3.7399, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.2138, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3098, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 931\n",
      "-------------------------------\n",
      "train_loss tensor(3.7555, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0386, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2138, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 932\n",
      "-------------------------------\n",
      "train_loss tensor(3.7743, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0534, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2155, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 933\n",
      "-------------------------------\n",
      "train_loss tensor(3.6894, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0335, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.1916, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 934\n",
      "-------------------------------\n",
      "train_loss tensor(3.6754, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0460, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2138, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 935\n",
      "-------------------------------\n",
      "train_loss tensor(3.6627, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0126, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2119, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 936\n",
      "-------------------------------\n",
      "train_loss tensor(3.6737, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0292, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2266, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 937\n",
      "-------------------------------\n",
      "train_loss tensor(3.6700, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0363, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2409, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 938\n",
      "-------------------------------\n",
      "train_loss tensor(3.6557, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0029, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.1929, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 939\n",
      "-------------------------------\n",
      "train_loss tensor(3.6709, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0724, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2435, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 940\n",
      "-------------------------------\n",
      "train_loss tensor(3.6697, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0176, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2333, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 941\n",
      "-------------------------------\n",
      "train_loss tensor(3.6682, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0012, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.1883, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 942\n",
      "-------------------------------\n",
      "train_loss tensor(3.6547, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0299, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3180, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 943\n",
      "-------------------------------\n",
      "train_loss tensor(3.6667, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9986, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.1980, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 944\n",
      "-------------------------------\n",
      "train_loss tensor(3.6572, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0133, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2017, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 945\n",
      "-------------------------------\n",
      "train_loss tensor(3.6540, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0315, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3686, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 946\n",
      "-------------------------------\n",
      "train_loss tensor(3.6483, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0203, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.1730, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 947\n",
      "-------------------------------\n",
      "train_loss tensor(3.6466, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0474, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2743, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 948\n",
      "-------------------------------\n",
      "train_loss tensor(3.6473, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0274, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2394, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 949\n",
      "-------------------------------\n",
      "train_loss tensor(3.6906, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0847, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2991, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 950\n",
      "-------------------------------\n",
      "train_loss tensor(3.6928, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0056, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2397, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 951\n",
      "-------------------------------\n",
      "train_loss tensor(3.6595, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9776, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3778, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 952\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(3.7283, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0130, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3208, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 953\n",
      "-------------------------------\n",
      "train_loss tensor(3.6596, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.1749, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 954\n",
      "-------------------------------\n",
      "train_loss tensor(3.6441, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0644, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3026, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 955\n",
      "-------------------------------\n",
      "train_loss tensor(3.6496, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0324, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2518, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 956\n",
      "-------------------------------\n",
      "train_loss tensor(3.6164, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0111, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2570, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 957\n",
      "-------------------------------\n",
      "train_loss tensor(3.6303, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9834, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2574, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 958\n",
      "-------------------------------\n",
      "train_loss tensor(3.6505, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0349, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5065, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 959\n",
      "-------------------------------\n",
      "train_loss tensor(3.6364, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9803, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.1825, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 960\n",
      "-------------------------------\n",
      "train_loss tensor(3.6957, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9570, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.1710, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 961\n",
      "-------------------------------\n",
      "train_loss tensor(3.6451, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0301, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2028, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 962\n",
      "-------------------------------\n",
      "train_loss tensor(3.6373, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9707, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.1775, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 963\n",
      "-------------------------------\n",
      "train_loss tensor(3.5963, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9870, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2588, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 964\n",
      "-------------------------------\n",
      "train_loss tensor(3.6258, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9508, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.1749, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 965\n",
      "-------------------------------\n",
      "train_loss tensor(3.6226, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9588, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2754, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 966\n",
      "-------------------------------\n",
      "train_loss tensor(3.6371, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9910, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4114, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 967\n",
      "-------------------------------\n",
      "train_loss tensor(3.6322, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0036, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4053, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 968\n",
      "-------------------------------\n",
      "train_loss tensor(3.6866, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9653, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3957, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 969\n",
      "-------------------------------\n",
      "train_loss tensor(3.6953, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0923, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.1045, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 970\n",
      "-------------------------------\n",
      "train_loss tensor(3.6193, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9871, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2533, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 971\n",
      "-------------------------------\n",
      "train_loss tensor(3.6228, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0129, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2390, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 972\n",
      "-------------------------------\n",
      "train_loss tensor(3.5785, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9127, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.1599, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 973\n",
      "-------------------------------\n",
      "train_loss tensor(3.6114, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9696, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3135, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 974\n",
      "-------------------------------\n",
      "train_loss tensor(3.6016, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9635, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.1090, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 975\n",
      "-------------------------------\n",
      "train_loss tensor(3.6038, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0021, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2877, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 976\n",
      "-------------------------------\n",
      "train_loss tensor(3.5926, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9362, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.1638, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 977\n",
      "-------------------------------\n",
      "train_loss tensor(3.5555, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9502, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.1556, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 978\n",
      "-------------------------------\n",
      "train_loss tensor(3.5537, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9086, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(6.2072, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 979\n",
      "-------------------------------\n",
      "train_loss tensor(3.5568, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9220, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.1958, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 980\n",
      "-------------------------------\n",
      "train_loss tensor(3.5400, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9023, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2010, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 981\n",
      "-------------------------------\n",
      "train_loss tensor(3.5351, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9105, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2586, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 982\n",
      "-------------------------------\n",
      "train_loss tensor(3.5355, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9075, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.1843, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 983\n",
      "-------------------------------\n",
      "train_loss tensor(3.5243, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9117, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2126, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 984\n",
      "-------------------------------\n",
      "train_loss tensor(3.5352, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8983, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2490, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 985\n",
      "-------------------------------\n",
      "train_loss tensor(3.5611, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0199, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2589, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 986\n",
      "-------------------------------\n",
      "train_loss tensor(3.5633, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8813, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2444, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 987\n",
      "-------------------------------\n",
      "train_loss tensor(3.5700, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8940, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.1714, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 988\n",
      "-------------------------------\n",
      "train_loss tensor(3.5196, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9067, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2529, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 989\n",
      "-------------------------------\n",
      "train_loss tensor(3.5349, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8965, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2477, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 990\n",
      "-------------------------------\n",
      "train_loss tensor(3.5250, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9828, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2479, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 991\n",
      "-------------------------------\n",
      "train_loss tensor(3.5783, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8999, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3205, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 992\n",
      "-------------------------------\n",
      "train_loss tensor(3.5637, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0092, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3106, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 993\n",
      "-------------------------------\n",
      "train_loss tensor(3.6265, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9074, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2481, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 994\n",
      "-------------------------------\n",
      "train_loss tensor(3.6330, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8622, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5229, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 995\n",
      "-------------------------------\n",
      "train_loss tensor(3.5878, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9804, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.1651, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 996\n",
      "-------------------------------\n",
      "train_loss tensor(3.6022, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8728, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2195, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 997\n",
      "-------------------------------\n",
      "train_loss tensor(3.5501, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8514, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2194, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 998\n",
      "-------------------------------\n",
      "train_loss tensor(3.5972, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8718, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.1570, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 999\n",
      "-------------------------------\n",
      "train_loss tensor(3.5316, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8595, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2405, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1000\n",
      "-------------------------------\n",
      "train_loss tensor(3.5968, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9347, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.1630, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1001\n",
      "-------------------------------\n",
      "train_loss tensor(3.5516, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8563, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3338, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1002\n",
      "-------------------------------\n",
      "train_loss tensor(3.5234, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9501, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2989, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1003\n",
      "-------------------------------\n",
      "train_loss tensor(3.5272, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8654, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2143, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1004\n",
      "-------------------------------\n",
      "train_loss tensor(3.4922, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8813, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.1677, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1005\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(3.4823, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8902, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2608, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1006\n",
      "-------------------------------\n",
      "train_loss tensor(3.5339, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0963, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3510, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1007\n",
      "-------------------------------\n",
      "train_loss tensor(3.6305, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8739, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5328, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1008\n",
      "-------------------------------\n",
      "train_loss tensor(3.5728, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8795, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2356, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1009\n",
      "-------------------------------\n",
      "train_loss tensor(3.4884, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8823, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2326, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1010\n",
      "-------------------------------\n",
      "train_loss tensor(3.5284, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8950, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2119, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1011\n",
      "-------------------------------\n",
      "train_loss tensor(3.4987, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8621, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2867, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1012\n",
      "-------------------------------\n",
      "train_loss tensor(3.5082, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8099, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2098, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1013\n",
      "-------------------------------\n",
      "train_loss tensor(3.4666, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7878, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2027, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1014\n",
      "-------------------------------\n",
      "train_loss tensor(3.4516, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8262, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2838, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1015\n",
      "-------------------------------\n",
      "train_loss tensor(3.4572, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8240, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2402, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1016\n",
      "-------------------------------\n",
      "train_loss tensor(3.4361, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7973, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2354, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1017\n",
      "-------------------------------\n",
      "train_loss tensor(3.4379, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8022, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2882, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1018\n",
      "-------------------------------\n",
      "train_loss tensor(3.4356, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8445, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2147, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1019\n",
      "-------------------------------\n",
      "train_loss tensor(3.4266, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8062, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3528, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1020\n",
      "-------------------------------\n",
      "train_loss tensor(3.4440, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8437, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2325, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1021\n",
      "-------------------------------\n",
      "train_loss tensor(3.4409, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8029, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2411, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1022\n",
      "-------------------------------\n",
      "train_loss tensor(3.4392, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7985, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3442, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1023\n",
      "-------------------------------\n",
      "train_loss tensor(3.4601, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8859, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.1945, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1024\n",
      "-------------------------------\n",
      "train_loss tensor(3.4529, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7837, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3419, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1025\n",
      "-------------------------------\n",
      "train_loss tensor(3.4450, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8492, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2027, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1026\n",
      "-------------------------------\n",
      "train_loss tensor(3.4240, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7847, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2857, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1027\n",
      "-------------------------------\n",
      "train_loss tensor(3.4212, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8056, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2814, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1028\n",
      "-------------------------------\n",
      "train_loss tensor(3.4129, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7813, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2446, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1029\n",
      "-------------------------------\n",
      "train_loss tensor(3.4277, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7762, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3851, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1030\n",
      "-------------------------------\n",
      "train_loss tensor(3.4338, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8938, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2093, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1031\n",
      "-------------------------------\n",
      "train_loss tensor(3.4045, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8040, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(6.4501, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1032\n",
      "-------------------------------\n",
      "train_loss tensor(3.4783, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9502, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3697, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1033\n",
      "-------------------------------\n",
      "train_loss tensor(3.4423, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7714, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3458, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1034\n",
      "-------------------------------\n",
      "train_loss tensor(3.4483, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8927, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2300, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1035\n",
      "-------------------------------\n",
      "train_loss tensor(3.4239, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7787, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3466, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1036\n",
      "-------------------------------\n",
      "train_loss tensor(3.4143, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8631, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.1534, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1037\n",
      "-------------------------------\n",
      "train_loss tensor(3.4432, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7410, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3501, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1038\n",
      "-------------------------------\n",
      "train_loss tensor(3.3908, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8187, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2196, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1039\n",
      "-------------------------------\n",
      "train_loss tensor(3.4144, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7724, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2523, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1040\n",
      "-------------------------------\n",
      "train_loss tensor(3.3859, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7660, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4017, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1041\n",
      "-------------------------------\n",
      "train_loss tensor(3.3714, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7944, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2267, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1042\n",
      "-------------------------------\n",
      "train_loss tensor(3.3894, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7782, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3616, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1043\n",
      "-------------------------------\n",
      "train_loss tensor(3.3827, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7910, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2969, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1044\n",
      "-------------------------------\n",
      "train_loss tensor(3.3713, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7811, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2400, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1045\n",
      "-------------------------------\n",
      "train_loss tensor(3.3603, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7657, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3732, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1046\n",
      "-------------------------------\n",
      "train_loss tensor(3.3841, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7834, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2510, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1047\n",
      "-------------------------------\n",
      "train_loss tensor(3.3754, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7362, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2800, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1048\n",
      "-------------------------------\n",
      "train_loss tensor(3.3578, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7674, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3951, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1049\n",
      "-------------------------------\n",
      "train_loss tensor(3.3491, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7817, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2614, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1050\n",
      "-------------------------------\n",
      "train_loss tensor(3.3424, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7374, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4044, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1051\n",
      "-------------------------------\n",
      "train_loss tensor(3.3676, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7941, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2827, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1052\n",
      "-------------------------------\n",
      "train_loss tensor(3.3709, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7594, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4234, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1053\n",
      "-------------------------------\n",
      "train_loss tensor(3.3889, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8220, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3267, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1054\n",
      "-------------------------------\n",
      "train_loss tensor(3.3505, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7416, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4407, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1055\n",
      "-------------------------------\n",
      "train_loss tensor(3.3898, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7742, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3271, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1056\n",
      "-------------------------------\n",
      "train_loss tensor(3.3386, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7297, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4312, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1057\n",
      "-------------------------------\n",
      "train_loss tensor(3.3210, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7677, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.2859, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1058\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(3.3345, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7557, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3226, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1059\n",
      "-------------------------------\n",
      "train_loss tensor(3.3359, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7397, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4605, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1060\n",
      "-------------------------------\n",
      "train_loss tensor(3.3093, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7739, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3109, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1061\n",
      "-------------------------------\n",
      "train_loss tensor(3.3240, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7223, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3902, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1062\n",
      "-------------------------------\n",
      "train_loss tensor(3.3141, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7540, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3785, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1063\n",
      "-------------------------------\n",
      "train_loss tensor(3.2985, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7447, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3908, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1064\n",
      "-------------------------------\n",
      "train_loss tensor(3.2923, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7277, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3917, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1065\n",
      "-------------------------------\n",
      "train_loss tensor(3.2868, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7463, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4640, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1066\n",
      "-------------------------------\n",
      "train_loss tensor(3.3029, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7128, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4137, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1067\n",
      "-------------------------------\n",
      "train_loss tensor(3.3141, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7762, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3306, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1068\n",
      "-------------------------------\n",
      "train_loss tensor(3.3093, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7100, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.6567, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1069\n",
      "-------------------------------\n",
      "train_loss tensor(3.3578, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8299, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3226, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1070\n",
      "-------------------------------\n",
      "train_loss tensor(3.3240, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7170, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4290, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1071\n",
      "-------------------------------\n",
      "train_loss tensor(3.2816, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7729, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3603, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1072\n",
      "-------------------------------\n",
      "train_loss tensor(3.2837, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7291, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4274, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1073\n",
      "-------------------------------\n",
      "train_loss tensor(3.2773, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7237, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5177, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1074\n",
      "-------------------------------\n",
      "train_loss tensor(3.2984, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7254, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4774, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1075\n",
      "-------------------------------\n",
      "train_loss tensor(3.2972, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7295, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4782, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1076\n",
      "-------------------------------\n",
      "train_loss tensor(3.2860, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7361, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4195, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1077\n",
      "-------------------------------\n",
      "train_loss tensor(3.2679, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7303, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4278, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1078\n",
      "-------------------------------\n",
      "train_loss tensor(3.2810, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7498, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4938, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1079\n",
      "-------------------------------\n",
      "train_loss tensor(3.2822, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7043, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4659, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1080\n",
      "-------------------------------\n",
      "train_loss tensor(3.2614, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7047, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4678, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1081\n",
      "-------------------------------\n",
      "train_loss tensor(3.2671, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7092, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5581, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1082\n",
      "-------------------------------\n",
      "train_loss tensor(3.2918, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7548, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5117, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1083\n",
      "-------------------------------\n",
      "train_loss tensor(3.2639, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7647, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4458, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1084\n",
      "-------------------------------\n",
      "train_loss tensor(3.2780, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6869, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(6.5609, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1085\n",
      "-------------------------------\n",
      "train_loss tensor(3.2637, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7719, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.3899, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1086\n",
      "-------------------------------\n",
      "train_loss tensor(3.2637, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6913, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5431, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1087\n",
      "-------------------------------\n",
      "train_loss tensor(3.2880, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8061, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5180, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1088\n",
      "-------------------------------\n",
      "train_loss tensor(3.2879, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6823, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5689, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1089\n",
      "-------------------------------\n",
      "train_loss tensor(3.2607, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6896, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5797, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1090\n",
      "-------------------------------\n",
      "train_loss tensor(3.2687, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7213, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5584, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1091\n",
      "-------------------------------\n",
      "train_loss tensor(3.2404, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7446, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4889, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1092\n",
      "-------------------------------\n",
      "train_loss tensor(3.2343, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7247, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5962, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1093\n",
      "-------------------------------\n",
      "train_loss tensor(3.2266, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7046, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5154, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1094\n",
      "-------------------------------\n",
      "train_loss tensor(3.2197, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6910, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5765, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1095\n",
      "-------------------------------\n",
      "train_loss tensor(3.2245, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7101, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.6218, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1096\n",
      "-------------------------------\n",
      "train_loss tensor(3.2163, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6804, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5801, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1097\n",
      "-------------------------------\n",
      "train_loss tensor(3.1995, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6925, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5871, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1098\n",
      "-------------------------------\n",
      "train_loss tensor(3.2028, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6934, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5328, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1099\n",
      "-------------------------------\n",
      "train_loss tensor(3.2177, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6946, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.6241, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1100\n",
      "-------------------------------\n",
      "train_loss tensor(3.1972, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7196, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5337, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1101\n",
      "-------------------------------\n",
      "train_loss tensor(3.1936, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6712, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.6313, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1102\n",
      "-------------------------------\n",
      "train_loss tensor(3.1963, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6964, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5669, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1103\n",
      "-------------------------------\n",
      "train_loss tensor(3.1965, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6893, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.7005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1104\n",
      "-------------------------------\n",
      "train_loss tensor(3.2177, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7103, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.4969, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1105\n",
      "-------------------------------\n",
      "train_loss tensor(3.1929, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7091, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.6541, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1106\n",
      "-------------------------------\n",
      "train_loss tensor(3.2068, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6346, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.7055, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1107\n",
      "-------------------------------\n",
      "train_loss tensor(3.1971, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7449, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.6189, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1108\n",
      "-------------------------------\n",
      "train_loss tensor(3.1865, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6720, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.7261, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1109\n",
      "-------------------------------\n",
      "train_loss tensor(3.1782, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7154, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.6073, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1110\n",
      "-------------------------------\n",
      "train_loss tensor(3.1955, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6807, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.7390, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1111\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(3.1675, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6968, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.6012, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1112\n",
      "-------------------------------\n",
      "train_loss tensor(3.1700, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6630, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.6945, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1113\n",
      "-------------------------------\n",
      "train_loss tensor(3.1778, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7166, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.6752, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1114\n",
      "-------------------------------\n",
      "train_loss tensor(3.1788, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7195, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.7340, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1115\n",
      "-------------------------------\n",
      "train_loss tensor(3.1576, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6291, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.7306, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1116\n",
      "-------------------------------\n",
      "train_loss tensor(3.1952, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7910, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.6683, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1117\n",
      "-------------------------------\n",
      "train_loss tensor(3.2345, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7273, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.0357, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1118\n",
      "-------------------------------\n",
      "train_loss tensor(3.2306, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7253, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5693, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1119\n",
      "-------------------------------\n",
      "train_loss tensor(3.2008, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6279, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5422, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1120\n",
      "-------------------------------\n",
      "train_loss tensor(3.1639, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6988, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.7441, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1121\n",
      "-------------------------------\n",
      "train_loss tensor(3.1836, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6538, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.9825, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1122\n",
      "-------------------------------\n",
      "train_loss tensor(3.1847, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6944, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.7458, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1123\n",
      "-------------------------------\n",
      "train_loss tensor(3.2197, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6779, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5999, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1124\n",
      "-------------------------------\n",
      "train_loss tensor(3.2107, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6056, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.1135, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1125\n",
      "-------------------------------\n",
      "train_loss tensor(3.2535, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8026, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.5725, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1126\n",
      "-------------------------------\n",
      "train_loss tensor(3.1874, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6782, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.7966, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1127\n",
      "-------------------------------\n",
      "train_loss tensor(3.1796, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6623, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.6708, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1128\n",
      "-------------------------------\n",
      "train_loss tensor(3.1391, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7185, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.6338, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1129\n",
      "-------------------------------\n",
      "train_loss tensor(3.1458, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6271, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.8691, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1130\n",
      "-------------------------------\n",
      "train_loss tensor(3.1897, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7412, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.6952, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1131\n",
      "-------------------------------\n",
      "train_loss tensor(3.1868, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6471, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.7093, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1132\n",
      "-------------------------------\n",
      "train_loss tensor(3.1413, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6427, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.7024, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1133\n",
      "-------------------------------\n",
      "train_loss tensor(3.1314, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6904, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.7684, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1134\n",
      "-------------------------------\n",
      "train_loss tensor(3.1349, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6373, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.9607, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1135\n",
      "-------------------------------\n",
      "train_loss tensor(3.1525, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6387, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.0697, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1136\n",
      "-------------------------------\n",
      "train_loss tensor(3.1521, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6871, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.7908, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1137\n",
      "-------------------------------\n",
      "train_loss tensor(3.1742, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6420, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(7.6167, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1138\n",
      "-------------------------------\n",
      "train_loss tensor(3.2400, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6383, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.5581, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1139\n",
      "-------------------------------\n",
      "train_loss tensor(3.1757, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6970, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.7565, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1140\n",
      "-------------------------------\n",
      "train_loss tensor(3.1458, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6017, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.8276, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1141\n",
      "-------------------------------\n",
      "train_loss tensor(3.1378, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6685, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.7249, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1142\n",
      "-------------------------------\n",
      "train_loss tensor(3.1087, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6334, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.8357, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1143\n",
      "-------------------------------\n",
      "train_loss tensor(3.1294, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6318, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.0068, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1144\n",
      "-------------------------------\n",
      "train_loss tensor(3.1078, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6315, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.7238, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1145\n",
      "-------------------------------\n",
      "train_loss tensor(3.1313, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7158, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.8444, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1146\n",
      "-------------------------------\n",
      "train_loss tensor(3.1211, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5992, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.0348, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1147\n",
      "-------------------------------\n",
      "train_loss tensor(3.1129, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6656, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.8458, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1148\n",
      "-------------------------------\n",
      "train_loss tensor(3.0897, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6333, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.8467, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1149\n",
      "-------------------------------\n",
      "train_loss tensor(3.1375, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6101, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.0737, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1150\n",
      "-------------------------------\n",
      "train_loss tensor(3.1039, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6725, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.9605, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1151\n",
      "-------------------------------\n",
      "train_loss tensor(3.0867, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6432, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.0154, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1152\n",
      "-------------------------------\n",
      "train_loss tensor(3.0807, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6475, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.9106, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1153\n",
      "-------------------------------\n",
      "train_loss tensor(3.0911, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6429, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.0507, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1154\n",
      "-------------------------------\n",
      "train_loss tensor(3.0901, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5717, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.4030, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1155\n",
      "-------------------------------\n",
      "train_loss tensor(3.1174, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7485, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.7802, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1156\n",
      "-------------------------------\n",
      "train_loss tensor(3.1123, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6664, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.9780, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1157\n",
      "-------------------------------\n",
      "train_loss tensor(3.0725, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6726, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.7202, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1158\n",
      "-------------------------------\n",
      "train_loss tensor(3.0956, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6037, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.9833, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1159\n",
      "-------------------------------\n",
      "train_loss tensor(3.0650, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6816, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.8760, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1160\n",
      "-------------------------------\n",
      "train_loss tensor(3.0659, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6450, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.7259, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1161\n",
      "-------------------------------\n",
      "train_loss tensor(3.0769, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6063, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.9112, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1162\n",
      "-------------------------------\n",
      "train_loss tensor(3.0986, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6797, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.9398, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1163\n",
      "-------------------------------\n",
      "train_loss tensor(3.0738, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5692, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.2168, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1164\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(3.1035, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6920, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.8113, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1165\n",
      "-------------------------------\n",
      "train_loss tensor(3.0643, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6052, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.9591, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1166\n",
      "-------------------------------\n",
      "train_loss tensor(3.0592, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6495, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.1112, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1167\n",
      "-------------------------------\n",
      "train_loss tensor(3.0725, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6445, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.1087, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1168\n",
      "-------------------------------\n",
      "train_loss tensor(3.0498, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6230, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.0107, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1169\n",
      "-------------------------------\n",
      "train_loss tensor(3.0679, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6251, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.9200, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1170\n",
      "-------------------------------\n",
      "train_loss tensor(3.0475, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6590, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.9927, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1171\n",
      "-------------------------------\n",
      "train_loss tensor(3.0431, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5878, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.3424, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1172\n",
      "-------------------------------\n",
      "train_loss tensor(3.0591, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6908, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.8495, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1173\n",
      "-------------------------------\n",
      "train_loss tensor(3.0420, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6197, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.3285, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1174\n",
      "-------------------------------\n",
      "train_loss tensor(3.0569, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6756, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.9718, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1175\n",
      "-------------------------------\n",
      "train_loss tensor(3.0446, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6331, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.9669, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1176\n",
      "-------------------------------\n",
      "train_loss tensor(3.0232, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6201, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(6.9695, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1177\n",
      "-------------------------------\n",
      "train_loss tensor(3.0270, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6105, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.0677, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1178\n",
      "-------------------------------\n",
      "train_loss tensor(3.0317, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6175, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.1659, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1179\n",
      "-------------------------------\n",
      "train_loss tensor(3.0277, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6046, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.0176, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1180\n",
      "-------------------------------\n",
      "train_loss tensor(3.0148, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6444, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.1422, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1181\n",
      "-------------------------------\n",
      "train_loss tensor(3.0186, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5876, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.1132, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1182\n",
      "-------------------------------\n",
      "train_loss tensor(3.0314, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6780, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.1248, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1183\n",
      "-------------------------------\n",
      "train_loss tensor(3.0250, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6166, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.0414, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1184\n",
      "-------------------------------\n",
      "train_loss tensor(3.0068, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5819, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.3006, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1185\n",
      "-------------------------------\n",
      "train_loss tensor(3.0036, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6131, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.1558, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1186\n",
      "-------------------------------\n",
      "train_loss tensor(3.0019, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6660, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.0959, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1187\n",
      "-------------------------------\n",
      "train_loss tensor(2.9951, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6207, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.1570, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1188\n",
      "-------------------------------\n",
      "train_loss tensor(3.0266, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6346, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.3412, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1189\n",
      "-------------------------------\n",
      "train_loss tensor(3.0424, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5858, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.4652, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1190\n",
      "-------------------------------\n",
      "train_loss tensor(3.0415, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6214, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(7.0532, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1191\n",
      "-------------------------------\n",
      "train_loss tensor(3.0064, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6586, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.5330, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1192\n",
      "-------------------------------\n",
      "train_loss tensor(3.0276, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5639, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.4764, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1193\n",
      "-------------------------------\n",
      "train_loss tensor(3.0551, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7105, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.1790, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1194\n",
      "-------------------------------\n",
      "train_loss tensor(3.0272, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5721, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.1361, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1195\n",
      "-------------------------------\n",
      "train_loss tensor(3.0021, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6259, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.3424, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1196\n",
      "-------------------------------\n",
      "train_loss tensor(2.9969, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6515, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.2110, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1197\n",
      "-------------------------------\n",
      "train_loss tensor(3.0073, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6225, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.1289, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1198\n",
      "-------------------------------\n",
      "train_loss tensor(3.0311, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5867, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7189, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1199\n",
      "-------------------------------\n",
      "train_loss tensor(3.0267, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6869, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.3623, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1200\n",
      "-------------------------------\n",
      "train_loss tensor(3.0618, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6468, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.1341, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1201\n",
      "-------------------------------\n",
      "train_loss tensor(3.0153, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5579, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.5242, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1202\n",
      "-------------------------------\n",
      "train_loss tensor(3.0192, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7200, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.1324, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1203\n",
      "-------------------------------\n",
      "train_loss tensor(2.9932, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5700, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.6606, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1204\n",
      "-------------------------------\n",
      "train_loss tensor(2.9751, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6396, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.3230, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1205\n",
      "-------------------------------\n",
      "train_loss tensor(2.9667, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6082, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.2243, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1206\n",
      "-------------------------------\n",
      "train_loss tensor(2.9773, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5752, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.5549, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1207\n",
      "-------------------------------\n",
      "train_loss tensor(2.9754, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5973, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.3324, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1208\n",
      "-------------------------------\n",
      "train_loss tensor(2.9537, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6379, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.2273, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1209\n",
      "-------------------------------\n",
      "train_loss tensor(2.9582, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5983, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.4507, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1210\n",
      "-------------------------------\n",
      "train_loss tensor(2.9569, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6601, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.1700, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1211\n",
      "-------------------------------\n",
      "train_loss tensor(2.9922, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6099, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.3452, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1212\n",
      "-------------------------------\n",
      "train_loss tensor(2.9574, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5860, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.2913, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1213\n",
      "-------------------------------\n",
      "train_loss tensor(2.9532, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5603, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.6002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1214\n",
      "-------------------------------\n",
      "train_loss tensor(2.9693, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6347, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.4098, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1215\n",
      "-------------------------------\n",
      "train_loss tensor(2.9705, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5642, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.3004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1216\n",
      "-------------------------------\n",
      "train_loss tensor(2.9739, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6246, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0687, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1217\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(3.0356, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6723, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7307, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1218\n",
      "-------------------------------\n",
      "train_loss tensor(3.0203, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5670, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.3509, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1219\n",
      "-------------------------------\n",
      "train_loss tensor(3.0431, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6198, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.5342, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1220\n",
      "-------------------------------\n",
      "train_loss tensor(3.0086, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6755, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.2117, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1221\n",
      "-------------------------------\n",
      "train_loss tensor(2.9713, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5325, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7280, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1222\n",
      "-------------------------------\n",
      "train_loss tensor(2.9567, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6530, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.0987, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1223\n",
      "-------------------------------\n",
      "train_loss tensor(2.9669, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5750, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.3532, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1224\n",
      "-------------------------------\n",
      "train_loss tensor(2.9585, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6124, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.4384, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1225\n",
      "-------------------------------\n",
      "train_loss tensor(2.9748, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5715, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.2899, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1226\n",
      "-------------------------------\n",
      "train_loss tensor(2.9511, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6494, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.3058, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1227\n",
      "-------------------------------\n",
      "train_loss tensor(2.9472, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5807, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.3480, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1228\n",
      "-------------------------------\n",
      "train_loss tensor(2.9416, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5894, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.5259, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1229\n",
      "-------------------------------\n",
      "train_loss tensor(3.0218, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7566, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.0519, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1230\n",
      "-------------------------------\n",
      "train_loss tensor(3.0392, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5558, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.5173, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1231\n",
      "-------------------------------\n",
      "train_loss tensor(2.9667, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6102, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.4806, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1232\n",
      "-------------------------------\n",
      "train_loss tensor(2.9292, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6477, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.2409, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1233\n",
      "-------------------------------\n",
      "train_loss tensor(2.9288, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5788, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.5856, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1234\n",
      "-------------------------------\n",
      "train_loss tensor(2.9179, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6198, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.1560, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1235\n",
      "-------------------------------\n",
      "train_loss tensor(2.9365, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6023, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.4681, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1236\n",
      "-------------------------------\n",
      "train_loss tensor(2.9449, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5978, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.2506, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1237\n",
      "-------------------------------\n",
      "train_loss tensor(2.9859, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6201, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.5419, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1238\n",
      "-------------------------------\n",
      "train_loss tensor(2.9289, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5722, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8064, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1239\n",
      "-------------------------------\n",
      "train_loss tensor(2.9165, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5944, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.3907, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1240\n",
      "-------------------------------\n",
      "train_loss tensor(2.9052, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5888, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.5438, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1241\n",
      "-------------------------------\n",
      "train_loss tensor(2.9136, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5693, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.4161, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1242\n",
      "-------------------------------\n",
      "train_loss tensor(2.9190, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6453, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.2413, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1243\n",
      "-------------------------------\n",
      "train_loss tensor(2.9022, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5553, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(7.6685, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1244\n",
      "-------------------------------\n",
      "train_loss tensor(2.8975, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6041, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.3715, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1245\n",
      "-------------------------------\n",
      "train_loss tensor(2.8859, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5671, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.6424, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1246\n",
      "-------------------------------\n",
      "train_loss tensor(2.8977, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6155, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.4073, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1247\n",
      "-------------------------------\n",
      "train_loss tensor(2.9150, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6218, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.5035, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1248\n",
      "-------------------------------\n",
      "train_loss tensor(2.9180, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5992, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8655, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1249\n",
      "-------------------------------\n",
      "train_loss tensor(2.9477, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6543, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.4006, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1250\n",
      "-------------------------------\n",
      "train_loss tensor(2.9122, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6180, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.5038, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1251\n",
      "-------------------------------\n",
      "train_loss tensor(2.9579, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5429, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2046, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1252\n",
      "-------------------------------\n",
      "train_loss tensor(2.9458, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7534, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.4705, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1253\n",
      "-------------------------------\n",
      "train_loss tensor(2.9618, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5727, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3726, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1254\n",
      "-------------------------------\n",
      "train_loss tensor(3.0032, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6564, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.1511, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1255\n",
      "-------------------------------\n",
      "train_loss tensor(2.9920, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6309, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.6473, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1256\n",
      "-------------------------------\n",
      "train_loss tensor(2.9464, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5857, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.3293, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1257\n",
      "-------------------------------\n",
      "train_loss tensor(2.9125, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6337, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.3357, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1258\n",
      "-------------------------------\n",
      "train_loss tensor(2.9202, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6168, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.2351, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1259\n",
      "-------------------------------\n",
      "train_loss tensor(2.9216, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6066, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.4583, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1260\n",
      "-------------------------------\n",
      "train_loss tensor(2.9449, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6716, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.1740, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1261\n",
      "-------------------------------\n",
      "train_loss tensor(2.9432, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5719, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7691, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1262\n",
      "-------------------------------\n",
      "train_loss tensor(2.8827, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5839, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.3437, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1263\n",
      "-------------------------------\n",
      "train_loss tensor(2.9027, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6050, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.3592, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1264\n",
      "-------------------------------\n",
      "train_loss tensor(2.8937, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5944, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.6124, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1265\n",
      "-------------------------------\n",
      "train_loss tensor(2.9582, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7166, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.5283, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1266\n",
      "-------------------------------\n",
      "train_loss tensor(2.9747, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5511, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1349, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1267\n",
      "-------------------------------\n",
      "train_loss tensor(2.9603, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6429, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.4892, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1268\n",
      "-------------------------------\n",
      "train_loss tensor(2.9189, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6191, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7653, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1269\n",
      "-------------------------------\n",
      "train_loss tensor(2.8999, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6451, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.3414, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1270\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(2.8937, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6245, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.1564, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1271\n",
      "-------------------------------\n",
      "train_loss tensor(2.8920, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5505, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8043, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1272\n",
      "-------------------------------\n",
      "train_loss tensor(2.8885, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5616, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8415, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1273\n",
      "-------------------------------\n",
      "train_loss tensor(2.8726, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6736, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.3084, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1274\n",
      "-------------------------------\n",
      "train_loss tensor(2.8615, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5379, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.5330, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1275\n",
      "-------------------------------\n",
      "train_loss tensor(2.8960, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6329, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.2926, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1276\n",
      "-------------------------------\n",
      "train_loss tensor(2.8662, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5752, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.6208, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1277\n",
      "-------------------------------\n",
      "train_loss tensor(2.8599, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5859, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.5828, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1278\n",
      "-------------------------------\n",
      "train_loss tensor(2.8496, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6070, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.4204, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1279\n",
      "-------------------------------\n",
      "train_loss tensor(2.8549, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5465, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.5880, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1280\n",
      "-------------------------------\n",
      "train_loss tensor(2.8535, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6471, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.5069, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1281\n",
      "-------------------------------\n",
      "train_loss tensor(2.8655, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5543, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8460, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1282\n",
      "-------------------------------\n",
      "train_loss tensor(2.8692, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6533, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.4793, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1283\n",
      "-------------------------------\n",
      "train_loss tensor(2.8681, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5763, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2571, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1284\n",
      "-------------------------------\n",
      "train_loss tensor(2.9184, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6687, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.3932, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1285\n",
      "-------------------------------\n",
      "train_loss tensor(2.8715, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5546, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8615, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1286\n",
      "-------------------------------\n",
      "train_loss tensor(2.8828, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5794, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.6883, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1287\n",
      "-------------------------------\n",
      "train_loss tensor(2.8642, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6355, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.6134, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1288\n",
      "-------------------------------\n",
      "train_loss tensor(2.8672, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5203, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9974, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1289\n",
      "-------------------------------\n",
      "train_loss tensor(2.8515, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6079, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.6739, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1290\n",
      "-------------------------------\n",
      "train_loss tensor(2.8840, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5527, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8398, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1291\n",
      "-------------------------------\n",
      "train_loss tensor(2.9316, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6227, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3606, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1292\n",
      "-------------------------------\n",
      "train_loss tensor(2.9111, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5582, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8106, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1293\n",
      "-------------------------------\n",
      "train_loss tensor(2.8439, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6236, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8529, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1294\n",
      "-------------------------------\n",
      "train_loss tensor(2.8680, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5374, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8331, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1295\n",
      "-------------------------------\n",
      "train_loss tensor(2.8816, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6294, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7702, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1296\n",
      "-------------------------------\n",
      "train_loss tensor(2.8907, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6519, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(7.7676, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1297\n",
      "-------------------------------\n",
      "train_loss tensor(2.8844, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5334, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3141, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1298\n",
      "-------------------------------\n",
      "train_loss tensor(2.8430, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6910, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9372, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1299\n",
      "-------------------------------\n",
      "train_loss tensor(2.8337, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5696, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1095, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1300\n",
      "-------------------------------\n",
      "train_loss tensor(2.8187, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5947, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0373, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1301\n",
      "-------------------------------\n",
      "train_loss tensor(2.8195, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5783, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8736, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1302\n",
      "-------------------------------\n",
      "train_loss tensor(2.8349, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5843, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2942, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1303\n",
      "-------------------------------\n",
      "train_loss tensor(2.8345, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5814, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1566, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1304\n",
      "-------------------------------\n",
      "train_loss tensor(2.8649, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6965, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7284, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1305\n",
      "-------------------------------\n",
      "train_loss tensor(2.8371, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5274, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5522, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1306\n",
      "-------------------------------\n",
      "train_loss tensor(2.8251, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6756, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8575, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1307\n",
      "-------------------------------\n",
      "train_loss tensor(2.8568, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6041, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7444, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1308\n",
      "-------------------------------\n",
      "train_loss tensor(2.8188, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5439, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1409, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1309\n",
      "-------------------------------\n",
      "train_loss tensor(2.8169, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6597, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8420, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1310\n",
      "-------------------------------\n",
      "train_loss tensor(2.8348, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5390, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6272, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1311\n",
      "-------------------------------\n",
      "train_loss tensor(2.8280, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6201, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9874, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1312\n",
      "-------------------------------\n",
      "train_loss tensor(2.8319, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6305, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8233, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1313\n",
      "-------------------------------\n",
      "train_loss tensor(2.8278, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5552, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3602, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1314\n",
      "-------------------------------\n",
      "train_loss tensor(2.8348, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6588, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8752, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1315\n",
      "-------------------------------\n",
      "train_loss tensor(2.8333, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5787, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1434, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1316\n",
      "-------------------------------\n",
      "train_loss tensor(2.8260, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5801, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7448, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1317\n",
      "-------------------------------\n",
      "train_loss tensor(2.8053, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5609, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0468, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1318\n",
      "-------------------------------\n",
      "train_loss tensor(2.8032, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5524, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2259, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1319\n",
      "-------------------------------\n",
      "train_loss tensor(2.7903, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6036, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8735, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1320\n",
      "-------------------------------\n",
      "train_loss tensor(2.7959, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5800, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0405, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1321\n",
      "-------------------------------\n",
      "train_loss tensor(2.7773, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5456, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1303, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1322\n",
      "-------------------------------\n",
      "train_loss tensor(2.7802, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6126, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1242, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1323\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(2.7742, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5528, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2642, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1324\n",
      "-------------------------------\n",
      "train_loss tensor(2.7916, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6413, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9667, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1325\n",
      "-------------------------------\n",
      "train_loss tensor(2.7941, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5427, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4269, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1326\n",
      "-------------------------------\n",
      "train_loss tensor(2.7684, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5968, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0319, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1327\n",
      "-------------------------------\n",
      "train_loss tensor(2.7734, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5586, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2620, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1328\n",
      "-------------------------------\n",
      "train_loss tensor(2.7699, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5587, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2534, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1329\n",
      "-------------------------------\n",
      "train_loss tensor(2.7799, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5989, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2864, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1330\n",
      "-------------------------------\n",
      "train_loss tensor(2.7881, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6270, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1363, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1331\n",
      "-------------------------------\n",
      "train_loss tensor(2.7759, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5638, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4346, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1332\n",
      "-------------------------------\n",
      "train_loss tensor(2.7878, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6412, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1958, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1333\n",
      "-------------------------------\n",
      "train_loss tensor(2.7761, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6045, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1674, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1334\n",
      "-------------------------------\n",
      "train_loss tensor(2.7969, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6014, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3524, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1335\n",
      "-------------------------------\n",
      "train_loss tensor(2.7947, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5460, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3064, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1336\n",
      "-------------------------------\n",
      "train_loss tensor(2.7809, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6208, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2038, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1337\n",
      "-------------------------------\n",
      "train_loss tensor(2.7648, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5710, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4391, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1338\n",
      "-------------------------------\n",
      "train_loss tensor(2.7615, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5700, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2927, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1339\n",
      "-------------------------------\n",
      "train_loss tensor(2.7566, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5943, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4368, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1340\n",
      "-------------------------------\n",
      "train_loss tensor(2.7810, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5528, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6076, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1341\n",
      "-------------------------------\n",
      "train_loss tensor(2.7950, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6815, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0055, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1342\n",
      "-------------------------------\n",
      "train_loss tensor(2.7739, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5599, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6424, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1343\n",
      "-------------------------------\n",
      "train_loss tensor(2.7665, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6471, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9482, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1344\n",
      "-------------------------------\n",
      "train_loss tensor(2.7572, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5284, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4820, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1345\n",
      "-------------------------------\n",
      "train_loss tensor(2.7612, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6663, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0799, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1346\n",
      "-------------------------------\n",
      "train_loss tensor(2.7623, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6017, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3040, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1347\n",
      "-------------------------------\n",
      "train_loss tensor(2.7313, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5441, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3024, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1348\n",
      "-------------------------------\n",
      "train_loss tensor(2.7537, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6296, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1882, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1349\n",
      "-------------------------------\n",
      "train_loss tensor(2.7683, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5628, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(8.5483, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1350\n",
      "-------------------------------\n",
      "train_loss tensor(2.7563, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5898, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5423, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1351\n",
      "-------------------------------\n",
      "train_loss tensor(2.7520, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6109, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1645, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1352\n",
      "-------------------------------\n",
      "train_loss tensor(2.7731, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5484, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6745, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1353\n",
      "-------------------------------\n",
      "train_loss tensor(2.7311, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5892, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4627, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1354\n",
      "-------------------------------\n",
      "train_loss tensor(2.7354, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5484, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3944, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1355\n",
      "-------------------------------\n",
      "train_loss tensor(2.7543, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6685, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3328, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1356\n",
      "-------------------------------\n",
      "train_loss tensor(2.7606, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5790, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4202, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1357\n",
      "-------------------------------\n",
      "train_loss tensor(2.7564, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6235, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6338, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1358\n",
      "-------------------------------\n",
      "train_loss tensor(2.7689, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6052, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2497, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1359\n",
      "-------------------------------\n",
      "train_loss tensor(2.7455, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5579, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6129, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1360\n",
      "-------------------------------\n",
      "train_loss tensor(2.7481, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5623, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6870, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1361\n",
      "-------------------------------\n",
      "train_loss tensor(2.7488, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6199, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2237, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1362\n",
      "-------------------------------\n",
      "train_loss tensor(2.7350, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5527, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5221, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1363\n",
      "-------------------------------\n",
      "train_loss tensor(2.7275, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5839, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3861, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1364\n",
      "-------------------------------\n",
      "train_loss tensor(2.7253, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6035, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4007, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1365\n",
      "-------------------------------\n",
      "train_loss tensor(2.7500, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5808, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9726, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1366\n",
      "-------------------------------\n",
      "train_loss tensor(2.7399, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5822, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5184, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1367\n",
      "-------------------------------\n",
      "train_loss tensor(2.7299, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6381, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4020, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1368\n",
      "-------------------------------\n",
      "train_loss tensor(2.7439, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5670, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6479, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1369\n",
      "-------------------------------\n",
      "train_loss tensor(2.7059, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6632, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6694, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1370\n",
      "-------------------------------\n",
      "train_loss tensor(2.7195, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5937, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3990, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1371\n",
      "-------------------------------\n",
      "train_loss tensor(2.7327, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5857, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6122, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1372\n",
      "-------------------------------\n",
      "train_loss tensor(2.7447, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6518, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3619, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1373\n",
      "-------------------------------\n",
      "train_loss tensor(2.7389, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5894, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8249, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1374\n",
      "-------------------------------\n",
      "train_loss tensor(2.7216, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5672, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6373, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1375\n",
      "-------------------------------\n",
      "train_loss tensor(2.7665, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7165, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2144, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1376\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(2.7293, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5442, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7740, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1377\n",
      "-------------------------------\n",
      "train_loss tensor(2.7336, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6215, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5080, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1378\n",
      "-------------------------------\n",
      "train_loss tensor(2.6978, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5830, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6094, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1379\n",
      "-------------------------------\n",
      "train_loss tensor(2.7160, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6216, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7441, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1380\n",
      "-------------------------------\n",
      "train_loss tensor(2.7423, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6563, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2604, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1381\n",
      "-------------------------------\n",
      "train_loss tensor(2.7438, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5407, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7108, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1382\n",
      "-------------------------------\n",
      "train_loss tensor(2.7244, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6299, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6425, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1383\n",
      "-------------------------------\n",
      "train_loss tensor(2.7220, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5874, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4744, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1384\n",
      "-------------------------------\n",
      "train_loss tensor(2.6928, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6012, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5242, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1385\n",
      "-------------------------------\n",
      "train_loss tensor(2.7009, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6351, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4234, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1386\n",
      "-------------------------------\n",
      "train_loss tensor(2.7092, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6219, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9217, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1387\n",
      "-------------------------------\n",
      "train_loss tensor(2.7282, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6181, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5552, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1388\n",
      "-------------------------------\n",
      "train_loss tensor(2.7057, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6105, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6800, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1389\n",
      "-------------------------------\n",
      "train_loss tensor(2.7359, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6430, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6882, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1390\n",
      "-------------------------------\n",
      "train_loss tensor(2.7453, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6711, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.2134, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1391\n",
      "-------------------------------\n",
      "train_loss tensor(2.7675, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6263, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7934, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1392\n",
      "-------------------------------\n",
      "train_loss tensor(2.7688, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7041, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3471, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1393\n",
      "-------------------------------\n",
      "train_loss tensor(2.7323, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5694, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5266, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1394\n",
      "-------------------------------\n",
      "train_loss tensor(2.7174, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6627, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.1251, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1395\n",
      "-------------------------------\n",
      "train_loss tensor(2.7443, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5870, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8632, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1396\n",
      "-------------------------------\n",
      "train_loss tensor(2.7081, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6320, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7270, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1397\n",
      "-------------------------------\n",
      "train_loss tensor(2.6880, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6201, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3661, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1398\n",
      "-------------------------------\n",
      "train_loss tensor(2.7302, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6486, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5729, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1399\n",
      "-------------------------------\n",
      "train_loss tensor(2.7095, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5532, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8971, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1400\n",
      "-------------------------------\n",
      "train_loss tensor(2.6912, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5984, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5942, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1401\n",
      "-------------------------------\n",
      "train_loss tensor(2.6814, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5865, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5885, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1402\n",
      "-------------------------------\n",
      "train_loss tensor(2.6794, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5808, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(8.6035, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1403\n",
      "-------------------------------\n",
      "train_loss tensor(2.6833, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6424, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6804, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1404\n",
      "-------------------------------\n",
      "train_loss tensor(2.6830, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5799, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7249, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1405\n",
      "-------------------------------\n",
      "train_loss tensor(2.7029, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6064, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5851, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1406\n",
      "-------------------------------\n",
      "train_loss tensor(2.6845, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6251, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4839, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1407\n",
      "-------------------------------\n",
      "train_loss tensor(2.7186, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5288, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.0436, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1408\n",
      "-------------------------------\n",
      "train_loss tensor(2.7090, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6515, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6070, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1409\n",
      "-------------------------------\n",
      "train_loss tensor(2.7305, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6477, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7381, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1410\n",
      "-------------------------------\n",
      "train_loss tensor(2.7354, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6111, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.7748, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1411\n",
      "-------------------------------\n",
      "train_loss tensor(2.7992, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6227, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1412\n",
      "-------------------------------\n",
      "train_loss tensor(2.7322, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6635, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.0845, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1413\n",
      "-------------------------------\n",
      "train_loss tensor(2.7152, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6146, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7038, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1414\n",
      "-------------------------------\n",
      "train_loss tensor(2.7167, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6971, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4761, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1415\n",
      "-------------------------------\n",
      "train_loss tensor(2.7183, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5401, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8187, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1416\n",
      "-------------------------------\n",
      "train_loss tensor(2.7198, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8295, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1417\n",
      "-------------------------------\n",
      "train_loss tensor(2.7068, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6541, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5049, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1418\n",
      "-------------------------------\n",
      "train_loss tensor(2.7233, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5853, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9817, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1419\n",
      "-------------------------------\n",
      "train_loss tensor(2.6706, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6943, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4455, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1420\n",
      "-------------------------------\n",
      "train_loss tensor(2.6980, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5598, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9917, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1421\n",
      "-------------------------------\n",
      "train_loss tensor(2.6683, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6479, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3067, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1422\n",
      "-------------------------------\n",
      "train_loss tensor(2.6516, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5646, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5859, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1423\n",
      "-------------------------------\n",
      "train_loss tensor(2.6565, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6717, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4538, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1424\n",
      "-------------------------------\n",
      "train_loss tensor(2.6506, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5893, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1425\n",
      "-------------------------------\n",
      "train_loss tensor(2.6531, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6296, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7035, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1426\n",
      "-------------------------------\n",
      "train_loss tensor(2.6637, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6526, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5610, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1427\n",
      "-------------------------------\n",
      "train_loss tensor(2.6630, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5649, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.0602, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1428\n",
      "-------------------------------\n",
      "train_loss tensor(2.6527, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6822, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5031, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1429\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(2.7022, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6362, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9621, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1430\n",
      "-------------------------------\n",
      "train_loss tensor(2.6770, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6611, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9126, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1431\n",
      "-------------------------------\n",
      "train_loss tensor(2.6864, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6268, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5645, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1432\n",
      "-------------------------------\n",
      "train_loss tensor(2.6545, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6178, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8474, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1433\n",
      "-------------------------------\n",
      "train_loss tensor(2.6617, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5993, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6366, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1434\n",
      "-------------------------------\n",
      "train_loss tensor(2.6600, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6327, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7993, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1435\n",
      "-------------------------------\n",
      "train_loss tensor(2.6434, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6738, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8217, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1436\n",
      "-------------------------------\n",
      "train_loss tensor(2.6647, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6098, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7892, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1437\n",
      "-------------------------------\n",
      "train_loss tensor(2.6457, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6428, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5425, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1438\n",
      "-------------------------------\n",
      "train_loss tensor(2.6465, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6210, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7804, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1439\n",
      "-------------------------------\n",
      "train_loss tensor(2.6578, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6133, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7723, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1440\n",
      "-------------------------------\n",
      "train_loss tensor(2.6352, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6059, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7849, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1441\n",
      "-------------------------------\n",
      "train_loss tensor(2.6453, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6673, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9081, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1442\n",
      "-------------------------------\n",
      "train_loss tensor(2.6654, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6277, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6159, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1443\n",
      "-------------------------------\n",
      "train_loss tensor(2.6634, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6257, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7085, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1444\n",
      "-------------------------------\n",
      "train_loss tensor(2.6826, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7275, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5571, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1445\n",
      "-------------------------------\n",
      "train_loss tensor(2.7057, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5772, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.1210, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1446\n",
      "-------------------------------\n",
      "train_loss tensor(2.6709, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7166, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7044, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1447\n",
      "-------------------------------\n",
      "train_loss tensor(2.6598, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5869, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.2002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1448\n",
      "-------------------------------\n",
      "train_loss tensor(2.6780, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6467, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.1515, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1449\n",
      "-------------------------------\n",
      "train_loss tensor(2.6384, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6507, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9535, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1450\n",
      "-------------------------------\n",
      "train_loss tensor(2.6478, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5687, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.5003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1451\n",
      "-------------------------------\n",
      "train_loss tensor(2.6386, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6611, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7945, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1452\n",
      "-------------------------------\n",
      "train_loss tensor(2.6145, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6323, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8111, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1453\n",
      "-------------------------------\n",
      "train_loss tensor(2.6108, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6047, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7018, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1454\n",
      "-------------------------------\n",
      "train_loss tensor(2.6128, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6606, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5615, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1455\n",
      "-------------------------------\n",
      "train_loss tensor(2.6176, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6125, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(8.9638, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1456\n",
      "-------------------------------\n",
      "train_loss tensor(2.6238, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6397, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7301, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1457\n",
      "-------------------------------\n",
      "train_loss tensor(2.6184, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6483, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6972, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1458\n",
      "-------------------------------\n",
      "train_loss tensor(2.6342, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6141, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7506, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1459\n",
      "-------------------------------\n",
      "train_loss tensor(2.6204, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6299, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7656, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1460\n",
      "-------------------------------\n",
      "train_loss tensor(2.5956, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5927, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.0499, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1461\n",
      "-------------------------------\n",
      "train_loss tensor(2.6242, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7034, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6510, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1462\n",
      "-------------------------------\n",
      "train_loss tensor(2.6333, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6433, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8377, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1463\n",
      "-------------------------------\n",
      "train_loss tensor(2.6205, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6488, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9763, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1464\n",
      "-------------------------------\n",
      "train_loss tensor(2.6246, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6534, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6308, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1465\n",
      "-------------------------------\n",
      "train_loss tensor(2.6185, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6548, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7954, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1466\n",
      "-------------------------------\n",
      "train_loss tensor(2.6164, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6125, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9387, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1467\n",
      "-------------------------------\n",
      "train_loss tensor(2.6159, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6224, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8332, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1468\n",
      "-------------------------------\n",
      "train_loss tensor(2.6362, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6868, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7803, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1469\n",
      "-------------------------------\n",
      "train_loss tensor(2.6339, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5836, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.0469, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1470\n",
      "-------------------------------\n",
      "train_loss tensor(2.6152, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7457, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4661, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1471\n",
      "-------------------------------\n",
      "train_loss tensor(2.6887, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6019, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8051, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1472\n",
      "-------------------------------\n",
      "train_loss tensor(2.7061, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6667, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9496, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1473\n",
      "-------------------------------\n",
      "train_loss tensor(2.6639, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5994, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8726, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1474\n",
      "-------------------------------\n",
      "train_loss tensor(2.6433, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6326, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7962, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1475\n",
      "-------------------------------\n",
      "train_loss tensor(2.6253, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6839, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8921, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1476\n",
      "-------------------------------\n",
      "train_loss tensor(2.6500, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6239, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.0923, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1477\n",
      "-------------------------------\n",
      "train_loss tensor(2.6467, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6741, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9294, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1478\n",
      "-------------------------------\n",
      "train_loss tensor(2.6169, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6187, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8746, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1479\n",
      "-------------------------------\n",
      "train_loss tensor(2.6348, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6948, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4032, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1480\n",
      "-------------------------------\n",
      "train_loss tensor(2.6249, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.5997, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.6161, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1481\n",
      "-------------------------------\n",
      "train_loss tensor(2.6362, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7059, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7618, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1482\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(2.6499, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6022, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6492, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1483\n",
      "-------------------------------\n",
      "train_loss tensor(2.5959, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6608, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5418, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1484\n",
      "-------------------------------\n",
      "train_loss tensor(2.6253, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6724, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7612, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1485\n",
      "-------------------------------\n",
      "train_loss tensor(2.5807, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6413, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8828, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1486\n",
      "-------------------------------\n",
      "train_loss tensor(2.5831, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6493, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9785, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1487\n",
      "-------------------------------\n",
      "train_loss tensor(2.5923, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6495, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6477, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1488\n",
      "-------------------------------\n",
      "train_loss tensor(2.6032, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6596, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4932, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1489\n",
      "-------------------------------\n",
      "train_loss tensor(2.6049, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6134, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.1071, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1490\n",
      "-------------------------------\n",
      "train_loss tensor(2.6009, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7376, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1491\n",
      "-------------------------------\n",
      "train_loss tensor(2.5912, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6176, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9563, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1492\n",
      "-------------------------------\n",
      "train_loss tensor(2.5845, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6924, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3999, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1493\n",
      "-------------------------------\n",
      "train_loss tensor(2.5704, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.0068, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1494\n",
      "-------------------------------\n",
      "train_loss tensor(2.5705, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7327, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6396, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1495\n",
      "-------------------------------\n",
      "train_loss tensor(2.6009, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.2989, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1496\n",
      "-------------------------------\n",
      "train_loss tensor(2.5680, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6955, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6214, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1497\n",
      "-------------------------------\n",
      "train_loss tensor(2.5725, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6486, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5242, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1498\n",
      "-------------------------------\n",
      "train_loss tensor(2.5720, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6364, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4678, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1499\n",
      "-------------------------------\n",
      "train_loss tensor(2.5688, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6455, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8690, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1500\n",
      "-------------------------------\n",
      "train_loss tensor(2.5709, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6898, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4771, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1501\n",
      "-------------------------------\n",
      "train_loss tensor(2.5593, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6375, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3439, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1502\n",
      "-------------------------------\n",
      "train_loss tensor(2.5664, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7196, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1764, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1503\n",
      "-------------------------------\n",
      "train_loss tensor(2.5515, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6515, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9433, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1504\n",
      "-------------------------------\n",
      "train_loss tensor(2.5701, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6558, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6943, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1505\n",
      "-------------------------------\n",
      "train_loss tensor(2.5575, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6631, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5442, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1506\n",
      "-------------------------------\n",
      "train_loss tensor(2.5672, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6393, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8427, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1507\n",
      "-------------------------------\n",
      "train_loss tensor(2.5592, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6678, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8246, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1508\n",
      "-------------------------------\n",
      "train_loss tensor(2.5579, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6727, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(8.6773, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1509\n",
      "-------------------------------\n",
      "train_loss tensor(2.5457, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6203, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7840, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1510\n",
      "-------------------------------\n",
      "train_loss tensor(2.5750, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6941, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5386, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1511\n",
      "-------------------------------\n",
      "train_loss tensor(2.5589, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6347, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8689, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1512\n",
      "-------------------------------\n",
      "train_loss tensor(2.5457, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6535, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7071, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1513\n",
      "-------------------------------\n",
      "train_loss tensor(2.5488, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6845, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6475, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1514\n",
      "-------------------------------\n",
      "train_loss tensor(2.5390, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6395, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6160, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1515\n",
      "-------------------------------\n",
      "train_loss tensor(2.5441, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6217, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7933, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1516\n",
      "-------------------------------\n",
      "train_loss tensor(2.5663, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6814, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6415, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1517\n",
      "-------------------------------\n",
      "train_loss tensor(2.5472, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6385, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7052, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1518\n",
      "-------------------------------\n",
      "train_loss tensor(2.5428, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6905, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5554, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1519\n",
      "-------------------------------\n",
      "train_loss tensor(2.5463, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6364, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8748, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1520\n",
      "-------------------------------\n",
      "train_loss tensor(2.5445, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6970, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7693, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1521\n",
      "-------------------------------\n",
      "train_loss tensor(2.5451, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6465, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7705, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1522\n",
      "-------------------------------\n",
      "train_loss tensor(2.5496, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6263, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8500, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1523\n",
      "-------------------------------\n",
      "train_loss tensor(2.5498, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6886, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5641, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1524\n",
      "-------------------------------\n",
      "train_loss tensor(2.5581, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6429, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.0811, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1525\n",
      "-------------------------------\n",
      "train_loss tensor(2.5680, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6979, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5407, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1526\n",
      "-------------------------------\n",
      "train_loss tensor(2.5808, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7243, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.2298, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1527\n",
      "-------------------------------\n",
      "train_loss tensor(2.5940, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6844, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6740, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1528\n",
      "-------------------------------\n",
      "train_loss tensor(2.5933, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6776, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7597, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1529\n",
      "-------------------------------\n",
      "train_loss tensor(2.6000, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6737, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8069, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1530\n",
      "-------------------------------\n",
      "train_loss tensor(2.6051, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6999, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5138, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1531\n",
      "-------------------------------\n",
      "train_loss tensor(2.5740, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6393, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7441, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1532\n",
      "-------------------------------\n",
      "train_loss tensor(2.5461, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6614, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7261, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1533\n",
      "-------------------------------\n",
      "train_loss tensor(2.5455, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6780, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7175, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1534\n",
      "-------------------------------\n",
      "train_loss tensor(2.5434, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6329, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.0232, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1535\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(2.5284, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7053, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7221, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1536\n",
      "-------------------------------\n",
      "train_loss tensor(2.5315, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6625, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7968, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1537\n",
      "-------------------------------\n",
      "train_loss tensor(2.5359, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6751, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6690, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1538\n",
      "-------------------------------\n",
      "train_loss tensor(2.5351, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6601, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7138, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1539\n",
      "-------------------------------\n",
      "train_loss tensor(2.5505, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7259, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4446, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1540\n",
      "-------------------------------\n",
      "train_loss tensor(2.5516, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6638, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8008, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1541\n",
      "-------------------------------\n",
      "train_loss tensor(2.5668, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6759, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9008, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1542\n",
      "-------------------------------\n",
      "train_loss tensor(2.5793, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6960, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4829, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1543\n",
      "-------------------------------\n",
      "train_loss tensor(2.5908, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6699, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7991, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1544\n",
      "-------------------------------\n",
      "train_loss tensor(2.6467, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8011, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6496, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1545\n",
      "-------------------------------\n",
      "train_loss tensor(2.5717, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6488, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.0702, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1546\n",
      "-------------------------------\n",
      "train_loss tensor(2.5809, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7567, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5656, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1547\n",
      "-------------------------------\n",
      "train_loss tensor(2.5472, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6321, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7652, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1548\n",
      "-------------------------------\n",
      "train_loss tensor(2.5556, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7033, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4053, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1549\n",
      "-------------------------------\n",
      "train_loss tensor(2.5390, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6885, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4963, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1550\n",
      "-------------------------------\n",
      "train_loss tensor(2.5538, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6292, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.2392, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1551\n",
      "-------------------------------\n",
      "train_loss tensor(2.5493, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7514, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3139, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1552\n",
      "-------------------------------\n",
      "train_loss tensor(2.5387, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6251, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8676, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1553\n",
      "-------------------------------\n",
      "train_loss tensor(2.5388, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7183, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4074, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1554\n",
      "-------------------------------\n",
      "train_loss tensor(2.5165, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6470, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6280, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1555\n",
      "-------------------------------\n",
      "train_loss tensor(2.5113, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6840, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5629, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1556\n",
      "-------------------------------\n",
      "train_loss tensor(2.5242, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6833, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3862, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1557\n",
      "-------------------------------\n",
      "train_loss tensor(2.5112, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6842, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6403, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1558\n",
      "-------------------------------\n",
      "train_loss tensor(2.5115, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6885, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6100, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1559\n",
      "-------------------------------\n",
      "train_loss tensor(2.5064, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6640, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4809, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1560\n",
      "-------------------------------\n",
      "train_loss tensor(2.4987, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6628, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4382, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1561\n",
      "-------------------------------\n",
      "train_loss tensor(2.5134, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6792, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(8.6400, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1562\n",
      "-------------------------------\n",
      "train_loss tensor(2.5512, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7068, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5249, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1563\n",
      "-------------------------------\n",
      "train_loss tensor(2.5166, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6970, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7092, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1564\n",
      "-------------------------------\n",
      "train_loss tensor(2.4918, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6510, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5803, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1565\n",
      "-------------------------------\n",
      "train_loss tensor(2.5256, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7196, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3664, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1566\n",
      "-------------------------------\n",
      "train_loss tensor(2.5257, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6410, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6494, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1567\n",
      "-------------------------------\n",
      "train_loss tensor(2.5161, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7843, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1629, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1568\n",
      "-------------------------------\n",
      "train_loss tensor(2.5400, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6671, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3606, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1569\n",
      "-------------------------------\n",
      "train_loss tensor(2.5272, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6592, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5711, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1570\n",
      "-------------------------------\n",
      "train_loss tensor(2.5088, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6812, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7844, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1571\n",
      "-------------------------------\n",
      "train_loss tensor(2.5140, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6928, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5216, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1572\n",
      "-------------------------------\n",
      "train_loss tensor(2.5274, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7352, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5565, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1573\n",
      "-------------------------------\n",
      "train_loss tensor(2.4910, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6519, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6973, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1574\n",
      "-------------------------------\n",
      "train_loss tensor(2.5026, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6996, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7742, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1575\n",
      "-------------------------------\n",
      "train_loss tensor(2.4943, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6585, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7499, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1576\n",
      "-------------------------------\n",
      "train_loss tensor(2.4863, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7217, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6436, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1577\n",
      "-------------------------------\n",
      "train_loss tensor(2.5063, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7065, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7351, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1578\n",
      "-------------------------------\n",
      "train_loss tensor(2.4883, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6745, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7266, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1579\n",
      "-------------------------------\n",
      "train_loss tensor(2.4916, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6674, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6871, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1580\n",
      "-------------------------------\n",
      "train_loss tensor(2.4901, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7088, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5255, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1581\n",
      "-------------------------------\n",
      "train_loss tensor(2.4914, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6635, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9823, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1582\n",
      "-------------------------------\n",
      "train_loss tensor(2.4941, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7511, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5444, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1583\n",
      "-------------------------------\n",
      "train_loss tensor(2.5053, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6670, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8643, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1584\n",
      "-------------------------------\n",
      "train_loss tensor(2.5070, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6855, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6120, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1585\n",
      "-------------------------------\n",
      "train_loss tensor(2.4901, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7217, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6592, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1586\n",
      "-------------------------------\n",
      "train_loss tensor(2.4970, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6731, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6534, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1587\n",
      "-------------------------------\n",
      "train_loss tensor(2.5329, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7157, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7447, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1588\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(2.5126, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6853, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7558, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1589\n",
      "-------------------------------\n",
      "train_loss tensor(2.4962, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6957, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7372, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1590\n",
      "-------------------------------\n",
      "train_loss tensor(2.4759, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7143, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9663, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1591\n",
      "-------------------------------\n",
      "train_loss tensor(2.5072, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6745, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6772, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1592\n",
      "-------------------------------\n",
      "train_loss tensor(2.4763, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7072, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7641, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1593\n",
      "-------------------------------\n",
      "train_loss tensor(2.5066, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6841, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9175, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1594\n",
      "-------------------------------\n",
      "train_loss tensor(2.4923, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7310, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6461, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1595\n",
      "-------------------------------\n",
      "train_loss tensor(2.4943, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7033, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7302, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1596\n",
      "-------------------------------\n",
      "train_loss tensor(2.4963, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7608, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7473, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1597\n",
      "-------------------------------\n",
      "train_loss tensor(2.5105, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6505, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8751, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1598\n",
      "-------------------------------\n",
      "train_loss tensor(2.5216, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7299, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6132, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1599\n",
      "-------------------------------\n",
      "train_loss tensor(2.5040, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6498, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9229, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1600\n",
      "-------------------------------\n",
      "train_loss tensor(2.5396, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7703, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5817, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1601\n",
      "-------------------------------\n",
      "train_loss tensor(2.4784, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7179, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6767, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1602\n",
      "-------------------------------\n",
      "train_loss tensor(2.4825, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6609, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5859, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1603\n",
      "-------------------------------\n",
      "train_loss tensor(2.4626, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7383, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5047, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1604\n",
      "-------------------------------\n",
      "train_loss tensor(2.4897, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6417, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9317, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1605\n",
      "-------------------------------\n",
      "train_loss tensor(2.4722, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6914, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6415, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1606\n",
      "-------------------------------\n",
      "train_loss tensor(2.4599, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7115, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7095, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1607\n",
      "-------------------------------\n",
      "train_loss tensor(2.4762, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7109, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9258, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1608\n",
      "-------------------------------\n",
      "train_loss tensor(2.4471, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7265, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5452, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1609\n",
      "-------------------------------\n",
      "train_loss tensor(2.4667, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6614, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9322, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1610\n",
      "-------------------------------\n",
      "train_loss tensor(2.4622, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6986, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6186, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1611\n",
      "-------------------------------\n",
      "train_loss tensor(2.4653, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6696, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7139, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1612\n",
      "-------------------------------\n",
      "train_loss tensor(2.4658, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7217, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7141, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1613\n",
      "-------------------------------\n",
      "train_loss tensor(2.4924, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7392, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8687, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1614\n",
      "-------------------------------\n",
      "train_loss tensor(2.5104, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8305, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(8.4018, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1615\n",
      "-------------------------------\n",
      "train_loss tensor(2.5202, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6877, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.0238, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1616\n",
      "-------------------------------\n",
      "train_loss tensor(2.5095, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6814, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8174, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1617\n",
      "-------------------------------\n",
      "train_loss tensor(2.4973, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7935, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4980, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1618\n",
      "-------------------------------\n",
      "train_loss tensor(2.4930, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6619, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5222, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1619\n",
      "-------------------------------\n",
      "train_loss tensor(2.4865, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7974, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3530, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1620\n",
      "-------------------------------\n",
      "train_loss tensor(2.4946, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6323, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8043, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1621\n",
      "-------------------------------\n",
      "train_loss tensor(2.4680, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7403, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5972, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1622\n",
      "-------------------------------\n",
      "train_loss tensor(2.4543, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6923, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7770, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1623\n",
      "-------------------------------\n",
      "train_loss tensor(2.4614, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7314, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8208, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1624\n",
      "-------------------------------\n",
      "train_loss tensor(2.4566, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7449, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5971, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1625\n",
      "-------------------------------\n",
      "train_loss tensor(2.4489, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7067, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7111, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1626\n",
      "-------------------------------\n",
      "train_loss tensor(2.4394, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7232, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5914, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1627\n",
      "-------------------------------\n",
      "train_loss tensor(2.4571, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6958, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6647, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1628\n",
      "-------------------------------\n",
      "train_loss tensor(2.4577, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6985, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6022, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1629\n",
      "-------------------------------\n",
      "train_loss tensor(2.5128, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7689, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7833, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1630\n",
      "-------------------------------\n",
      "train_loss tensor(2.5338, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7176, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5390, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1631\n",
      "-------------------------------\n",
      "train_loss tensor(2.5212, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7356, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3495, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1632\n",
      "-------------------------------\n",
      "train_loss tensor(2.4894, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6385, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.3673, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1633\n",
      "-------------------------------\n",
      "train_loss tensor(2.4928, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8021, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3437, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1634\n",
      "-------------------------------\n",
      "train_loss tensor(2.4871, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6337, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6259, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1635\n",
      "-------------------------------\n",
      "train_loss tensor(2.4730, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6670, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7287, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1636\n",
      "-------------------------------\n",
      "train_loss tensor(2.4665, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7217, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5236, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1637\n",
      "-------------------------------\n",
      "train_loss tensor(2.4658, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7180, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7943, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1638\n",
      "-------------------------------\n",
      "train_loss tensor(2.4727, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7288, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3050, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1639\n",
      "-------------------------------\n",
      "train_loss tensor(2.4344, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6653, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5664, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1640\n",
      "-------------------------------\n",
      "train_loss tensor(2.4395, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6728, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6236, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1641\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(2.4312, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6786, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5793, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1642\n",
      "-------------------------------\n",
      "train_loss tensor(2.4268, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7141, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5324, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1643\n",
      "-------------------------------\n",
      "train_loss tensor(2.4320, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7086, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6663, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1644\n",
      "-------------------------------\n",
      "train_loss tensor(2.4194, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6770, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7048, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1645\n",
      "-------------------------------\n",
      "train_loss tensor(2.4268, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7185, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7570, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1646\n",
      "-------------------------------\n",
      "train_loss tensor(2.4764, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6990, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4608, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1647\n",
      "-------------------------------\n",
      "train_loss tensor(2.4631, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7007, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7780, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1648\n",
      "-------------------------------\n",
      "train_loss tensor(2.4410, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7028, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5582, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1649\n",
      "-------------------------------\n",
      "train_loss tensor(2.4246, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6609, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5902, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1650\n",
      "-------------------------------\n",
      "train_loss tensor(2.4282, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7278, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4643, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1651\n",
      "-------------------------------\n",
      "train_loss tensor(2.4426, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6823, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6659, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1652\n",
      "-------------------------------\n",
      "train_loss tensor(2.4767, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7203, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6350, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1653\n",
      "-------------------------------\n",
      "train_loss tensor(2.4763, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6829, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7155, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1654\n",
      "-------------------------------\n",
      "train_loss tensor(2.4678, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6718, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5562, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1655\n",
      "-------------------------------\n",
      "train_loss tensor(2.4446, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7028, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7227, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1656\n",
      "-------------------------------\n",
      "train_loss tensor(2.4302, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7091, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4932, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1657\n",
      "-------------------------------\n",
      "train_loss tensor(2.4342, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7065, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4841, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1658\n",
      "-------------------------------\n",
      "train_loss tensor(2.4232, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6765, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6126, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1659\n",
      "-------------------------------\n",
      "train_loss tensor(2.4537, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7629, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4744, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1660\n",
      "-------------------------------\n",
      "train_loss tensor(2.4333, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6669, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6586, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1661\n",
      "-------------------------------\n",
      "train_loss tensor(2.4156, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7704, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4815, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1662\n",
      "-------------------------------\n",
      "train_loss tensor(2.4263, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6483, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8761, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1663\n",
      "-------------------------------\n",
      "train_loss tensor(2.4208, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7928, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4412, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1664\n",
      "-------------------------------\n",
      "train_loss tensor(2.4286, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6567, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8105, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1665\n",
      "-------------------------------\n",
      "train_loss tensor(2.4403, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7813, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3030, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1666\n",
      "-------------------------------\n",
      "train_loss tensor(2.4343, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6710, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6213, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1667\n",
      "-------------------------------\n",
      "train_loss tensor(2.4142, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7084, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(8.5256, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1668\n",
      "-------------------------------\n",
      "train_loss tensor(2.4058, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6904, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5455, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1669\n",
      "-------------------------------\n",
      "train_loss tensor(2.4183, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7024, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5093, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1670\n",
      "-------------------------------\n",
      "train_loss tensor(2.4216, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6988, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5232, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1671\n",
      "-------------------------------\n",
      "train_loss tensor(2.4281, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7189, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4579, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1672\n",
      "-------------------------------\n",
      "train_loss tensor(2.4222, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7262, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5403, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1673\n",
      "-------------------------------\n",
      "train_loss tensor(2.4100, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6603, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5026, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1674\n",
      "-------------------------------\n",
      "train_loss tensor(2.4221, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7427, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4836, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1675\n",
      "-------------------------------\n",
      "train_loss tensor(2.4233, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7053, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5989, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1676\n",
      "-------------------------------\n",
      "train_loss tensor(2.3926, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7144, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4404, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1677\n",
      "-------------------------------\n",
      "train_loss tensor(2.4112, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7211, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2886, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1678\n",
      "-------------------------------\n",
      "train_loss tensor(2.4266, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6707, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5088, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1679\n",
      "-------------------------------\n",
      "train_loss tensor(2.4073, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7069, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4467, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1680\n",
      "-------------------------------\n",
      "train_loss tensor(2.4037, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7141, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3760, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1681\n",
      "-------------------------------\n",
      "train_loss tensor(2.4152, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7095, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4713, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1682\n",
      "-------------------------------\n",
      "train_loss tensor(2.4124, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7120, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7296, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1683\n",
      "-------------------------------\n",
      "train_loss tensor(2.4802, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7364, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4699, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1684\n",
      "-------------------------------\n",
      "train_loss tensor(2.4575, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7366, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5094, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1685\n",
      "-------------------------------\n",
      "train_loss tensor(2.4219, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6731, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5412, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1686\n",
      "-------------------------------\n",
      "train_loss tensor(2.4235, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8355, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6250, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1687\n",
      "-------------------------------\n",
      "train_loss tensor(2.4267, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7236, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.0240, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1688\n",
      "-------------------------------\n",
      "train_loss tensor(2.4294, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7452, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8237, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1689\n",
      "-------------------------------\n",
      "train_loss tensor(2.4098, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6674, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8720, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1690\n",
      "-------------------------------\n",
      "train_loss tensor(2.3942, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7863, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5143, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1691\n",
      "-------------------------------\n",
      "train_loss tensor(2.4095, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7072, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6855, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1692\n",
      "-------------------------------\n",
      "train_loss tensor(2.4292, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7538, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7043, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1693\n",
      "-------------------------------\n",
      "train_loss tensor(2.4156, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6701, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8747, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1694\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(2.4072, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7047, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6136, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1695\n",
      "-------------------------------\n",
      "train_loss tensor(2.4185, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7671, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6231, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1696\n",
      "-------------------------------\n",
      "train_loss tensor(2.4321, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6768, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.1728, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1697\n",
      "-------------------------------\n",
      "train_loss tensor(2.4083, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7296, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5573, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1698\n",
      "-------------------------------\n",
      "train_loss tensor(2.4046, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7094, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6272, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1699\n",
      "-------------------------------\n",
      "train_loss tensor(2.3934, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7031, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7059, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1700\n",
      "-------------------------------\n",
      "train_loss tensor(2.3858, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7198, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5725, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1701\n",
      "-------------------------------\n",
      "train_loss tensor(2.4175, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6740, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6379, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1702\n",
      "-------------------------------\n",
      "train_loss tensor(2.4172, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7082, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5999, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1703\n",
      "-------------------------------\n",
      "train_loss tensor(2.4006, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7323, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8056, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1704\n",
      "-------------------------------\n",
      "train_loss tensor(2.4037, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6908, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6341, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1705\n",
      "-------------------------------\n",
      "train_loss tensor(2.3908, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7062, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6385, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1706\n",
      "-------------------------------\n",
      "train_loss tensor(2.3892, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6776, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7712, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1707\n",
      "-------------------------------\n",
      "train_loss tensor(2.3863, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7942, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5115, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1708\n",
      "-------------------------------\n",
      "train_loss tensor(2.4074, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6662, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.1869, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1709\n",
      "-------------------------------\n",
      "train_loss tensor(2.4082, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6986, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6694, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1710\n",
      "-------------------------------\n",
      "train_loss tensor(2.3985, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7206, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6395, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1711\n",
      "-------------------------------\n",
      "train_loss tensor(2.3855, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7312, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7613, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1712\n",
      "-------------------------------\n",
      "train_loss tensor(2.3844, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6890, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6244, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1713\n",
      "-------------------------------\n",
      "train_loss tensor(2.3756, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7198, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5700, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1714\n",
      "-------------------------------\n",
      "train_loss tensor(2.3718, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6957, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7226, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1715\n",
      "-------------------------------\n",
      "train_loss tensor(2.3656, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7293, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5944, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1716\n",
      "-------------------------------\n",
      "train_loss tensor(2.3730, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7015, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7377, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1717\n",
      "-------------------------------\n",
      "train_loss tensor(2.3658, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6933, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5858, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1718\n",
      "-------------------------------\n",
      "train_loss tensor(2.3843, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7236, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7650, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1719\n",
      "-------------------------------\n",
      "train_loss tensor(2.3620, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7081, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8432, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1720\n",
      "-------------------------------\n",
      "train_loss tensor(2.3569, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7305, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(8.7424, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1721\n",
      "-------------------------------\n",
      "train_loss tensor(2.3840, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6861, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7998, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1722\n",
      "-------------------------------\n",
      "train_loss tensor(2.3802, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7790, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5248, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1723\n",
      "-------------------------------\n",
      "train_loss tensor(2.3887, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6931, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6796, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1724\n",
      "-------------------------------\n",
      "train_loss tensor(2.3693, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7238, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5378, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1725\n",
      "-------------------------------\n",
      "train_loss tensor(2.3510, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7083, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6682, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1726\n",
      "-------------------------------\n",
      "train_loss tensor(2.3486, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6917, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8633, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1727\n",
      "-------------------------------\n",
      "train_loss tensor(2.3673, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7325, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5169, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1728\n",
      "-------------------------------\n",
      "train_loss tensor(2.3956, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7393, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6220, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1729\n",
      "-------------------------------\n",
      "train_loss tensor(2.3501, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6831, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.0504, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1730\n",
      "-------------------------------\n",
      "train_loss tensor(2.3624, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6883, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6866, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1731\n",
      "-------------------------------\n",
      "train_loss tensor(2.3630, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7482, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7154, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1732\n",
      "-------------------------------\n",
      "train_loss tensor(2.3953, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7832, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3595, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1733\n",
      "-------------------------------\n",
      "train_loss tensor(2.3881, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7034, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8582, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1734\n",
      "-------------------------------\n",
      "train_loss tensor(2.3933, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7545, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4583, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1735\n",
      "-------------------------------\n",
      "train_loss tensor(2.4119, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7198, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8578, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1736\n",
      "-------------------------------\n",
      "train_loss tensor(2.5129, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7119, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9527, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1737\n",
      "-------------------------------\n",
      "train_loss tensor(2.5672, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8101, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3844, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1738\n",
      "-------------------------------\n",
      "train_loss tensor(2.4265, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6472, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(10.0181, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1739\n",
      "-------------------------------\n",
      "train_loss tensor(2.4735, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8046, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2648, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1740\n",
      "-------------------------------\n",
      "train_loss tensor(2.4471, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7894, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4123, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1741\n",
      "-------------------------------\n",
      "train_loss tensor(2.4106, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8611, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2609, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1742\n",
      "-------------------------------\n",
      "train_loss tensor(2.4097, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7632, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7251, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1743\n",
      "-------------------------------\n",
      "train_loss tensor(2.4198, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7738, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0608, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1744\n",
      "-------------------------------\n",
      "train_loss tensor(2.4346, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7143, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2261, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1745\n",
      "-------------------------------\n",
      "train_loss tensor(2.3627, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6925, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1355, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1746\n",
      "-------------------------------\n",
      "train_loss tensor(2.3678, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7054, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5076, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1747\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(2.3475, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7371, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3722, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1748\n",
      "-------------------------------\n",
      "train_loss tensor(2.3389, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6995, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4573, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1749\n",
      "-------------------------------\n",
      "train_loss tensor(2.3284, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7131, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4320, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1750\n",
      "-------------------------------\n",
      "train_loss tensor(2.3670, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7857, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3289, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1751\n",
      "-------------------------------\n",
      "train_loss tensor(2.3691, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7333, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3624, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1752\n",
      "-------------------------------\n",
      "train_loss tensor(2.3607, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7477, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4285, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1753\n",
      "-------------------------------\n",
      "train_loss tensor(2.3474, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6863, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8538, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1754\n",
      "-------------------------------\n",
      "train_loss tensor(2.3570, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7949, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3245, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1755\n",
      "-------------------------------\n",
      "train_loss tensor(2.3506, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6566, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7438, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1756\n",
      "-------------------------------\n",
      "train_loss tensor(2.3408, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8067, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3858, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1757\n",
      "-------------------------------\n",
      "train_loss tensor(2.3640, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6788, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6120, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1758\n",
      "-------------------------------\n",
      "train_loss tensor(2.3698, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7844, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3721, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1759\n",
      "-------------------------------\n",
      "train_loss tensor(2.3541, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7263, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2402, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1760\n",
      "-------------------------------\n",
      "train_loss tensor(2.3399, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7300, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4140, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1761\n",
      "-------------------------------\n",
      "train_loss tensor(2.3410, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7332, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2869, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1762\n",
      "-------------------------------\n",
      "train_loss tensor(2.3340, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7707, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4797, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1763\n",
      "-------------------------------\n",
      "train_loss tensor(2.3495, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6678, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6012, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1764\n",
      "-------------------------------\n",
      "train_loss tensor(2.3281, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7668, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4547, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1765\n",
      "-------------------------------\n",
      "train_loss tensor(2.3228, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7148, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7306, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1766\n",
      "-------------------------------\n",
      "train_loss tensor(2.3117, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7627, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5107, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1767\n",
      "-------------------------------\n",
      "train_loss tensor(2.3148, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7158, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4146, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1768\n",
      "-------------------------------\n",
      "train_loss tensor(2.3267, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7583, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3984, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1769\n",
      "-------------------------------\n",
      "train_loss tensor(2.3154, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7125, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4128, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1770\n",
      "-------------------------------\n",
      "train_loss tensor(2.3152, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7136, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4508, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1771\n",
      "-------------------------------\n",
      "train_loss tensor(2.3093, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7019, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4132, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1772\n",
      "-------------------------------\n",
      "train_loss tensor(2.3145, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7878, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3926, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1773\n",
      "-------------------------------\n",
      "train_loss tensor(2.3131, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6976, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(8.3705, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1774\n",
      "-------------------------------\n",
      "train_loss tensor(2.3000, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7374, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4095, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1775\n",
      "-------------------------------\n",
      "train_loss tensor(2.3023, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7503, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2743, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1776\n",
      "-------------------------------\n",
      "train_loss tensor(2.3306, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6794, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5558, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1777\n",
      "-------------------------------\n",
      "train_loss tensor(2.3381, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7735, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3259, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1778\n",
      "-------------------------------\n",
      "train_loss tensor(2.3256, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6931, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5080, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1779\n",
      "-------------------------------\n",
      "train_loss tensor(2.3222, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7644, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5138, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1780\n",
      "-------------------------------\n",
      "train_loss tensor(2.3605, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7531, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4071, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1781\n",
      "-------------------------------\n",
      "train_loss tensor(2.3344, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7480, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4430, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1782\n",
      "-------------------------------\n",
      "train_loss tensor(2.3861, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7380, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4402, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1783\n",
      "-------------------------------\n",
      "train_loss tensor(2.3594, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6908, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7388, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1784\n",
      "-------------------------------\n",
      "train_loss tensor(2.3462, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7878, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3791, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1785\n",
      "-------------------------------\n",
      "train_loss tensor(2.3246, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7038, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6410, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1786\n",
      "-------------------------------\n",
      "train_loss tensor(2.3077, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7311, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4051, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1787\n",
      "-------------------------------\n",
      "train_loss tensor(2.3129, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7410, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6090, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1788\n",
      "-------------------------------\n",
      "train_loss tensor(2.3300, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6966, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6997, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1789\n",
      "-------------------------------\n",
      "train_loss tensor(2.3220, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8171, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4664, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1790\n",
      "-------------------------------\n",
      "train_loss tensor(2.3330, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6847, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8959, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1791\n",
      "-------------------------------\n",
      "train_loss tensor(2.3373, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7484, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6206, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1792\n",
      "-------------------------------\n",
      "train_loss tensor(2.3182, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7421, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4165, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1793\n",
      "-------------------------------\n",
      "train_loss tensor(2.3004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7644, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5130, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1794\n",
      "-------------------------------\n",
      "train_loss tensor(2.2961, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7191, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5359, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1795\n",
      "-------------------------------\n",
      "train_loss tensor(2.3080, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7641, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5932, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1796\n",
      "-------------------------------\n",
      "train_loss tensor(2.3143, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7855, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5802, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1797\n",
      "-------------------------------\n",
      "train_loss tensor(2.3115, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7166, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8527, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1798\n",
      "-------------------------------\n",
      "train_loss tensor(2.3176, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7555, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7900, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1799\n",
      "-------------------------------\n",
      "train_loss tensor(2.3359, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7501, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6204, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1800\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(2.3388, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7897, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4494, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1801\n",
      "-------------------------------\n",
      "train_loss tensor(2.3267, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6843, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7333, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1802\n",
      "-------------------------------\n",
      "train_loss tensor(2.3043, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7540, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4046, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1803\n",
      "-------------------------------\n",
      "train_loss tensor(2.3115, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7235, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5583, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1804\n",
      "-------------------------------\n",
      "train_loss tensor(2.3021, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6939, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5415, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1805\n",
      "-------------------------------\n",
      "train_loss tensor(2.3045, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7686, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4957, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1806\n",
      "-------------------------------\n",
      "train_loss tensor(2.3061, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6991, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6334, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1807\n",
      "-------------------------------\n",
      "train_loss tensor(2.3347, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7663, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4477, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1808\n",
      "-------------------------------\n",
      "train_loss tensor(2.3132, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7025, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6304, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1809\n",
      "-------------------------------\n",
      "train_loss tensor(2.2915, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7678, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5245, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1810\n",
      "-------------------------------\n",
      "train_loss tensor(2.3238, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7307, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5951, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1811\n",
      "-------------------------------\n",
      "train_loss tensor(2.2948, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7821, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5807, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1812\n",
      "-------------------------------\n",
      "train_loss tensor(2.3025, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7245, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4128, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1813\n",
      "-------------------------------\n",
      "train_loss tensor(2.3041, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7711, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4764, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1814\n",
      "-------------------------------\n",
      "train_loss tensor(2.3075, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7139, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4793, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1815\n",
      "-------------------------------\n",
      "train_loss tensor(2.2995, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7706, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5718, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1816\n",
      "-------------------------------\n",
      "train_loss tensor(2.2771, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7246, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4657, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1817\n",
      "-------------------------------\n",
      "train_loss tensor(2.2809, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7140, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5154, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1818\n",
      "-------------------------------\n",
      "train_loss tensor(2.2854, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7406, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3480, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1819\n",
      "-------------------------------\n",
      "train_loss tensor(2.2764, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7310, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6071, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1820\n",
      "-------------------------------\n",
      "train_loss tensor(2.2689, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7573, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3367, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1821\n",
      "-------------------------------\n",
      "train_loss tensor(2.2994, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8067, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4583, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1822\n",
      "-------------------------------\n",
      "train_loss tensor(2.3188, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7486, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4838, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1823\n",
      "-------------------------------\n",
      "train_loss tensor(2.2918, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7391, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5300, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1824\n",
      "-------------------------------\n",
      "train_loss tensor(2.3007, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7941, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3857, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1825\n",
      "-------------------------------\n",
      "train_loss tensor(2.2848, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7275, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6336, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1826\n",
      "-------------------------------\n",
      "train_loss tensor(2.2719, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7791, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(8.3524, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1827\n",
      "-------------------------------\n",
      "train_loss tensor(2.2794, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7241, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5620, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1828\n",
      "-------------------------------\n",
      "train_loss tensor(2.2688, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7548, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3489, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1829\n",
      "-------------------------------\n",
      "train_loss tensor(2.2671, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7199, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8072, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1830\n",
      "-------------------------------\n",
      "train_loss tensor(2.3092, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7471, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3558, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1831\n",
      "-------------------------------\n",
      "train_loss tensor(2.3051, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7172, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8205, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1832\n",
      "-------------------------------\n",
      "train_loss tensor(2.2852, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8185, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5073, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1833\n",
      "-------------------------------\n",
      "train_loss tensor(2.2856, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7198, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7881, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1834\n",
      "-------------------------------\n",
      "train_loss tensor(2.2769, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7887, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4870, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1835\n",
      "-------------------------------\n",
      "train_loss tensor(2.2581, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8113, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1836\n",
      "-------------------------------\n",
      "train_loss tensor(2.2790, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8389, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4817, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1837\n",
      "-------------------------------\n",
      "train_loss tensor(2.2887, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7577, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4352, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1838\n",
      "-------------------------------\n",
      "train_loss tensor(2.2887, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8157, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5571, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1839\n",
      "-------------------------------\n",
      "train_loss tensor(2.3287, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6956, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7622, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1840\n",
      "-------------------------------\n",
      "train_loss tensor(2.3484, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8617, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3613, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1841\n",
      "-------------------------------\n",
      "train_loss tensor(2.3281, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7237, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.1220, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1842\n",
      "-------------------------------\n",
      "train_loss tensor(2.3040, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7921, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5021, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1843\n",
      "-------------------------------\n",
      "train_loss tensor(2.2922, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7562, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3929, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1844\n",
      "-------------------------------\n",
      "train_loss tensor(2.2867, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7729, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5246, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1845\n",
      "-------------------------------\n",
      "train_loss tensor(2.2949, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7446, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2880, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1846\n",
      "-------------------------------\n",
      "train_loss tensor(2.3190, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7507, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6091, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1847\n",
      "-------------------------------\n",
      "train_loss tensor(2.3314, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8095, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2322, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1848\n",
      "-------------------------------\n",
      "train_loss tensor(2.3033, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7548, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4390, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1849\n",
      "-------------------------------\n",
      "train_loss tensor(2.2880, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7448, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4685, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1850\n",
      "-------------------------------\n",
      "train_loss tensor(2.3182, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8089, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4007, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1851\n",
      "-------------------------------\n",
      "train_loss tensor(2.2779, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6755, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4899, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1852\n",
      "-------------------------------\n",
      "train_loss tensor(2.2650, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7524, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3613, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1853\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(2.2493, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7306, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4636, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1854\n",
      "-------------------------------\n",
      "train_loss tensor(2.2514, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7690, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4075, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1855\n",
      "-------------------------------\n",
      "train_loss tensor(2.2613, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7169, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3793, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1856\n",
      "-------------------------------\n",
      "train_loss tensor(2.2548, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7763, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3932, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1857\n",
      "-------------------------------\n",
      "train_loss tensor(2.2507, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7621, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2863, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1858\n",
      "-------------------------------\n",
      "train_loss tensor(2.2708, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7762, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3543, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1859\n",
      "-------------------------------\n",
      "train_loss tensor(2.2620, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7532, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4076, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1860\n",
      "-------------------------------\n",
      "train_loss tensor(2.2809, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7643, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4106, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1861\n",
      "-------------------------------\n",
      "train_loss tensor(2.2652, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7619, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4149, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1862\n",
      "-------------------------------\n",
      "train_loss tensor(2.2570, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7209, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5745, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1863\n",
      "-------------------------------\n",
      "train_loss tensor(2.2559, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7352, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5703, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1864\n",
      "-------------------------------\n",
      "train_loss tensor(2.2515, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7501, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2747, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1865\n",
      "-------------------------------\n",
      "train_loss tensor(2.2454, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7211, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4037, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1866\n",
      "-------------------------------\n",
      "train_loss tensor(2.2397, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7759, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3206, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1867\n",
      "-------------------------------\n",
      "train_loss tensor(2.2535, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7319, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4620, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1868\n",
      "-------------------------------\n",
      "train_loss tensor(2.2291, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7446, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3649, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1869\n",
      "-------------------------------\n",
      "train_loss tensor(2.2365, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7379, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6011, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1870\n",
      "-------------------------------\n",
      "train_loss tensor(2.2466, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7832, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3197, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1871\n",
      "-------------------------------\n",
      "train_loss tensor(2.2477, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6976, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6882, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1872\n",
      "-------------------------------\n",
      "train_loss tensor(2.2427, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7825, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4902, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1873\n",
      "-------------------------------\n",
      "train_loss tensor(2.2488, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7518, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6031, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1874\n",
      "-------------------------------\n",
      "train_loss tensor(2.2453, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7989, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5314, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1875\n",
      "-------------------------------\n",
      "train_loss tensor(2.2536, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7606, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5262, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1876\n",
      "-------------------------------\n",
      "train_loss tensor(2.2558, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7559, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4332, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1877\n",
      "-------------------------------\n",
      "train_loss tensor(2.2394, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7081, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6407, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1878\n",
      "-------------------------------\n",
      "train_loss tensor(2.2338, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7451, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4233, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1879\n",
      "-------------------------------\n",
      "train_loss tensor(2.2348, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7787, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(8.4666, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1880\n",
      "-------------------------------\n",
      "train_loss tensor(2.2473, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7847, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4388, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1881\n",
      "-------------------------------\n",
      "train_loss tensor(2.2535, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7168, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2817, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1882\n",
      "-------------------------------\n",
      "train_loss tensor(2.2557, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7531, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4606, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1883\n",
      "-------------------------------\n",
      "train_loss tensor(2.2449, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7300, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7398, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1884\n",
      "-------------------------------\n",
      "train_loss tensor(2.2270, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7636, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5014, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1885\n",
      "-------------------------------\n",
      "train_loss tensor(2.2442, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7532, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5346, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1886\n",
      "-------------------------------\n",
      "train_loss tensor(2.2519, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8261, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2652, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1887\n",
      "-------------------------------\n",
      "train_loss tensor(2.2839, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7308, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7208, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1888\n",
      "-------------------------------\n",
      "train_loss tensor(2.2602, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7667, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3264, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1889\n",
      "-------------------------------\n",
      "train_loss tensor(2.2503, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7488, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4030, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1890\n",
      "-------------------------------\n",
      "train_loss tensor(2.2465, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7497, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7984, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1891\n",
      "-------------------------------\n",
      "train_loss tensor(2.2574, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7495, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3379, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1892\n",
      "-------------------------------\n",
      "train_loss tensor(2.2424, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7485, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4997, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1893\n",
      "-------------------------------\n",
      "train_loss tensor(2.2329, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7786, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5418, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1894\n",
      "-------------------------------\n",
      "train_loss tensor(2.2491, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8048, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3884, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1895\n",
      "-------------------------------\n",
      "train_loss tensor(2.2610, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7261, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4711, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1896\n",
      "-------------------------------\n",
      "train_loss tensor(2.2378, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7669, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4255, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1897\n",
      "-------------------------------\n",
      "train_loss tensor(2.2574, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7905, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8590, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1898\n",
      "-------------------------------\n",
      "train_loss tensor(2.2486, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7547, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3367, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1899\n",
      "-------------------------------\n",
      "train_loss tensor(2.2329, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7646, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4525, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1900\n",
      "-------------------------------\n",
      "train_loss tensor(2.2402, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7389, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4556, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1901\n",
      "-------------------------------\n",
      "train_loss tensor(2.2289, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8197, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4436, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1902\n",
      "-------------------------------\n",
      "train_loss tensor(2.2233, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7341, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4584, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1903\n",
      "-------------------------------\n",
      "train_loss tensor(2.2461, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8343, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4735, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1904\n",
      "-------------------------------\n",
      "train_loss tensor(2.2520, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7284, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3128, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1905\n",
      "-------------------------------\n",
      "train_loss tensor(2.2312, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8025, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3075, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1906\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(2.2320, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7105, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4869, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1907\n",
      "-------------------------------\n",
      "train_loss tensor(2.2389, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8665, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2033, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1908\n",
      "-------------------------------\n",
      "train_loss tensor(2.2705, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7451, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3385, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1909\n",
      "-------------------------------\n",
      "train_loss tensor(2.2697, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7855, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2985, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1910\n",
      "-------------------------------\n",
      "train_loss tensor(2.2986, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6882, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.2671, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1911\n",
      "-------------------------------\n",
      "train_loss tensor(2.3542, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8370, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7931, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1912\n",
      "-------------------------------\n",
      "train_loss tensor(2.3584, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8076, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3584, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1913\n",
      "-------------------------------\n",
      "train_loss tensor(2.3068, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.6934, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.1642, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1914\n",
      "-------------------------------\n",
      "train_loss tensor(2.2932, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7709, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4216, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1915\n",
      "-------------------------------\n",
      "train_loss tensor(2.2706, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7394, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6440, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1916\n",
      "-------------------------------\n",
      "train_loss tensor(2.2348, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7472, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8906, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1917\n",
      "-------------------------------\n",
      "train_loss tensor(2.2341, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7363, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7166, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1918\n",
      "-------------------------------\n",
      "train_loss tensor(2.2416, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8338, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7738, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1919\n",
      "-------------------------------\n",
      "train_loss tensor(2.2726, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7103, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.0514, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1920\n",
      "-------------------------------\n",
      "train_loss tensor(2.2212, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7730, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5166, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1921\n",
      "-------------------------------\n",
      "train_loss tensor(2.2498, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7895, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7088, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1922\n",
      "-------------------------------\n",
      "train_loss tensor(2.2890, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7454, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.1654, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1923\n",
      "-------------------------------\n",
      "train_loss tensor(2.2868, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7648, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.2116, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1924\n",
      "-------------------------------\n",
      "train_loss tensor(2.2509, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8139, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6980, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1925\n",
      "-------------------------------\n",
      "train_loss tensor(2.2759, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7628, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7175, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1926\n",
      "-------------------------------\n",
      "train_loss tensor(2.2398, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7181, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.8589, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1927\n",
      "-------------------------------\n",
      "train_loss tensor(2.2303, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8246, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9744, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1928\n",
      "-------------------------------\n",
      "train_loss tensor(2.2217, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7007, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8478, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1929\n",
      "-------------------------------\n",
      "train_loss tensor(2.2105, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7540, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8171, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1930\n",
      "-------------------------------\n",
      "train_loss tensor(2.2030, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7515, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7795, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1931\n",
      "-------------------------------\n",
      "train_loss tensor(2.1900, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7577, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8297, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1932\n",
      "-------------------------------\n",
      "train_loss tensor(2.1966, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7249, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(8.8528, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1933\n",
      "-------------------------------\n",
      "train_loss tensor(2.1920, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7569, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7299, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1934\n",
      "-------------------------------\n",
      "train_loss tensor(2.1912, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7640, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8019, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1935\n",
      "-------------------------------\n",
      "train_loss tensor(2.2168, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7614, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7837, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1936\n",
      "-------------------------------\n",
      "train_loss tensor(2.2044, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7747, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5461, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1937\n",
      "-------------------------------\n",
      "train_loss tensor(2.1967, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7228, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.0545, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1938\n",
      "-------------------------------\n",
      "train_loss tensor(2.2142, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7909, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5847, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1939\n",
      "-------------------------------\n",
      "train_loss tensor(2.2467, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7646, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7960, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1940\n",
      "-------------------------------\n",
      "train_loss tensor(2.2221, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7659, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7535, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1941\n",
      "-------------------------------\n",
      "train_loss tensor(2.2422, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7435, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.2541, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1942\n",
      "-------------------------------\n",
      "train_loss tensor(2.2241, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7830, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8895, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1943\n",
      "-------------------------------\n",
      "train_loss tensor(2.2027, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7448, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7701, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1944\n",
      "-------------------------------\n",
      "train_loss tensor(2.2200, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7213, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8544, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1945\n",
      "-------------------------------\n",
      "train_loss tensor(2.2150, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8353, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7244, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1946\n",
      "-------------------------------\n",
      "train_loss tensor(2.2115, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7120, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.1495, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1947\n",
      "-------------------------------\n",
      "train_loss tensor(2.2225, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8095, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4929, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1948\n",
      "-------------------------------\n",
      "train_loss tensor(2.2200, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7478, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8253, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1949\n",
      "-------------------------------\n",
      "train_loss tensor(2.2002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7278, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7712, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1950\n",
      "-------------------------------\n",
      "train_loss tensor(2.2102, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7660, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.1181, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1951\n",
      "-------------------------------\n",
      "train_loss tensor(2.2063, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7606, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6321, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1952\n",
      "-------------------------------\n",
      "train_loss tensor(2.2094, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7558, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7652, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1953\n",
      "-------------------------------\n",
      "train_loss tensor(2.1990, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7687, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5862, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1954\n",
      "-------------------------------\n",
      "train_loss tensor(2.1881, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7394, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9451, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1955\n",
      "-------------------------------\n",
      "train_loss tensor(2.1909, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7556, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9820, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1956\n",
      "-------------------------------\n",
      "train_loss tensor(2.2107, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7696, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7297, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1957\n",
      "-------------------------------\n",
      "train_loss tensor(2.1930, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7338, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.0629, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1958\n",
      "-------------------------------\n",
      "train_loss tensor(2.1948, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7963, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8791, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1959\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(2.1922, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7506, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5824, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1960\n",
      "-------------------------------\n",
      "train_loss tensor(2.1852, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7979, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6627, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1961\n",
      "-------------------------------\n",
      "train_loss tensor(2.2073, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7786, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7049, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1962\n",
      "-------------------------------\n",
      "train_loss tensor(2.1802, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7779, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7615, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1963\n",
      "-------------------------------\n",
      "train_loss tensor(2.1822, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7774, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7788, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1964\n",
      "-------------------------------\n",
      "train_loss tensor(2.1846, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7593, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8615, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1965\n",
      "-------------------------------\n",
      "train_loss tensor(2.1809, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7315, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7857, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1966\n",
      "-------------------------------\n",
      "train_loss tensor(2.1766, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8302, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4555, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1967\n",
      "-------------------------------\n",
      "train_loss tensor(2.1990, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7130, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9020, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1968\n",
      "-------------------------------\n",
      "train_loss tensor(2.2007, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8369, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6322, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1969\n",
      "-------------------------------\n",
      "train_loss tensor(2.2153, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7384, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6260, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1970\n",
      "-------------------------------\n",
      "train_loss tensor(2.2176, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7673, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.0260, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1971\n",
      "-------------------------------\n",
      "train_loss tensor(2.2070, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7814, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6229, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1972\n",
      "-------------------------------\n",
      "train_loss tensor(2.1804, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7674, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7320, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1973\n",
      "-------------------------------\n",
      "train_loss tensor(2.1890, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7322, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.1760, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1974\n",
      "-------------------------------\n",
      "train_loss tensor(2.1939, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7814, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5194, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1975\n",
      "-------------------------------\n",
      "train_loss tensor(2.1852, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7217, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7073, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1976\n",
      "-------------------------------\n",
      "train_loss tensor(2.1641, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7688, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6214, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1977\n",
      "-------------------------------\n",
      "train_loss tensor(2.1564, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7585, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4681, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1978\n",
      "-------------------------------\n",
      "train_loss tensor(2.1592, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7695, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5317, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1979\n",
      "-------------------------------\n",
      "train_loss tensor(2.1587, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7104, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.0662, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1980\n",
      "-------------------------------\n",
      "train_loss tensor(2.1803, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8047, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5883, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1981\n",
      "-------------------------------\n",
      "train_loss tensor(2.1698, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7607, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6008, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1982\n",
      "-------------------------------\n",
      "train_loss tensor(2.1798, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7982, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7443, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1983\n",
      "-------------------------------\n",
      "train_loss tensor(2.1802, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7547, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6679, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1984\n",
      "-------------------------------\n",
      "train_loss tensor(2.1876, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7971, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6450, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1985\n",
      "-------------------------------\n",
      "train_loss tensor(2.1832, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7439, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(8.7415, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1986\n",
      "-------------------------------\n",
      "train_loss tensor(2.1748, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7981, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7542, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1987\n",
      "-------------------------------\n",
      "train_loss tensor(2.1926, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7584, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9594, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1988\n",
      "-------------------------------\n",
      "train_loss tensor(2.2117, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8344, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4901, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1989\n",
      "-------------------------------\n",
      "train_loss tensor(2.2245, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7717, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6523, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1990\n",
      "-------------------------------\n",
      "train_loss tensor(2.1827, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7695, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5545, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1991\n",
      "-------------------------------\n",
      "train_loss tensor(2.1778, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7233, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9393, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1992\n",
      "-------------------------------\n",
      "train_loss tensor(2.1621, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8402, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3593, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1993\n",
      "-------------------------------\n",
      "train_loss tensor(2.1666, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7337, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8339, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1994\n",
      "-------------------------------\n",
      "train_loss tensor(2.1612, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7560, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4610, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1995\n",
      "-------------------------------\n",
      "train_loss tensor(2.1574, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8118, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2668, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1996\n",
      "-------------------------------\n",
      "train_loss tensor(2.1597, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7517, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4368, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1997\n",
      "-------------------------------\n",
      "train_loss tensor(2.1490, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7506, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5333, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1998\n",
      "-------------------------------\n",
      "train_loss tensor(2.1507, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7854, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5299, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 1999\n",
      "-------------------------------\n",
      "train_loss tensor(2.1544, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7684, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2317, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2000\n",
      "-------------------------------\n",
      "train_loss tensor(2.1399, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7347, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3991, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2001\n",
      "-------------------------------\n",
      "train_loss tensor(2.1381, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7479, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2415, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2002\n",
      "-------------------------------\n",
      "train_loss tensor(2.1324, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7692, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2482, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2003\n",
      "-------------------------------\n",
      "train_loss tensor(2.1391, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7666, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5677, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2004\n",
      "-------------------------------\n",
      "train_loss tensor(2.1428, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7920, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3855, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2005\n",
      "-------------------------------\n",
      "train_loss tensor(2.1340, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7612, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4280, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2006\n",
      "-------------------------------\n",
      "train_loss tensor(2.1440, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7719, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2628, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2007\n",
      "-------------------------------\n",
      "train_loss tensor(2.1803, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7960, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3119, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2008\n",
      "-------------------------------\n",
      "train_loss tensor(2.1758, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7572, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5450, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2009\n",
      "-------------------------------\n",
      "train_loss tensor(2.1836, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8063, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0723, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2010\n",
      "-------------------------------\n",
      "train_loss tensor(2.2096, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9044, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3969, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2011\n",
      "-------------------------------\n",
      "train_loss tensor(2.2516, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7117, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7132, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2012\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(2.2164, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8341, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4853, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2013\n",
      "-------------------------------\n",
      "train_loss tensor(2.1907, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7836, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5729, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2014\n",
      "-------------------------------\n",
      "train_loss tensor(2.1673, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7750, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5530, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2015\n",
      "-------------------------------\n",
      "train_loss tensor(2.1655, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7862, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5706, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2016\n",
      "-------------------------------\n",
      "train_loss tensor(2.1588, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8366, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0287, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2017\n",
      "-------------------------------\n",
      "train_loss tensor(2.1443, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7416, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3634, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2018\n",
      "-------------------------------\n",
      "train_loss tensor(2.1325, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7924, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1914, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2019\n",
      "-------------------------------\n",
      "train_loss tensor(2.1497, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8202, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2375, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2020\n",
      "-------------------------------\n",
      "train_loss tensor(2.1393, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7698, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2068, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2021\n",
      "-------------------------------\n",
      "train_loss tensor(2.1647, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8108, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1561, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2022\n",
      "-------------------------------\n",
      "train_loss tensor(2.1653, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7857, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0601, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2023\n",
      "-------------------------------\n",
      "train_loss tensor(2.1519, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7833, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1922, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2024\n",
      "-------------------------------\n",
      "train_loss tensor(2.1491, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7767, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6122, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2025\n",
      "-------------------------------\n",
      "train_loss tensor(2.1414, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7795, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4429, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2026\n",
      "-------------------------------\n",
      "train_loss tensor(2.1530, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8597, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0780, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2027\n",
      "-------------------------------\n",
      "train_loss tensor(2.1502, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7444, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1856, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2028\n",
      "-------------------------------\n",
      "train_loss tensor(2.1679, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7378, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4846, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2029\n",
      "-------------------------------\n",
      "train_loss tensor(2.2161, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9264, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0458, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2030\n",
      "-------------------------------\n",
      "train_loss tensor(2.2058, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7570, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.0658, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2031\n",
      "-------------------------------\n",
      "train_loss tensor(2.1876, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8725, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3805, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2032\n",
      "-------------------------------\n",
      "train_loss tensor(2.1775, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7597, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4805, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2033\n",
      "-------------------------------\n",
      "train_loss tensor(2.1445, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7860, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3203, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2034\n",
      "-------------------------------\n",
      "train_loss tensor(2.1480, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7876, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5235, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2035\n",
      "-------------------------------\n",
      "train_loss tensor(2.1286, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7664, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2580, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2036\n",
      "-------------------------------\n",
      "train_loss tensor(2.1276, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8077, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2412, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2037\n",
      "-------------------------------\n",
      "train_loss tensor(2.1264, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7611, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5482, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2038\n",
      "-------------------------------\n",
      "train_loss tensor(2.1298, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7993, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(8.1050, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2039\n",
      "-------------------------------\n",
      "train_loss tensor(2.1569, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8071, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2098, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2040\n",
      "-------------------------------\n",
      "train_loss tensor(2.1641, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7863, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3508, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2041\n",
      "-------------------------------\n",
      "train_loss tensor(2.1523, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7846, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5965, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2042\n",
      "-------------------------------\n",
      "train_loss tensor(2.1487, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8289, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9728, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2043\n",
      "-------------------------------\n",
      "train_loss tensor(2.1358, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7821, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4088, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2044\n",
      "-------------------------------\n",
      "train_loss tensor(2.1373, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7694, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3401, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2045\n",
      "-------------------------------\n",
      "train_loss tensor(2.1237, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7852, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3145, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2046\n",
      "-------------------------------\n",
      "train_loss tensor(2.1323, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7274, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9059, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2047\n",
      "-------------------------------\n",
      "train_loss tensor(2.1268, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8514, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1351, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2048\n",
      "-------------------------------\n",
      "train_loss tensor(2.1202, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7607, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6806, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2049\n",
      "-------------------------------\n",
      "train_loss tensor(2.1232, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7790, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0771, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2050\n",
      "-------------------------------\n",
      "train_loss tensor(2.1132, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8297, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3339, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2051\n",
      "-------------------------------\n",
      "train_loss tensor(2.1126, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7539, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3028, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2052\n",
      "-------------------------------\n",
      "train_loss tensor(2.1115, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7608, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1349, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2053\n",
      "-------------------------------\n",
      "train_loss tensor(2.1101, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7822, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3106, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2054\n",
      "-------------------------------\n",
      "train_loss tensor(2.1202, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7874, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1202, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2055\n",
      "-------------------------------\n",
      "train_loss tensor(2.1208, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8271, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8944, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2056\n",
      "-------------------------------\n",
      "train_loss tensor(2.1145, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7648, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1862, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2057\n",
      "-------------------------------\n",
      "train_loss tensor(2.1337, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7922, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1694, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2058\n",
      "-------------------------------\n",
      "train_loss tensor(2.1097, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7862, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9646, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2059\n",
      "-------------------------------\n",
      "train_loss tensor(2.1157, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7871, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1406, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2060\n",
      "-------------------------------\n",
      "train_loss tensor(2.1148, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8361, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1119, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2061\n",
      "-------------------------------\n",
      "train_loss tensor(2.1289, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7781, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8405, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2062\n",
      "-------------------------------\n",
      "train_loss tensor(2.1120, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8289, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1613, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2063\n",
      "-------------------------------\n",
      "train_loss tensor(2.0952, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8196, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9663, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2064\n",
      "-------------------------------\n",
      "train_loss tensor(2.1040, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7615, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5581, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2065\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(2.1064, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8319, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9906, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2066\n",
      "-------------------------------\n",
      "train_loss tensor(2.1013, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7839, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2966, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2067\n",
      "-------------------------------\n",
      "train_loss tensor(2.0917, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7770, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3351, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2068\n",
      "-------------------------------\n",
      "train_loss tensor(2.0927, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7689, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1077, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2069\n",
      "-------------------------------\n",
      "train_loss tensor(2.0901, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8350, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0362, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2070\n",
      "-------------------------------\n",
      "train_loss tensor(2.0839, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7864, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3115, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2071\n",
      "-------------------------------\n",
      "train_loss tensor(2.1193, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8032, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9884, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2072\n",
      "-------------------------------\n",
      "train_loss tensor(2.1007, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8204, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8274, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2073\n",
      "-------------------------------\n",
      "train_loss tensor(2.1122, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8116, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8826, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2074\n",
      "-------------------------------\n",
      "train_loss tensor(2.1032, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7562, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5646, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2075\n",
      "-------------------------------\n",
      "train_loss tensor(2.1044, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8443, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9325, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2076\n",
      "-------------------------------\n",
      "train_loss tensor(2.1046, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7700, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4233, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2077\n",
      "-------------------------------\n",
      "train_loss tensor(2.1011, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8120, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0016, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2078\n",
      "-------------------------------\n",
      "train_loss tensor(2.1336, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8353, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0048, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2079\n",
      "-------------------------------\n",
      "train_loss tensor(2.1519, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8244, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8034, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2080\n",
      "-------------------------------\n",
      "train_loss tensor(2.1644, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7416, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5866, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2081\n",
      "-------------------------------\n",
      "train_loss tensor(2.1380, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8450, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1150, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2082\n",
      "-------------------------------\n",
      "train_loss tensor(2.1349, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8294, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0902, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2083\n",
      "-------------------------------\n",
      "train_loss tensor(2.1076, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7868, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5850, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2084\n",
      "-------------------------------\n",
      "train_loss tensor(2.1056, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8441, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1816, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2085\n",
      "-------------------------------\n",
      "train_loss tensor(2.0932, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7852, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3819, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2086\n",
      "-------------------------------\n",
      "train_loss tensor(2.1070, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7760, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3651, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2087\n",
      "-------------------------------\n",
      "train_loss tensor(2.1138, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9138, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8229, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2088\n",
      "-------------------------------\n",
      "train_loss tensor(2.1087, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7779, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4683, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2089\n",
      "-------------------------------\n",
      "train_loss tensor(2.0975, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7985, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1877, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2090\n",
      "-------------------------------\n",
      "train_loss tensor(2.1001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8728, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0840, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2091\n",
      "-------------------------------\n",
      "train_loss tensor(2.1199, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7790, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(8.8058, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2092\n",
      "-------------------------------\n",
      "train_loss tensor(2.1473, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8132, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0524, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2093\n",
      "-------------------------------\n",
      "train_loss tensor(2.1263, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8540, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0361, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2094\n",
      "-------------------------------\n",
      "train_loss tensor(2.1214, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8013, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2413, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2095\n",
      "-------------------------------\n",
      "train_loss tensor(2.1011, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7792, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4435, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2096\n",
      "-------------------------------\n",
      "train_loss tensor(2.0950, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8852, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8582, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2097\n",
      "-------------------------------\n",
      "train_loss tensor(2.0957, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8188, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4876, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2098\n",
      "-------------------------------\n",
      "train_loss tensor(2.1280, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8232, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1438, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2099\n",
      "-------------------------------\n",
      "train_loss tensor(2.1000, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7749, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1409, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2100\n",
      "-------------------------------\n",
      "train_loss tensor(2.1098, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7859, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4638, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2101\n",
      "-------------------------------\n",
      "train_loss tensor(2.1132, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8471, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0063, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2102\n",
      "-------------------------------\n",
      "train_loss tensor(2.0973, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8354, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0527, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2103\n",
      "-------------------------------\n",
      "train_loss tensor(2.0870, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7919, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9759, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2104\n",
      "-------------------------------\n",
      "train_loss tensor(2.0743, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7497, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3665, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2105\n",
      "-------------------------------\n",
      "train_loss tensor(2.0911, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8404, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0526, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2106\n",
      "-------------------------------\n",
      "train_loss tensor(2.0929, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7816, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1829, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2107\n",
      "-------------------------------\n",
      "train_loss tensor(2.1221, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8101, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9859, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2108\n",
      "-------------------------------\n",
      "train_loss tensor(2.1066, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7528, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4344, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2109\n",
      "-------------------------------\n",
      "train_loss tensor(2.0810, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8111, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8097, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2110\n",
      "-------------------------------\n",
      "train_loss tensor(2.0773, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8354, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0638, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2111\n",
      "-------------------------------\n",
      "train_loss tensor(2.0839, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7912, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3150, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2112\n",
      "-------------------------------\n",
      "train_loss tensor(2.0870, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7767, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0880, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2113\n",
      "-------------------------------\n",
      "train_loss tensor(2.0730, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8336, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9282, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2114\n",
      "-------------------------------\n",
      "train_loss tensor(2.0731, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7986, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1805, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2115\n",
      "-------------------------------\n",
      "train_loss tensor(2.0857, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7972, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0171, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2116\n",
      "-------------------------------\n",
      "train_loss tensor(2.1050, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8873, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8218, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2117\n",
      "-------------------------------\n",
      "train_loss tensor(2.0983, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8077, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5478, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2118\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(2.1188, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8298, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7390, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2119\n",
      "-------------------------------\n",
      "train_loss tensor(2.0992, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8666, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9412, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2120\n",
      "-------------------------------\n",
      "train_loss tensor(2.0962, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7808, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2287, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2121\n",
      "-------------------------------\n",
      "train_loss tensor(2.1130, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8427, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.6203, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2122\n",
      "-------------------------------\n",
      "train_loss tensor(2.1067, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7736, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0314, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2123\n",
      "-------------------------------\n",
      "train_loss tensor(2.0988, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9087, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.6436, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2124\n",
      "-------------------------------\n",
      "train_loss tensor(2.0987, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7823, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4722, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2125\n",
      "-------------------------------\n",
      "train_loss tensor(2.0962, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8193, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1359, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2126\n",
      "-------------------------------\n",
      "train_loss tensor(2.0913, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7953, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6788, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2127\n",
      "-------------------------------\n",
      "train_loss tensor(2.0925, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8332, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5976, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2128\n",
      "-------------------------------\n",
      "train_loss tensor(2.0905, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3095, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2129\n",
      "-------------------------------\n",
      "train_loss tensor(2.1151, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7760, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7577, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2130\n",
      "-------------------------------\n",
      "train_loss tensor(2.1447, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9845, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9148, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2131\n",
      "-------------------------------\n",
      "train_loss tensor(2.1319, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8242, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0334, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2132\n",
      "-------------------------------\n",
      "train_loss tensor(2.1145, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8462, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0728, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2133\n",
      "-------------------------------\n",
      "train_loss tensor(2.1365, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7742, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0614, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2134\n",
      "-------------------------------\n",
      "train_loss tensor(2.1487, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8219, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7131, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2135\n",
      "-------------------------------\n",
      "train_loss tensor(2.1591, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9368, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1108, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2136\n",
      "-------------------------------\n",
      "train_loss tensor(2.1630, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8205, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3225, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2137\n",
      "-------------------------------\n",
      "train_loss tensor(2.1312, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8247, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1814, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2138\n",
      "-------------------------------\n",
      "train_loss tensor(2.0835, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7971, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0848, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2139\n",
      "-------------------------------\n",
      "train_loss tensor(2.0917, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7966, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3968, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2140\n",
      "-------------------------------\n",
      "train_loss tensor(2.0986, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8643, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8981, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2141\n",
      "-------------------------------\n",
      "train_loss tensor(2.0761, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7885, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1595, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2142\n",
      "-------------------------------\n",
      "train_loss tensor(2.0643, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8600, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9481, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2143\n",
      "-------------------------------\n",
      "train_loss tensor(2.0963, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8533, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0242, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2144\n",
      "-------------------------------\n",
      "train_loss tensor(2.1129, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8546, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(7.7803, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2145\n",
      "-------------------------------\n",
      "train_loss tensor(2.1011, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8346, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5133, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2146\n",
      "-------------------------------\n",
      "train_loss tensor(2.0849, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8449, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0371, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2147\n",
      "-------------------------------\n",
      "train_loss tensor(2.0781, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8334, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9704, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2148\n",
      "-------------------------------\n",
      "train_loss tensor(2.0723, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8339, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2700, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2149\n",
      "-------------------------------\n",
      "train_loss tensor(2.0651, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8267, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9405, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2150\n",
      "-------------------------------\n",
      "train_loss tensor(2.0656, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8407, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1028, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2151\n",
      "-------------------------------\n",
      "train_loss tensor(2.0518, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8103, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2465, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2152\n",
      "-------------------------------\n",
      "train_loss tensor(2.0571, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8372, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0031, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2153\n",
      "-------------------------------\n",
      "train_loss tensor(2.0420, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8009, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9463, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2154\n",
      "-------------------------------\n",
      "train_loss tensor(2.0483, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8149, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9847, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2155\n",
      "-------------------------------\n",
      "train_loss tensor(2.0521, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8765, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1281, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2156\n",
      "-------------------------------\n",
      "train_loss tensor(2.0471, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8053, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0328, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2157\n",
      "-------------------------------\n",
      "train_loss tensor(2.0542, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8008, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1988, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2158\n",
      "-------------------------------\n",
      "train_loss tensor(2.0542, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8862, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8931, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2159\n",
      "-------------------------------\n",
      "train_loss tensor(2.0739, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8327, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0038, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2160\n",
      "-------------------------------\n",
      "train_loss tensor(2.0466, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8295, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7679, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2161\n",
      "-------------------------------\n",
      "train_loss tensor(2.0595, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7846, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4936, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2162\n",
      "-------------------------------\n",
      "train_loss tensor(2.0471, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8720, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0185, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2163\n",
      "-------------------------------\n",
      "train_loss tensor(2.0346, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8523, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9158, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2164\n",
      "-------------------------------\n",
      "train_loss tensor(2.0277, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8289, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8697, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2165\n",
      "-------------------------------\n",
      "train_loss tensor(2.0346, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8167, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2062, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2166\n",
      "-------------------------------\n",
      "train_loss tensor(2.0333, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8612, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9309, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2167\n",
      "-------------------------------\n",
      "train_loss tensor(2.0439, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8683, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9439, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2168\n",
      "-------------------------------\n",
      "train_loss tensor(2.0663, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8436, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1608, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2169\n",
      "-------------------------------\n",
      "train_loss tensor(2.0497, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8591, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8827, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2170\n",
      "-------------------------------\n",
      "train_loss tensor(2.0485, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8218, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2485, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2171\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(2.0412, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8408, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8926, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2172\n",
      "-------------------------------\n",
      "train_loss tensor(2.0450, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8370, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1400, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2173\n",
      "-------------------------------\n",
      "train_loss tensor(2.0556, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8267, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0990, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2174\n",
      "-------------------------------\n",
      "train_loss tensor(2.0424, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8713, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9850, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2175\n",
      "-------------------------------\n",
      "train_loss tensor(2.0537, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8507, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9174, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2176\n",
      "-------------------------------\n",
      "train_loss tensor(2.0392, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8769, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9113, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2177\n",
      "-------------------------------\n",
      "train_loss tensor(2.0305, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8598, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0418, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2178\n",
      "-------------------------------\n",
      "train_loss tensor(2.0518, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8844, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1351, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2179\n",
      "-------------------------------\n",
      "train_loss tensor(2.0388, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8815, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8209, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2180\n",
      "-------------------------------\n",
      "train_loss tensor(2.0439, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8175, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9897, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2181\n",
      "-------------------------------\n",
      "train_loss tensor(2.0588, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8340, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9039, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2182\n",
      "-------------------------------\n",
      "train_loss tensor(2.0699, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8970, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8381, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2183\n",
      "-------------------------------\n",
      "train_loss tensor(2.0787, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7983, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9662, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2184\n",
      "-------------------------------\n",
      "train_loss tensor(2.0587, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8291, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1053, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2185\n",
      "-------------------------------\n",
      "train_loss tensor(2.0521, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9378, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7188, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2186\n",
      "-------------------------------\n",
      "train_loss tensor(2.0883, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7930, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4208, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2187\n",
      "-------------------------------\n",
      "train_loss tensor(2.1135, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8818, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0420, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2188\n",
      "-------------------------------\n",
      "train_loss tensor(2.0952, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8538, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3529, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2189\n",
      "-------------------------------\n",
      "train_loss tensor(2.0778, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8335, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8475, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2190\n",
      "-------------------------------\n",
      "train_loss tensor(2.0756, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8280, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4555, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2191\n",
      "-------------------------------\n",
      "train_loss tensor(2.1122, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8780, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3668, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2192\n",
      "-------------------------------\n",
      "train_loss tensor(2.0692, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8288, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7045, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2193\n",
      "-------------------------------\n",
      "train_loss tensor(2.0573, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8402, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8724, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2194\n",
      "-------------------------------\n",
      "train_loss tensor(2.0687, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8064, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3801, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2195\n",
      "-------------------------------\n",
      "train_loss tensor(2.0686, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9129, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8954, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2196\n",
      "-------------------------------\n",
      "train_loss tensor(2.0507, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8622, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0508, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2197\n",
      "-------------------------------\n",
      "train_loss tensor(2.0501, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8388, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(8.3912, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2198\n",
      "-------------------------------\n",
      "train_loss tensor(2.0545, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8857, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.6464, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2199\n",
      "-------------------------------\n",
      "train_loss tensor(2.0636, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8565, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2543, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2200\n",
      "-------------------------------\n",
      "train_loss tensor(2.0466, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8844, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7798, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2201\n",
      "-------------------------------\n",
      "train_loss tensor(2.0439, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8413, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1234, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2202\n",
      "-------------------------------\n",
      "train_loss tensor(2.0133, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8338, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9777, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2203\n",
      "-------------------------------\n",
      "train_loss tensor(2.0066, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8399, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9857, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2204\n",
      "-------------------------------\n",
      "train_loss tensor(2.0039, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8460, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1291, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2205\n",
      "-------------------------------\n",
      "train_loss tensor(2.0093, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8421, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8663, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2206\n",
      "-------------------------------\n",
      "train_loss tensor(2.0073, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8206, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0558, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2207\n",
      "-------------------------------\n",
      "train_loss tensor(2.0156, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8319, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0831, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2208\n",
      "-------------------------------\n",
      "train_loss tensor(2.0026, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8335, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7706, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2209\n",
      "-------------------------------\n",
      "train_loss tensor(2.0064, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8474, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0881, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2210\n",
      "-------------------------------\n",
      "train_loss tensor(2.0079, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8617, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9679, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2211\n",
      "-------------------------------\n",
      "train_loss tensor(2.0186, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8620, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8995, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2212\n",
      "-------------------------------\n",
      "train_loss tensor(2.0335, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8721, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0455, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2213\n",
      "-------------------------------\n",
      "train_loss tensor(2.0168, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8411, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8331, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2214\n",
      "-------------------------------\n",
      "train_loss tensor(2.0255, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8520, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1821, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2215\n",
      "-------------------------------\n",
      "train_loss tensor(2.0325, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9070, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7212, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2216\n",
      "-------------------------------\n",
      "train_loss tensor(2.0326, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8354, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0142, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2217\n",
      "-------------------------------\n",
      "train_loss tensor(2.0241, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7850, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5791, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2218\n",
      "-------------------------------\n",
      "train_loss tensor(2.0373, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9406, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.6551, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2219\n",
      "-------------------------------\n",
      "train_loss tensor(2.0569, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8308, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2441, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2220\n",
      "-------------------------------\n",
      "train_loss tensor(2.0921, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8796, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8111, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2221\n",
      "-------------------------------\n",
      "train_loss tensor(2.0363, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8748, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9822, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2222\n",
      "-------------------------------\n",
      "train_loss tensor(2.0447, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8599, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8617, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2223\n",
      "-------------------------------\n",
      "train_loss tensor(2.0175, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8682, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8932, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2224\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(2.0256, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8225, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1324, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2225\n",
      "-------------------------------\n",
      "train_loss tensor(2.0410, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9099, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8613, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2226\n",
      "-------------------------------\n",
      "train_loss tensor(2.0827, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8769, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2044, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2227\n",
      "-------------------------------\n",
      "train_loss tensor(2.0779, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8750, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0675, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2228\n",
      "-------------------------------\n",
      "train_loss tensor(2.0498, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9186, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1597, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2229\n",
      "-------------------------------\n",
      "train_loss tensor(2.0420, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8487, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2840, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2230\n",
      "-------------------------------\n",
      "train_loss tensor(2.0119, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8589, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8224, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2231\n",
      "-------------------------------\n",
      "train_loss tensor(2.0058, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8470, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0711, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2232\n",
      "-------------------------------\n",
      "train_loss tensor(1.9989, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8454, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0398, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2233\n",
      "-------------------------------\n",
      "train_loss tensor(1.9926, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8746, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9240, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2234\n",
      "-------------------------------\n",
      "train_loss tensor(1.9919, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8689, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9627, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2235\n",
      "-------------------------------\n",
      "train_loss tensor(1.9922, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8306, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0384, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2236\n",
      "-------------------------------\n",
      "train_loss tensor(1.9902, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8608, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9550, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2237\n",
      "-------------------------------\n",
      "train_loss tensor(1.9847, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8812, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8506, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2238\n",
      "-------------------------------\n",
      "train_loss tensor(1.9899, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8664, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1057, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2239\n",
      "-------------------------------\n",
      "train_loss tensor(1.9913, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8327, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0223, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2240\n",
      "-------------------------------\n",
      "train_loss tensor(1.9959, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8728, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8040, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2241\n",
      "-------------------------------\n",
      "train_loss tensor(1.9889, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8114, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9968, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2242\n",
      "-------------------------------\n",
      "train_loss tensor(1.9810, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8519, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8992, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2243\n",
      "-------------------------------\n",
      "train_loss tensor(1.9895, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8586, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0467, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2244\n",
      "-------------------------------\n",
      "train_loss tensor(1.9888, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8679, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9954, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2245\n",
      "-------------------------------\n",
      "train_loss tensor(1.9850, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8299, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2026, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2246\n",
      "-------------------------------\n",
      "train_loss tensor(2.0007, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8586, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0296, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2247\n",
      "-------------------------------\n",
      "train_loss tensor(2.0026, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9492, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.6869, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2248\n",
      "-------------------------------\n",
      "train_loss tensor(2.0228, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8260, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1947, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2249\n",
      "-------------------------------\n",
      "train_loss tensor(2.0179, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8313, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0606, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2250\n",
      "-------------------------------\n",
      "train_loss tensor(2.0235, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8556, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(8.1340, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2251\n",
      "-------------------------------\n",
      "train_loss tensor(2.0127, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8292, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1879, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2252\n",
      "-------------------------------\n",
      "train_loss tensor(2.0040, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8859, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2253\n",
      "-------------------------------\n",
      "train_loss tensor(1.9965, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8560, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8100, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2254\n",
      "-------------------------------\n",
      "train_loss tensor(1.9834, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8657, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8852, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2255\n",
      "-------------------------------\n",
      "train_loss tensor(1.9942, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8353, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0361, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2256\n",
      "-------------------------------\n",
      "train_loss tensor(1.9849, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8974, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7970, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2257\n",
      "-------------------------------\n",
      "train_loss tensor(1.9986, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8405, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2967, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2258\n",
      "-------------------------------\n",
      "train_loss tensor(2.0010, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8729, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8344, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2259\n",
      "-------------------------------\n",
      "train_loss tensor(1.9928, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8704, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7653, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2260\n",
      "-------------------------------\n",
      "train_loss tensor(1.9980, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8526, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7274, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2261\n",
      "-------------------------------\n",
      "train_loss tensor(1.9865, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8518, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0440, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2262\n",
      "-------------------------------\n",
      "train_loss tensor(1.9860, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8709, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7744, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2263\n",
      "-------------------------------\n",
      "train_loss tensor(1.9851, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8382, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1644, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2264\n",
      "-------------------------------\n",
      "train_loss tensor(1.9867, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9283, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.6665, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2265\n",
      "-------------------------------\n",
      "train_loss tensor(2.0012, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8564, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1141, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2266\n",
      "-------------------------------\n",
      "train_loss tensor(1.9887, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8349, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1783, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2267\n",
      "-------------------------------\n",
      "train_loss tensor(2.0021, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8134, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8966, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2268\n",
      "-------------------------------\n",
      "train_loss tensor(1.9968, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9207, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8303, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2269\n",
      "-------------------------------\n",
      "train_loss tensor(2.0009, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9130, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7788, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2270\n",
      "-------------------------------\n",
      "train_loss tensor(2.0325, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8419, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3314, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2271\n",
      "-------------------------------\n",
      "train_loss tensor(2.0250, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8912, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.6062, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2272\n",
      "-------------------------------\n",
      "train_loss tensor(2.0256, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9950, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.6971, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2273\n",
      "-------------------------------\n",
      "train_loss tensor(2.0666, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8871, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0973, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2274\n",
      "-------------------------------\n",
      "train_loss tensor(2.0641, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8916, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5461, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2275\n",
      "-------------------------------\n",
      "train_loss tensor(2.0394, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9866, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.5928, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2276\n",
      "-------------------------------\n",
      "train_loss tensor(2.0499, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8462, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7910, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2277\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(2.0078, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8842, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7978, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2278\n",
      "-------------------------------\n",
      "train_loss tensor(1.9874, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9079, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9724, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2279\n",
      "-------------------------------\n",
      "train_loss tensor(2.0007, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8546, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7321, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2280\n",
      "-------------------------------\n",
      "train_loss tensor(1.9871, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8430, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3106, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2281\n",
      "-------------------------------\n",
      "train_loss tensor(1.9790, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8280, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0480, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2282\n",
      "-------------------------------\n",
      "train_loss tensor(1.9974, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8627, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9753, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2283\n",
      "-------------------------------\n",
      "train_loss tensor(2.0194, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8939, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2566, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2284\n",
      "-------------------------------\n",
      "train_loss tensor(2.0167, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9222, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.6957, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2285\n",
      "-------------------------------\n",
      "train_loss tensor(2.0342, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8145, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5754, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2286\n",
      "-------------------------------\n",
      "train_loss tensor(2.0376, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8770, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9793, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2287\n",
      "-------------------------------\n",
      "train_loss tensor(2.0052, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8744, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3233, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2288\n",
      "-------------------------------\n",
      "train_loss tensor(2.0170, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8693, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2818, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2289\n",
      "-------------------------------\n",
      "train_loss tensor(2.0028, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8248, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8157, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2290\n",
      "-------------------------------\n",
      "train_loss tensor(1.9944, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8543, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9154, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2291\n",
      "-------------------------------\n",
      "train_loss tensor(1.9887, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8768, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8598, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2292\n",
      "-------------------------------\n",
      "train_loss tensor(2.0102, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8259, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3711, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2293\n",
      "-------------------------------\n",
      "train_loss tensor(1.9971, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9395, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7972, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2294\n",
      "-------------------------------\n",
      "train_loss tensor(1.9852, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8137, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3723, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2295\n",
      "-------------------------------\n",
      "train_loss tensor(1.9873, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8864, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1711, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2296\n",
      "-------------------------------\n",
      "train_loss tensor(1.9863, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8586, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2320, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2297\n",
      "-------------------------------\n",
      "train_loss tensor(1.9676, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8242, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3328, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2298\n",
      "-------------------------------\n",
      "train_loss tensor(1.9876, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9124, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9953, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2299\n",
      "-------------------------------\n",
      "train_loss tensor(1.9695, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8656, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1655, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2300\n",
      "-------------------------------\n",
      "train_loss tensor(1.9707, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8668, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8140, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2301\n",
      "-------------------------------\n",
      "train_loss tensor(1.9669, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8336, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9498, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2302\n",
      "-------------------------------\n",
      "train_loss tensor(1.9787, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8575, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2642, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2303\n",
      "-------------------------------\n",
      "train_loss tensor(1.9631, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8951, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(8.0108, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2304\n",
      "-------------------------------\n",
      "train_loss tensor(1.9725, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8492, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8849, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2305\n",
      "-------------------------------\n",
      "train_loss tensor(1.9625, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8478, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8707, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2306\n",
      "-------------------------------\n",
      "train_loss tensor(1.9609, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8311, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8626, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2307\n",
      "-------------------------------\n",
      "train_loss tensor(1.9563, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8627, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0774, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2308\n",
      "-------------------------------\n",
      "train_loss tensor(1.9553, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8495, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9917, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2309\n",
      "-------------------------------\n",
      "train_loss tensor(1.9579, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8484, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7928, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2310\n",
      "-------------------------------\n",
      "train_loss tensor(1.9663, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8463, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1016, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2311\n",
      "-------------------------------\n",
      "train_loss tensor(1.9604, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8771, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9703, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2312\n",
      "-------------------------------\n",
      "train_loss tensor(1.9622, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8758, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8277, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2313\n",
      "-------------------------------\n",
      "train_loss tensor(1.9543, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8567, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8339, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2314\n",
      "-------------------------------\n",
      "train_loss tensor(1.9435, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8532, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9675, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2315\n",
      "-------------------------------\n",
      "train_loss tensor(1.9521, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8690, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9533, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2316\n",
      "-------------------------------\n",
      "train_loss tensor(1.9492, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8229, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8914, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2317\n",
      "-------------------------------\n",
      "train_loss tensor(1.9550, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8789, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8657, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2318\n",
      "-------------------------------\n",
      "train_loss tensor(1.9491, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8596, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0078, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2319\n",
      "-------------------------------\n",
      "train_loss tensor(1.9616, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8428, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8617, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2320\n",
      "-------------------------------\n",
      "train_loss tensor(1.9593, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8716, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0095, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2321\n",
      "-------------------------------\n",
      "train_loss tensor(1.9929, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8875, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8045, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2322\n",
      "-------------------------------\n",
      "train_loss tensor(1.9817, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8631, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0274, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2323\n",
      "-------------------------------\n",
      "train_loss tensor(1.9899, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9426, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7141, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2324\n",
      "-------------------------------\n",
      "train_loss tensor(1.9969, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8638, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2712, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2325\n",
      "-------------------------------\n",
      "train_loss tensor(1.9874, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9007, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9905, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2326\n",
      "-------------------------------\n",
      "train_loss tensor(1.9849, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8367, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9227, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2327\n",
      "-------------------------------\n",
      "train_loss tensor(1.9788, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8545, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4076, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2328\n",
      "-------------------------------\n",
      "train_loss tensor(2.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8734, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8877, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2329\n",
      "-------------------------------\n",
      "train_loss tensor(1.9641, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8897, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.6862, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2330\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(1.9586, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8406, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8143, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2331\n",
      "-------------------------------\n",
      "train_loss tensor(1.9461, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8490, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9588, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2332\n",
      "-------------------------------\n",
      "train_loss tensor(1.9822, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8298, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1491, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2333\n",
      "-------------------------------\n",
      "train_loss tensor(1.9758, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8563, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9932, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2334\n",
      "-------------------------------\n",
      "train_loss tensor(1.9944, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8895, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9711, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2335\n",
      "-------------------------------\n",
      "train_loss tensor(1.9908, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8822, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9511, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2336\n",
      "-------------------------------\n",
      "train_loss tensor(1.9671, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8240, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1656, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2337\n",
      "-------------------------------\n",
      "train_loss tensor(1.9571, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9275, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7591, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2338\n",
      "-------------------------------\n",
      "train_loss tensor(1.9829, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8287, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5030, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2339\n",
      "-------------------------------\n",
      "train_loss tensor(1.9774, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8868, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9325, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2340\n",
      "-------------------------------\n",
      "train_loss tensor(1.9855, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9093, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.6943, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2341\n",
      "-------------------------------\n",
      "train_loss tensor(1.9733, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8598, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1298, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2342\n",
      "-------------------------------\n",
      "train_loss tensor(1.9604, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8232, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9216, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2343\n",
      "-------------------------------\n",
      "train_loss tensor(1.9630, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8536, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8250, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2344\n",
      "-------------------------------\n",
      "train_loss tensor(1.9432, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8709, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7559, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2345\n",
      "-------------------------------\n",
      "train_loss tensor(1.9315, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8589, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8904, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2346\n",
      "-------------------------------\n",
      "train_loss tensor(1.9315, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8727, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0030, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2347\n",
      "-------------------------------\n",
      "train_loss tensor(1.9247, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8479, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7786, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2348\n",
      "-------------------------------\n",
      "train_loss tensor(1.9275, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8667, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9061, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2349\n",
      "-------------------------------\n",
      "train_loss tensor(1.9294, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8624, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9358, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2350\n",
      "-------------------------------\n",
      "train_loss tensor(1.9468, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9149, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7907, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2351\n",
      "-------------------------------\n",
      "train_loss tensor(1.9633, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8653, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9025, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2352\n",
      "-------------------------------\n",
      "train_loss tensor(1.9731, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8302, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3540, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2353\n",
      "-------------------------------\n",
      "train_loss tensor(1.9641, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8626, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7386, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2354\n",
      "-------------------------------\n",
      "train_loss tensor(1.9702, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8913, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9083, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2355\n",
      "-------------------------------\n",
      "train_loss tensor(1.9618, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9060, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8180, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2356\n",
      "-------------------------------\n",
      "train_loss tensor(1.9508, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8719, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(7.8006, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2357\n",
      "-------------------------------\n",
      "train_loss tensor(1.9325, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8756, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8291, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2358\n",
      "-------------------------------\n",
      "train_loss tensor(1.9424, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8346, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2508, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2359\n",
      "-------------------------------\n",
      "train_loss tensor(1.9443, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9219, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7603, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2360\n",
      "-------------------------------\n",
      "train_loss tensor(1.9452, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8479, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0539, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2361\n",
      "-------------------------------\n",
      "train_loss tensor(1.9629, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8804, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9206, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2362\n",
      "-------------------------------\n",
      "train_loss tensor(1.9811, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8787, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.6446, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2363\n",
      "-------------------------------\n",
      "train_loss tensor(1.9513, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9141, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2364\n",
      "-------------------------------\n",
      "train_loss tensor(1.9609, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8698, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7889, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2365\n",
      "-------------------------------\n",
      "train_loss tensor(1.9747, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8604, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0976, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2366\n",
      "-------------------------------\n",
      "train_loss tensor(1.9775, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8727, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0012, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2367\n",
      "-------------------------------\n",
      "train_loss tensor(1.9692, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8245, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9353, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2368\n",
      "-------------------------------\n",
      "train_loss tensor(1.9579, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8668, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8127, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2369\n",
      "-------------------------------\n",
      "train_loss tensor(1.9682, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9009, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8905, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2370\n",
      "-------------------------------\n",
      "train_loss tensor(1.9580, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8608, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0893, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2371\n",
      "-------------------------------\n",
      "train_loss tensor(1.9608, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8542, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9540, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2372\n",
      "-------------------------------\n",
      "train_loss tensor(1.9581, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8886, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7065, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2373\n",
      "-------------------------------\n",
      "train_loss tensor(1.9498, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8508, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1746, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2374\n",
      "-------------------------------\n",
      "train_loss tensor(1.9471, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8679, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8133, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2375\n",
      "-------------------------------\n",
      "train_loss tensor(1.9545, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9020, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.6977, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2376\n",
      "-------------------------------\n",
      "train_loss tensor(1.9475, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8379, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8733, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2377\n",
      "-------------------------------\n",
      "train_loss tensor(1.9325, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8173, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7917, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2378\n",
      "-------------------------------\n",
      "train_loss tensor(1.9244, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8992, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7879, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2379\n",
      "-------------------------------\n",
      "train_loss tensor(1.9420, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8597, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7925, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2380\n",
      "-------------------------------\n",
      "train_loss tensor(1.9391, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8457, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0751, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2381\n",
      "-------------------------------\n",
      "train_loss tensor(1.9300, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8911, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7723, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2382\n",
      "-------------------------------\n",
      "train_loss tensor(1.9550, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8344, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0555, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2383\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(1.9346, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9206, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.6594, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2384\n",
      "-------------------------------\n",
      "train_loss tensor(1.9251, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8219, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9899, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2385\n",
      "-------------------------------\n",
      "train_loss tensor(1.9259, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8569, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8056, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2386\n",
      "-------------------------------\n",
      "train_loss tensor(1.9284, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8807, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8561, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2387\n",
      "-------------------------------\n",
      "train_loss tensor(1.9450, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8814, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8481, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2388\n",
      "-------------------------------\n",
      "train_loss tensor(1.9376, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8346, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9131, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2389\n",
      "-------------------------------\n",
      "train_loss tensor(1.9328, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8522, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8034, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2390\n",
      "-------------------------------\n",
      "train_loss tensor(1.9380, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8981, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7534, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2391\n",
      "-------------------------------\n",
      "train_loss tensor(1.9248, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8499, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0334, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2392\n",
      "-------------------------------\n",
      "train_loss tensor(1.9190, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8611, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7239, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2393\n",
      "-------------------------------\n",
      "train_loss tensor(1.9224, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8257, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0024, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2394\n",
      "-------------------------------\n",
      "train_loss tensor(1.9187, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8649, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7568, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2395\n",
      "-------------------------------\n",
      "train_loss tensor(1.9437, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8029, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2890, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2396\n",
      "-------------------------------\n",
      "train_loss tensor(1.9481, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8916, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.6858, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2397\n",
      "-------------------------------\n",
      "train_loss tensor(1.9300, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9046, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8569, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2398\n",
      "-------------------------------\n",
      "train_loss tensor(1.9343, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8336, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8261, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2399\n",
      "-------------------------------\n",
      "train_loss tensor(1.9334, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8236, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8645, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2400\n",
      "-------------------------------\n",
      "train_loss tensor(1.9407, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8750, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7309, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2401\n",
      "-------------------------------\n",
      "train_loss tensor(1.9391, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8722, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8385, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2402\n",
      "-------------------------------\n",
      "train_loss tensor(1.9258, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9530, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7360, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2403\n",
      "-------------------------------\n",
      "train_loss tensor(1.9324, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8563, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7739, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2404\n",
      "-------------------------------\n",
      "train_loss tensor(1.9127, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8599, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0669, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2405\n",
      "-------------------------------\n",
      "train_loss tensor(1.9244, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8266, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8720, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2406\n",
      "-------------------------------\n",
      "train_loss tensor(1.9228, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8925, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7161, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2407\n",
      "-------------------------------\n",
      "train_loss tensor(1.9263, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8775, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8354, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2408\n",
      "-------------------------------\n",
      "train_loss tensor(1.9163, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8827, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8345, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2409\n",
      "-------------------------------\n",
      "train_loss tensor(1.9196, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8634, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(7.8625, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2410\n",
      "-------------------------------\n",
      "train_loss tensor(1.9120, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8285, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8848, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2411\n",
      "-------------------------------\n",
      "train_loss tensor(1.9166, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8901, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7470, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2412\n",
      "-------------------------------\n",
      "train_loss tensor(1.9215, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8399, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8035, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2413\n",
      "-------------------------------\n",
      "train_loss tensor(1.9194, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8838, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9067, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2414\n",
      "-------------------------------\n",
      "train_loss tensor(1.9453, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8798, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8823, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2415\n",
      "-------------------------------\n",
      "train_loss tensor(1.9316, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8852, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.6081, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2416\n",
      "-------------------------------\n",
      "train_loss tensor(1.9312, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8748, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8601, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2417\n",
      "-------------------------------\n",
      "train_loss tensor(1.9449, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8095, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2409, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2418\n",
      "-------------------------------\n",
      "train_loss tensor(1.9554, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9036, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8079, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2419\n",
      "-------------------------------\n",
      "train_loss tensor(1.9228, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8137, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4295, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2420\n",
      "-------------------------------\n",
      "train_loss tensor(1.9191, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8745, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8882, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2421\n",
      "-------------------------------\n",
      "train_loss tensor(1.9137, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8393, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8952, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2422\n",
      "-------------------------------\n",
      "train_loss tensor(1.9041, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8726, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8973, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2423\n",
      "-------------------------------\n",
      "train_loss tensor(1.9050, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8256, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2018, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2424\n",
      "-------------------------------\n",
      "train_loss tensor(1.8990, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8800, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7963, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2425\n",
      "-------------------------------\n",
      "train_loss tensor(1.9054, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8270, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9900, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2426\n",
      "-------------------------------\n",
      "train_loss tensor(1.9131, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8505, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0154, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2427\n",
      "-------------------------------\n",
      "train_loss tensor(1.9055, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8788, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7825, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2428\n",
      "-------------------------------\n",
      "train_loss tensor(1.9059, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8628, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9478, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2429\n",
      "-------------------------------\n",
      "train_loss tensor(1.8994, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8660, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7970, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2430\n",
      "-------------------------------\n",
      "train_loss tensor(1.8893, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8385, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9478, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2431\n",
      "-------------------------------\n",
      "train_loss tensor(1.8969, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8219, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9107, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2432\n",
      "-------------------------------\n",
      "train_loss tensor(1.8952, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8641, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8264, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2433\n",
      "-------------------------------\n",
      "train_loss tensor(1.9051, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8867, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7552, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2434\n",
      "-------------------------------\n",
      "train_loss tensor(1.9235, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8365, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9137, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2435\n",
      "-------------------------------\n",
      "train_loss tensor(1.9057, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8752, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7665, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2436\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(1.9005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8534, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0055, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2437\n",
      "-------------------------------\n",
      "train_loss tensor(1.9053, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8835, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9789, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2438\n",
      "-------------------------------\n",
      "train_loss tensor(1.9194, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8832, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7765, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2439\n",
      "-------------------------------\n",
      "train_loss tensor(1.8959, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8536, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8396, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2440\n",
      "-------------------------------\n",
      "train_loss tensor(1.8963, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8853, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9733, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2441\n",
      "-------------------------------\n",
      "train_loss tensor(1.9059, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8248, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9321, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2442\n",
      "-------------------------------\n",
      "train_loss tensor(1.9039, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8750, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7243, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2443\n",
      "-------------------------------\n",
      "train_loss tensor(1.8981, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8782, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9273, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2444\n",
      "-------------------------------\n",
      "train_loss tensor(1.9284, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8663, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8963, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2445\n",
      "-------------------------------\n",
      "train_loss tensor(1.9322, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9288, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7822, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2446\n",
      "-------------------------------\n",
      "train_loss tensor(1.9488, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7981, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1040, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2447\n",
      "-------------------------------\n",
      "train_loss tensor(1.9541, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9808, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7462, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2448\n",
      "-------------------------------\n",
      "train_loss tensor(1.9474, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8475, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0081, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2449\n",
      "-------------------------------\n",
      "train_loss tensor(1.9132, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8551, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9314, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2450\n",
      "-------------------------------\n",
      "train_loss tensor(1.9261, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8464, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0690, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2451\n",
      "-------------------------------\n",
      "train_loss tensor(1.9131, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9490, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8381, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2452\n",
      "-------------------------------\n",
      "train_loss tensor(1.9323, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9246, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8103, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2453\n",
      "-------------------------------\n",
      "train_loss tensor(2.0064, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8319, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2280, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2454\n",
      "-------------------------------\n",
      "train_loss tensor(1.9627, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9238, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8654, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2455\n",
      "-------------------------------\n",
      "train_loss tensor(1.9494, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8541, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8705, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2456\n",
      "-------------------------------\n",
      "train_loss tensor(1.9405, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8872, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8060, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2457\n",
      "-------------------------------\n",
      "train_loss tensor(1.9209, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8668, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9402, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2458\n",
      "-------------------------------\n",
      "train_loss tensor(1.9264, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9257, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7468, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2459\n",
      "-------------------------------\n",
      "train_loss tensor(1.9205, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8505, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9687, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2460\n",
      "-------------------------------\n",
      "train_loss tensor(1.9224, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8811, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8526, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2461\n",
      "-------------------------------\n",
      "train_loss tensor(1.9380, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9207, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8288, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2462\n",
      "-------------------------------\n",
      "train_loss tensor(1.9648, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8389, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(7.8359, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2463\n",
      "-------------------------------\n",
      "train_loss tensor(1.9156, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8867, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7431, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2464\n",
      "-------------------------------\n",
      "train_loss tensor(1.9164, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.7951, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9127, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2465\n",
      "-------------------------------\n",
      "train_loss tensor(1.8957, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8759, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8069, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2466\n",
      "-------------------------------\n",
      "train_loss tensor(1.8906, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8479, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8216, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2467\n",
      "-------------------------------\n",
      "train_loss tensor(1.8919, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8468, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8732, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2468\n",
      "-------------------------------\n",
      "train_loss tensor(1.9002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8743, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8044, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2469\n",
      "-------------------------------\n",
      "train_loss tensor(1.8879, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8760, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8642, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2470\n",
      "-------------------------------\n",
      "train_loss tensor(1.8779, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8389, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9222, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2471\n",
      "-------------------------------\n",
      "train_loss tensor(1.8806, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8707, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8391, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2472\n",
      "-------------------------------\n",
      "train_loss tensor(1.8756, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8452, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8976, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2473\n",
      "-------------------------------\n",
      "train_loss tensor(1.8783, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8253, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8974, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2474\n",
      "-------------------------------\n",
      "train_loss tensor(1.8855, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8910, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7740, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2475\n",
      "-------------------------------\n",
      "train_loss tensor(1.8827, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8756, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8126, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2476\n",
      "-------------------------------\n",
      "train_loss tensor(1.8852, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8700, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8570, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2477\n",
      "-------------------------------\n",
      "train_loss tensor(1.8805, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8474, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7968, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2478\n",
      "-------------------------------\n",
      "train_loss tensor(1.8818, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8412, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0444, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2479\n",
      "-------------------------------\n",
      "train_loss tensor(1.8993, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9053, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8098, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2480\n",
      "-------------------------------\n",
      "train_loss tensor(1.8986, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8454, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8507, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2481\n",
      "-------------------------------\n",
      "train_loss tensor(1.8831, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8953, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8106, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2482\n",
      "-------------------------------\n",
      "train_loss tensor(1.8802, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8216, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8660, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2483\n",
      "-------------------------------\n",
      "train_loss tensor(1.8899, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9204, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7682, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2484\n",
      "-------------------------------\n",
      "train_loss tensor(1.8890, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8477, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9302, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2485\n",
      "-------------------------------\n",
      "train_loss tensor(1.8753, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8881, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.6818, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2486\n",
      "-------------------------------\n",
      "train_loss tensor(1.8762, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8464, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9055, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2487\n",
      "-------------------------------\n",
      "train_loss tensor(1.8790, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8334, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7599, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2488\n",
      "-------------------------------\n",
      "train_loss tensor(1.8851, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9046, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7109, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2489\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(1.8915, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8867, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9583, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2490\n",
      "-------------------------------\n",
      "train_loss tensor(1.8874, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8287, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8386, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2491\n",
      "-------------------------------\n",
      "train_loss tensor(1.8794, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9129, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8101, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2492\n",
      "-------------------------------\n",
      "train_loss tensor(1.8772, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8288, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9517, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2493\n",
      "-------------------------------\n",
      "train_loss tensor(1.8940, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9009, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7719, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2494\n",
      "-------------------------------\n",
      "train_loss tensor(1.9091, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8686, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9102, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2495\n",
      "-------------------------------\n",
      "train_loss tensor(1.8873, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9061, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.6862, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2496\n",
      "-------------------------------\n",
      "train_loss tensor(1.9005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8597, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9243, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2497\n",
      "-------------------------------\n",
      "train_loss tensor(1.8785, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8266, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9395, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2498\n",
      "-------------------------------\n",
      "train_loss tensor(1.8843, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8915, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8380, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2499\n",
      "-------------------------------\n",
      "train_loss tensor(1.8724, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8471, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8386, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2500\n",
      "-------------------------------\n",
      "train_loss tensor(1.8765, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9124, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8153, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2501\n",
      "-------------------------------\n",
      "train_loss tensor(1.8868, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8418, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9459, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2502\n",
      "-------------------------------\n",
      "train_loss tensor(1.9228, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8903, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8397, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2503\n",
      "-------------------------------\n",
      "train_loss tensor(1.9169, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8625, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8111, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2504\n",
      "-------------------------------\n",
      "train_loss tensor(1.9050, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8660, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8774, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2505\n",
      "-------------------------------\n",
      "train_loss tensor(1.8945, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9699, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9776, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2506\n",
      "-------------------------------\n",
      "train_loss tensor(1.9120, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8154, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0273, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2507\n",
      "-------------------------------\n",
      "train_loss tensor(1.8982, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8957, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9950, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2508\n",
      "-------------------------------\n",
      "train_loss tensor(1.8924, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8334, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0630, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2509\n",
      "-------------------------------\n",
      "train_loss tensor(1.8756, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8869, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8148, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2510\n",
      "-------------------------------\n",
      "train_loss tensor(1.9040, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8824, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9558, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2511\n",
      "-------------------------------\n",
      "train_loss tensor(1.8954, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8869, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9848, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2512\n",
      "-------------------------------\n",
      "train_loss tensor(1.9101, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8708, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8090, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2513\n",
      "-------------------------------\n",
      "train_loss tensor(1.9049, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9277, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9176, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2514\n",
      "-------------------------------\n",
      "train_loss tensor(1.8939, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8485, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9316, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2515\n",
      "-------------------------------\n",
      "train_loss tensor(1.8754, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8400, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(8.1365, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2516\n",
      "-------------------------------\n",
      "train_loss tensor(1.8651, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8868, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8171, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2517\n",
      "-------------------------------\n",
      "train_loss tensor(1.8692, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8896, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8687, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2518\n",
      "-------------------------------\n",
      "train_loss tensor(1.8620, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8488, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8885, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2519\n",
      "-------------------------------\n",
      "train_loss tensor(1.8604, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8622, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8122, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2520\n",
      "-------------------------------\n",
      "train_loss tensor(1.8617, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8531, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8918, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2521\n",
      "-------------------------------\n",
      "train_loss tensor(1.8636, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8834, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8647, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2522\n",
      "-------------------------------\n",
      "train_loss tensor(1.8646, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8592, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8256, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2523\n",
      "-------------------------------\n",
      "train_loss tensor(1.8588, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8863, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9892, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2524\n",
      "-------------------------------\n",
      "train_loss tensor(1.8948, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8556, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8512, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2525\n",
      "-------------------------------\n",
      "train_loss tensor(1.8793, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8648, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9365, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2526\n",
      "-------------------------------\n",
      "train_loss tensor(1.8888, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9247, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9791, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2527\n",
      "-------------------------------\n",
      "train_loss tensor(1.9133, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7442, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2528\n",
      "-------------------------------\n",
      "train_loss tensor(1.9171, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8369, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7843, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2529\n",
      "-------------------------------\n",
      "train_loss tensor(1.9088, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9104, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7649, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2530\n",
      "-------------------------------\n",
      "train_loss tensor(1.8741, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9284, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8088, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2531\n",
      "-------------------------------\n",
      "train_loss tensor(1.9117, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8376, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9687, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2532\n",
      "-------------------------------\n",
      "train_loss tensor(1.8977, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0061, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8326, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2533\n",
      "-------------------------------\n",
      "train_loss tensor(1.8945, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8529, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8141, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2534\n",
      "-------------------------------\n",
      "train_loss tensor(1.8902, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9129, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8292, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2535\n",
      "-------------------------------\n",
      "train_loss tensor(1.8968, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8718, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7787, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2536\n",
      "-------------------------------\n",
      "train_loss tensor(1.8772, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8944, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8533, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2537\n",
      "-------------------------------\n",
      "train_loss tensor(1.8732, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8818, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9973, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2538\n",
      "-------------------------------\n",
      "train_loss tensor(1.8643, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8608, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8034, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2539\n",
      "-------------------------------\n",
      "train_loss tensor(1.8653, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9314, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8723, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2540\n",
      "-------------------------------\n",
      "train_loss tensor(1.8618, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8717, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9043, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2541\n",
      "-------------------------------\n",
      "train_loss tensor(1.8534, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8942, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8385, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2542\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(1.8713, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8587, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9264, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2543\n",
      "-------------------------------\n",
      "train_loss tensor(1.8847, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8745, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.7302, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2544\n",
      "-------------------------------\n",
      "train_loss tensor(1.8973, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8894, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9709, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2545\n",
      "-------------------------------\n",
      "train_loss tensor(1.8721, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9550, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2546\n",
      "-------------------------------\n",
      "train_loss tensor(1.8661, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8865, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9691, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2547\n",
      "-------------------------------\n",
      "train_loss tensor(1.8665, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8966, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9633, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2548\n",
      "-------------------------------\n",
      "train_loss tensor(1.8590, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8835, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0257, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2549\n",
      "-------------------------------\n",
      "train_loss tensor(1.8520, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8786, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9517, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2550\n",
      "-------------------------------\n",
      "train_loss tensor(1.8513, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8699, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9198, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2551\n",
      "-------------------------------\n",
      "train_loss tensor(1.8461, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8795, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9322, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2552\n",
      "-------------------------------\n",
      "train_loss tensor(1.8453, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8590, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9291, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2553\n",
      "-------------------------------\n",
      "train_loss tensor(1.8493, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8982, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9206, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2554\n",
      "-------------------------------\n",
      "train_loss tensor(1.8507, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8851, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8318, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2555\n",
      "-------------------------------\n",
      "train_loss tensor(1.8482, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9261, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0099, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2556\n",
      "-------------------------------\n",
      "train_loss tensor(1.8634, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9028, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9323, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2557\n",
      "-------------------------------\n",
      "train_loss tensor(1.8638, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9078, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8935, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2558\n",
      "-------------------------------\n",
      "train_loss tensor(1.9016, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8588, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9778, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2559\n",
      "-------------------------------\n",
      "train_loss tensor(1.8669, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8723, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0157, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2560\n",
      "-------------------------------\n",
      "train_loss tensor(1.8557, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8636, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8671, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2561\n",
      "-------------------------------\n",
      "train_loss tensor(1.8643, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9245, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9052, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2562\n",
      "-------------------------------\n",
      "train_loss tensor(1.8620, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8686, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9730, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2563\n",
      "-------------------------------\n",
      "train_loss tensor(1.8773, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9020, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9352, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2564\n",
      "-------------------------------\n",
      "train_loss tensor(1.8708, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9594, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8586, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2565\n",
      "-------------------------------\n",
      "train_loss tensor(1.9030, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8960, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0429, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2566\n",
      "-------------------------------\n",
      "train_loss tensor(1.9003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9235, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9904, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2567\n",
      "-------------------------------\n",
      "train_loss tensor(1.9021, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9041, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1746, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2568\n",
      "-------------------------------\n",
      "train_loss tensor(1.9269, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0157, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(7.6777, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2569\n",
      "-------------------------------\n",
      "train_loss tensor(1.9335, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8777, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9917, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2570\n",
      "-------------------------------\n",
      "train_loss tensor(1.9240, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9521, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9421, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2571\n",
      "-------------------------------\n",
      "train_loss tensor(1.8999, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9068, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0183, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2572\n",
      "-------------------------------\n",
      "train_loss tensor(1.8923, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8862, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0396, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2573\n",
      "-------------------------------\n",
      "train_loss tensor(1.9431, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9422, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8849, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2574\n",
      "-------------------------------\n",
      "train_loss tensor(1.9666, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9240, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0729, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2575\n",
      "-------------------------------\n",
      "train_loss tensor(1.9425, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9051, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8340, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2576\n",
      "-------------------------------\n",
      "train_loss tensor(1.9025, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9387, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0078, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2577\n",
      "-------------------------------\n",
      "train_loss tensor(1.8783, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8465, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9320, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2578\n",
      "-------------------------------\n",
      "train_loss tensor(1.8840, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8915, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0489, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2579\n",
      "-------------------------------\n",
      "train_loss tensor(1.9019, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9052, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0483, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2580\n",
      "-------------------------------\n",
      "train_loss tensor(1.8890, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8862, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9980, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2581\n",
      "-------------------------------\n",
      "train_loss tensor(1.8911, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9574, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9385, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2582\n",
      "-------------------------------\n",
      "train_loss tensor(1.9110, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8369, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0210, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2583\n",
      "-------------------------------\n",
      "train_loss tensor(1.8976, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0292, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0089, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2584\n",
      "-------------------------------\n",
      "train_loss tensor(1.8847, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8787, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9342, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2585\n",
      "-------------------------------\n",
      "train_loss tensor(1.8619, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8811, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9070, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2586\n",
      "-------------------------------\n",
      "train_loss tensor(1.8432, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8933, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8624, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2587\n",
      "-------------------------------\n",
      "train_loss tensor(1.8462, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8609, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8241, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2588\n",
      "-------------------------------\n",
      "train_loss tensor(1.8354, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8640, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9452, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2589\n",
      "-------------------------------\n",
      "train_loss tensor(1.8364, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8857, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9038, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2590\n",
      "-------------------------------\n",
      "train_loss tensor(1.8632, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8883, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9690, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2591\n",
      "-------------------------------\n",
      "train_loss tensor(1.8725, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8715, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8066, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2592\n",
      "-------------------------------\n",
      "train_loss tensor(1.8582, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9234, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9318, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2593\n",
      "-------------------------------\n",
      "train_loss tensor(1.8722, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8183, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8335, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2594\n",
      "-------------------------------\n",
      "train_loss tensor(1.8676, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8960, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9320, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2595\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(1.8629, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9212, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0579, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2596\n",
      "-------------------------------\n",
      "train_loss tensor(1.8543, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8656, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0204, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2597\n",
      "-------------------------------\n",
      "train_loss tensor(1.8624, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9057, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9683, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2598\n",
      "-------------------------------\n",
      "train_loss tensor(1.8432, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8611, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9572, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2599\n",
      "-------------------------------\n",
      "train_loss tensor(1.8593, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9178, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9852, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2600\n",
      "-------------------------------\n",
      "train_loss tensor(1.9006, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8438, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1669, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2601\n",
      "-------------------------------\n",
      "train_loss tensor(1.9496, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9016, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9129, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2602\n",
      "-------------------------------\n",
      "train_loss tensor(1.8991, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9827, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9985, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2603\n",
      "-------------------------------\n",
      "train_loss tensor(1.9984, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8845, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9965, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2604\n",
      "-------------------------------\n",
      "train_loss tensor(1.9518, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9714, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0735, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2605\n",
      "-------------------------------\n",
      "train_loss tensor(1.9186, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0119, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0432, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2606\n",
      "-------------------------------\n",
      "train_loss tensor(1.8845, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8565, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9137, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2607\n",
      "-------------------------------\n",
      "train_loss tensor(1.8761, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8597, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0683, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2608\n",
      "-------------------------------\n",
      "train_loss tensor(1.8517, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9324, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1140, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2609\n",
      "-------------------------------\n",
      "train_loss tensor(1.8326, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8662, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9578, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2610\n",
      "-------------------------------\n",
      "train_loss tensor(1.8419, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8584, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0472, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2611\n",
      "-------------------------------\n",
      "train_loss tensor(1.8301, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8930, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9901, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2612\n",
      "-------------------------------\n",
      "train_loss tensor(1.8254, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8491, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0292, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2613\n",
      "-------------------------------\n",
      "train_loss tensor(1.8214, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8880, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9720, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2614\n",
      "-------------------------------\n",
      "train_loss tensor(1.8266, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8949, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9400, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2615\n",
      "-------------------------------\n",
      "train_loss tensor(1.8382, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8803, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9813, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2616\n",
      "-------------------------------\n",
      "train_loss tensor(1.8386, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8797, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0018, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2617\n",
      "-------------------------------\n",
      "train_loss tensor(1.8254, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8748, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9989, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2618\n",
      "-------------------------------\n",
      "train_loss tensor(1.8327, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8868, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0066, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2619\n",
      "-------------------------------\n",
      "train_loss tensor(1.8304, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8950, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9477, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2620\n",
      "-------------------------------\n",
      "train_loss tensor(1.8431, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8759, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9669, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2621\n",
      "-------------------------------\n",
      "train_loss tensor(1.8391, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8884, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(7.9770, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2622\n",
      "-------------------------------\n",
      "train_loss tensor(1.8409, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9244, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0596, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2623\n",
      "-------------------------------\n",
      "train_loss tensor(1.8455, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9020, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8756, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2624\n",
      "-------------------------------\n",
      "train_loss tensor(1.8353, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8413, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9142, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2625\n",
      "-------------------------------\n",
      "train_loss tensor(1.8290, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9374, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9689, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2626\n",
      "-------------------------------\n",
      "train_loss tensor(1.8254, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8622, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9701, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2627\n",
      "-------------------------------\n",
      "train_loss tensor(1.8246, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9274, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0694, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2628\n",
      "-------------------------------\n",
      "train_loss tensor(1.8203, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8724, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0139, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2629\n",
      "-------------------------------\n",
      "train_loss tensor(1.8238, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9140, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9710, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2630\n",
      "-------------------------------\n",
      "train_loss tensor(1.8302, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8816, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0830, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2631\n",
      "-------------------------------\n",
      "train_loss tensor(1.8282, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8915, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9422, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2632\n",
      "-------------------------------\n",
      "train_loss tensor(1.8346, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9297, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1232, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2633\n",
      "-------------------------------\n",
      "train_loss tensor(1.8374, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8722, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0459, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2634\n",
      "-------------------------------\n",
      "train_loss tensor(1.8533, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8813, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9778, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2635\n",
      "-------------------------------\n",
      "train_loss tensor(1.8473, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8705, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0061, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2636\n",
      "-------------------------------\n",
      "train_loss tensor(1.8269, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8870, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0499, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2637\n",
      "-------------------------------\n",
      "train_loss tensor(1.8232, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8761, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9919, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2638\n",
      "-------------------------------\n",
      "train_loss tensor(1.8375, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9292, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0494, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2639\n",
      "-------------------------------\n",
      "train_loss tensor(1.8269, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8508, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9630, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2640\n",
      "-------------------------------\n",
      "train_loss tensor(1.8321, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9217, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1407, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2641\n",
      "-------------------------------\n",
      "train_loss tensor(1.8295, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9013, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0853, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2642\n",
      "-------------------------------\n",
      "train_loss tensor(1.8308, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9165, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1166, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2643\n",
      "-------------------------------\n",
      "train_loss tensor(1.8121, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8732, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0819, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2644\n",
      "-------------------------------\n",
      "train_loss tensor(1.8174, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9339, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0677, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2645\n",
      "-------------------------------\n",
      "train_loss tensor(1.8286, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8416, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0692, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2646\n",
      "-------------------------------\n",
      "train_loss tensor(1.8346, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8676, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0052, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2647\n",
      "-------------------------------\n",
      "train_loss tensor(1.8293, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9068, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9654, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2648\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(1.8185, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9029, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9342, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2649\n",
      "-------------------------------\n",
      "train_loss tensor(1.8046, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9018, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9375, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2650\n",
      "-------------------------------\n",
      "train_loss tensor(1.8136, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9307, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9946, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2651\n",
      "-------------------------------\n",
      "train_loss tensor(1.8337, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8690, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0864, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2652\n",
      "-------------------------------\n",
      "train_loss tensor(1.8194, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9234, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9706, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2653\n",
      "-------------------------------\n",
      "train_loss tensor(1.8124, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8906, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8861, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2654\n",
      "-------------------------------\n",
      "train_loss tensor(1.8163, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9040, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9997, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2655\n",
      "-------------------------------\n",
      "train_loss tensor(1.8161, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8705, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0521, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2656\n",
      "-------------------------------\n",
      "train_loss tensor(1.8129, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8812, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0535, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2657\n",
      "-------------------------------\n",
      "train_loss tensor(1.8126, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9182, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0188, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2658\n",
      "-------------------------------\n",
      "train_loss tensor(1.8113, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9049, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1367, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2659\n",
      "-------------------------------\n",
      "train_loss tensor(1.8213, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9112, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9806, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2660\n",
      "-------------------------------\n",
      "train_loss tensor(1.8007, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8868, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0851, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2661\n",
      "-------------------------------\n",
      "train_loss tensor(1.8073, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8995, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0839, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2662\n",
      "-------------------------------\n",
      "train_loss tensor(1.7986, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9235, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0482, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2663\n",
      "-------------------------------\n",
      "train_loss tensor(1.8038, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8868, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0481, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2664\n",
      "-------------------------------\n",
      "train_loss tensor(1.8083, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9221, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0244, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2665\n",
      "-------------------------------\n",
      "train_loss tensor(1.8058, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8929, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0081, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2666\n",
      "-------------------------------\n",
      "train_loss tensor(1.8015, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9201, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0960, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2667\n",
      "-------------------------------\n",
      "train_loss tensor(1.8099, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8897, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9908, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2668\n",
      "-------------------------------\n",
      "train_loss tensor(1.8074, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8681, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0644, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2669\n",
      "-------------------------------\n",
      "train_loss tensor(1.8022, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9375, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0212, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2670\n",
      "-------------------------------\n",
      "train_loss tensor(1.8075, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9023, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0567, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2671\n",
      "-------------------------------\n",
      "train_loss tensor(1.8124, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8934, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0670, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2672\n",
      "-------------------------------\n",
      "train_loss tensor(1.8011, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9314, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0216, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2673\n",
      "-------------------------------\n",
      "train_loss tensor(1.7992, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8920, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0189, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2674\n",
      "-------------------------------\n",
      "train_loss tensor(1.7986, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8810, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(8.0429, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2675\n",
      "-------------------------------\n",
      "train_loss tensor(1.8004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9217, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9646, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2676\n",
      "-------------------------------\n",
      "train_loss tensor(1.8123, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8973, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0808, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2677\n",
      "-------------------------------\n",
      "train_loss tensor(1.8019, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8923, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0868, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2678\n",
      "-------------------------------\n",
      "train_loss tensor(1.7981, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9126, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0714, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2679\n",
      "-------------------------------\n",
      "train_loss tensor(1.8004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8867, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0345, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2680\n",
      "-------------------------------\n",
      "train_loss tensor(1.7942, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9109, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9778, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2681\n",
      "-------------------------------\n",
      "train_loss tensor(1.7967, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9277, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0454, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2682\n",
      "-------------------------------\n",
      "train_loss tensor(1.8097, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8706, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1176, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2683\n",
      "-------------------------------\n",
      "train_loss tensor(1.7983, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9524, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1234, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2684\n",
      "-------------------------------\n",
      "train_loss tensor(1.7985, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8744, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1304, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2685\n",
      "-------------------------------\n",
      "train_loss tensor(1.7880, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9021, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1497, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2686\n",
      "-------------------------------\n",
      "train_loss tensor(1.7916, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9221, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0613, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2687\n",
      "-------------------------------\n",
      "train_loss tensor(1.7924, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9290, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0815, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2688\n",
      "-------------------------------\n",
      "train_loss tensor(1.8033, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8875, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0919, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2689\n",
      "-------------------------------\n",
      "train_loss tensor(1.8375, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9596, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2450, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2690\n",
      "-------------------------------\n",
      "train_loss tensor(1.8331, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9612, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1223, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2691\n",
      "-------------------------------\n",
      "train_loss tensor(1.8197, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8873, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0346, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2692\n",
      "-------------------------------\n",
      "train_loss tensor(1.8245, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9243, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1913, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2693\n",
      "-------------------------------\n",
      "train_loss tensor(1.8326, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8675, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0597, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2694\n",
      "-------------------------------\n",
      "train_loss tensor(1.8019, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9212, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0599, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2695\n",
      "-------------------------------\n",
      "train_loss tensor(1.7955, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0897, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2696\n",
      "-------------------------------\n",
      "train_loss tensor(1.8119, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8909, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0928, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2697\n",
      "-------------------------------\n",
      "train_loss tensor(1.8236, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9675, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0503, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2698\n",
      "-------------------------------\n",
      "train_loss tensor(1.8182, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8720, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0494, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2699\n",
      "-------------------------------\n",
      "train_loss tensor(1.8005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9455, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1199, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2700\n",
      "-------------------------------\n",
      "train_loss tensor(1.8161, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9452, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0271, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2701\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(1.8369, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9439, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1781, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2702\n",
      "-------------------------------\n",
      "train_loss tensor(1.8392, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9148, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1235, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2703\n",
      "-------------------------------\n",
      "train_loss tensor(1.8290, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8719, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0233, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2704\n",
      "-------------------------------\n",
      "train_loss tensor(1.8094, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9420, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3670, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2705\n",
      "-------------------------------\n",
      "train_loss tensor(1.8007, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8741, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1613, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2706\n",
      "-------------------------------\n",
      "train_loss tensor(1.8112, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9778, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1266, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2707\n",
      "-------------------------------\n",
      "train_loss tensor(1.8253, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8534, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1127, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2708\n",
      "-------------------------------\n",
      "train_loss tensor(1.8394, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9448, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0492, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2709\n",
      "-------------------------------\n",
      "train_loss tensor(1.8279, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9300, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1438, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2710\n",
      "-------------------------------\n",
      "train_loss tensor(1.8417, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9549, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.8393, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2711\n",
      "-------------------------------\n",
      "train_loss tensor(1.8469, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8622, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1327, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2712\n",
      "-------------------------------\n",
      "train_loss tensor(1.8633, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9246, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0703, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2713\n",
      "-------------------------------\n",
      "train_loss tensor(1.8584, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9743, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1397, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2714\n",
      "-------------------------------\n",
      "train_loss tensor(1.8395, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9247, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1072, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2715\n",
      "-------------------------------\n",
      "train_loss tensor(1.8609, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9550, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0176, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2716\n",
      "-------------------------------\n",
      "train_loss tensor(1.8407, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8806, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1589, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2717\n",
      "-------------------------------\n",
      "train_loss tensor(1.8460, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0243, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2627, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2718\n",
      "-------------------------------\n",
      "train_loss tensor(1.8632, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8761, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1736, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2719\n",
      "-------------------------------\n",
      "train_loss tensor(1.8598, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9841, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1422, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2720\n",
      "-------------------------------\n",
      "train_loss tensor(1.8516, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9099, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0665, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2721\n",
      "-------------------------------\n",
      "train_loss tensor(1.8331, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0400, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3813, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2722\n",
      "-------------------------------\n",
      "train_loss tensor(1.9434, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9389, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0448, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2723\n",
      "-------------------------------\n",
      "train_loss tensor(1.9739, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9977, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0861, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2724\n",
      "-------------------------------\n",
      "train_loss tensor(1.9626, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8793, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2313, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2725\n",
      "-------------------------------\n",
      "train_loss tensor(1.9478, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9875, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2341, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2726\n",
      "-------------------------------\n",
      "train_loss tensor(1.9128, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8945, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0082, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2727\n",
      "-------------------------------\n",
      "train_loss tensor(1.9074, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9503, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(8.0101, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2728\n",
      "-------------------------------\n",
      "train_loss tensor(1.8828, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0123, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2337, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2729\n",
      "-------------------------------\n",
      "train_loss tensor(1.8367, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8803, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9365, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2730\n",
      "-------------------------------\n",
      "train_loss tensor(1.8158, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9781, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1135, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2731\n",
      "-------------------------------\n",
      "train_loss tensor(1.8302, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8793, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9809, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2732\n",
      "-------------------------------\n",
      "train_loss tensor(1.8033, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8901, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0770, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2733\n",
      "-------------------------------\n",
      "train_loss tensor(1.8011, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9097, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1416, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2734\n",
      "-------------------------------\n",
      "train_loss tensor(1.8058, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8621, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0715, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2735\n",
      "-------------------------------\n",
      "train_loss tensor(1.8061, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9368, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2337, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2736\n",
      "-------------------------------\n",
      "train_loss tensor(1.7948, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8692, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1134, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2737\n",
      "-------------------------------\n",
      "train_loss tensor(1.7851, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9255, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9620, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2738\n",
      "-------------------------------\n",
      "train_loss tensor(1.7807, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9335, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0139, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2739\n",
      "-------------------------------\n",
      "train_loss tensor(1.7780, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8961, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0178, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2740\n",
      "-------------------------------\n",
      "train_loss tensor(1.7765, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8967, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1024, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2741\n",
      "-------------------------------\n",
      "train_loss tensor(1.7831, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8738, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0748, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2742\n",
      "-------------------------------\n",
      "train_loss tensor(1.7827, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9488, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1871, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2743\n",
      "-------------------------------\n",
      "train_loss tensor(1.7937, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9375, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0879, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2744\n",
      "-------------------------------\n",
      "train_loss tensor(1.7876, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8860, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0318, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2745\n",
      "-------------------------------\n",
      "train_loss tensor(1.7828, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9188, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0475, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2746\n",
      "-------------------------------\n",
      "train_loss tensor(1.7812, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8628, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0312, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2747\n",
      "-------------------------------\n",
      "train_loss tensor(1.7860, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9152, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2321, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2748\n",
      "-------------------------------\n",
      "train_loss tensor(1.7691, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8706, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9772, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2749\n",
      "-------------------------------\n",
      "train_loss tensor(1.7787, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9447, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1705, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2750\n",
      "-------------------------------\n",
      "train_loss tensor(1.7842, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8742, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9933, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2751\n",
      "-------------------------------\n",
      "train_loss tensor(1.7800, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9284, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1825, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2752\n",
      "-------------------------------\n",
      "train_loss tensor(1.7773, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9015, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9983, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2753\n",
      "-------------------------------\n",
      "train_loss tensor(1.7763, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8955, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0726, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2754\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(1.7801, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9084, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0751, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2755\n",
      "-------------------------------\n",
      "train_loss tensor(1.7965, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9484, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0043, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2756\n",
      "-------------------------------\n",
      "train_loss tensor(1.7867, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8982, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9249, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2757\n",
      "-------------------------------\n",
      "train_loss tensor(1.7902, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9080, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2758\n",
      "-------------------------------\n",
      "train_loss tensor(1.7926, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8958, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9886, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2759\n",
      "-------------------------------\n",
      "train_loss tensor(1.7854, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9164, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1316, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2760\n",
      "-------------------------------\n",
      "train_loss tensor(1.7804, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9226, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1290, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2761\n",
      "-------------------------------\n",
      "train_loss tensor(1.7849, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9065, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0505, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2762\n",
      "-------------------------------\n",
      "train_loss tensor(1.7802, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9281, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1755, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2763\n",
      "-------------------------------\n",
      "train_loss tensor(1.7706, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8676, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1232, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2764\n",
      "-------------------------------\n",
      "train_loss tensor(1.7851, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9292, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9991, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2765\n",
      "-------------------------------\n",
      "train_loss tensor(1.7735, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8996, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1332, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2766\n",
      "-------------------------------\n",
      "train_loss tensor(1.7843, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8873, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1363, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2767\n",
      "-------------------------------\n",
      "train_loss tensor(1.7726, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9236, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1676, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2768\n",
      "-------------------------------\n",
      "train_loss tensor(1.7695, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9112, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2859, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2769\n",
      "-------------------------------\n",
      "train_loss tensor(1.7638, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9098, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1232, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2770\n",
      "-------------------------------\n",
      "train_loss tensor(1.7585, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9271, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1604, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2771\n",
      "-------------------------------\n",
      "train_loss tensor(1.7590, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9095, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1903, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2772\n",
      "-------------------------------\n",
      "train_loss tensor(1.7638, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8968, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1754, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2773\n",
      "-------------------------------\n",
      "train_loss tensor(1.7664, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9275, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0479, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2774\n",
      "-------------------------------\n",
      "train_loss tensor(1.7696, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9272, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0326, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2775\n",
      "-------------------------------\n",
      "train_loss tensor(1.7782, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9241, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2634, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2776\n",
      "-------------------------------\n",
      "train_loss tensor(1.7743, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9428, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0147, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2777\n",
      "-------------------------------\n",
      "train_loss tensor(1.7683, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9308, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1468, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2778\n",
      "-------------------------------\n",
      "train_loss tensor(1.7863, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9127, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1632, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2779\n",
      "-------------------------------\n",
      "train_loss tensor(1.7719, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9440, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1570, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2780\n",
      "-------------------------------\n",
      "train_loss tensor(1.7729, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8934, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(8.0571, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2781\n",
      "-------------------------------\n",
      "train_loss tensor(1.7796, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9284, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1678, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2782\n",
      "-------------------------------\n",
      "train_loss tensor(1.7870, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9345, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1833, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2783\n",
      "-------------------------------\n",
      "train_loss tensor(1.7822, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9196, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2383, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2784\n",
      "-------------------------------\n",
      "train_loss tensor(1.7746, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9307, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1893, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2785\n",
      "-------------------------------\n",
      "train_loss tensor(1.7696, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9313, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1845, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2786\n",
      "-------------------------------\n",
      "train_loss tensor(1.7671, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9031, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1613, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2787\n",
      "-------------------------------\n",
      "train_loss tensor(1.7852, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9291, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3738, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2788\n",
      "-------------------------------\n",
      "train_loss tensor(1.8067, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9325, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1682, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2789\n",
      "-------------------------------\n",
      "train_loss tensor(1.8156, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8996, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1105, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2790\n",
      "-------------------------------\n",
      "train_loss tensor(1.7869, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9499, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2098, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2791\n",
      "-------------------------------\n",
      "train_loss tensor(1.7975, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9113, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0520, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2792\n",
      "-------------------------------\n",
      "train_loss tensor(1.8057, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9310, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3240, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2793\n",
      "-------------------------------\n",
      "train_loss tensor(1.7751, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9738, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2183, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2794\n",
      "-------------------------------\n",
      "train_loss tensor(1.7720, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9221, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1180, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2795\n",
      "-------------------------------\n",
      "train_loss tensor(1.7669, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9455, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6546, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2796\n",
      "-------------------------------\n",
      "train_loss tensor(1.7723, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9359, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1425, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2797\n",
      "-------------------------------\n",
      "train_loss tensor(1.7752, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9259, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2334, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2798\n",
      "-------------------------------\n",
      "train_loss tensor(1.7683, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9101, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0741, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2799\n",
      "-------------------------------\n",
      "train_loss tensor(1.7556, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9110, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0953, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2800\n",
      "-------------------------------\n",
      "train_loss tensor(1.7568, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9020, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2056, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2801\n",
      "-------------------------------\n",
      "train_loss tensor(1.7574, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9177, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1684, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2802\n",
      "-------------------------------\n",
      "train_loss tensor(1.7684, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9475, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4047, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2803\n",
      "-------------------------------\n",
      "train_loss tensor(1.7736, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9226, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2702, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2804\n",
      "-------------------------------\n",
      "train_loss tensor(1.7745, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8867, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0628, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2805\n",
      "-------------------------------\n",
      "train_loss tensor(1.7858, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9627, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3560, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2806\n",
      "-------------------------------\n",
      "train_loss tensor(1.7803, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9259, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1395, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2807\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(1.7635, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9488, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1406, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2808\n",
      "-------------------------------\n",
      "train_loss tensor(1.7552, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8929, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2342, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2809\n",
      "-------------------------------\n",
      "train_loss tensor(1.7525, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9571, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2652, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2810\n",
      "-------------------------------\n",
      "train_loss tensor(1.7516, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9218, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1202, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2811\n",
      "-------------------------------\n",
      "train_loss tensor(1.7510, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9399, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5741, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2812\n",
      "-------------------------------\n",
      "train_loss tensor(1.7538, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9390, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0824, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2813\n",
      "-------------------------------\n",
      "train_loss tensor(1.7591, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9226, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2526, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2814\n",
      "-------------------------------\n",
      "train_loss tensor(1.7573, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9082, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3165, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2815\n",
      "-------------------------------\n",
      "train_loss tensor(1.7708, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9319, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0811, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2816\n",
      "-------------------------------\n",
      "train_loss tensor(1.7766, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9282, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1618, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2817\n",
      "-------------------------------\n",
      "train_loss tensor(1.7741, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9713, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2753, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2818\n",
      "-------------------------------\n",
      "train_loss tensor(1.7695, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9236, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3681, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2819\n",
      "-------------------------------\n",
      "train_loss tensor(1.7632, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9455, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2327, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2820\n",
      "-------------------------------\n",
      "train_loss tensor(1.7877, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9697, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2862, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2821\n",
      "-------------------------------\n",
      "train_loss tensor(1.7687, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8943, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1965, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2822\n",
      "-------------------------------\n",
      "train_loss tensor(1.7589, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9465, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4618, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2823\n",
      "-------------------------------\n",
      "train_loss tensor(1.7561, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9053, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0968, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2824\n",
      "-------------------------------\n",
      "train_loss tensor(1.7768, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9803, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5828, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2825\n",
      "-------------------------------\n",
      "train_loss tensor(1.7742, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9014, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(7.9560, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2826\n",
      "-------------------------------\n",
      "train_loss tensor(1.7726, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9468, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3064, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2827\n",
      "-------------------------------\n",
      "train_loss tensor(1.7634, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9263, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2508, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2828\n",
      "-------------------------------\n",
      "train_loss tensor(1.7729, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9372, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6514, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2829\n",
      "-------------------------------\n",
      "train_loss tensor(1.7591, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9187, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2356, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2830\n",
      "-------------------------------\n",
      "train_loss tensor(1.7535, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9330, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2810, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2831\n",
      "-------------------------------\n",
      "train_loss tensor(1.7494, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9366, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3155, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2832\n",
      "-------------------------------\n",
      "train_loss tensor(1.7451, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9049, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1877, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2833\n",
      "-------------------------------\n",
      "train_loss tensor(1.7529, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9693, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(8.4607, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2834\n",
      "-------------------------------\n",
      "train_loss tensor(1.7533, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8854, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1640, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2835\n",
      "-------------------------------\n",
      "train_loss tensor(1.7686, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9278, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3389, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2836\n",
      "-------------------------------\n",
      "train_loss tensor(1.7691, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9527, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1834, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2837\n",
      "-------------------------------\n",
      "train_loss tensor(1.7764, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9296, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1879, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2838\n",
      "-------------------------------\n",
      "train_loss tensor(1.7774, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9585, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2647, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2839\n",
      "-------------------------------\n",
      "train_loss tensor(1.7699, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9487, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4612, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2840\n",
      "-------------------------------\n",
      "train_loss tensor(1.7687, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9403, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3985, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2841\n",
      "-------------------------------\n",
      "train_loss tensor(1.7612, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9496, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3693, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2842\n",
      "-------------------------------\n",
      "train_loss tensor(1.7644, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9772, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2761, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2843\n",
      "-------------------------------\n",
      "train_loss tensor(1.7837, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9400, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5083, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2844\n",
      "-------------------------------\n",
      "train_loss tensor(1.7941, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9380, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1031, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2845\n",
      "-------------------------------\n",
      "train_loss tensor(1.7777, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0034, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4694, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2846\n",
      "-------------------------------\n",
      "train_loss tensor(1.7593, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9085, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0736, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2847\n",
      "-------------------------------\n",
      "train_loss tensor(1.7485, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9749, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3773, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2848\n",
      "-------------------------------\n",
      "train_loss tensor(1.7450, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9270, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3935, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2849\n",
      "-------------------------------\n",
      "train_loss tensor(1.7394, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9548, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4929, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2850\n",
      "-------------------------------\n",
      "train_loss tensor(1.7445, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9291, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2676, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2851\n",
      "-------------------------------\n",
      "train_loss tensor(1.7434, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9590, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5370, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2852\n",
      "-------------------------------\n",
      "train_loss tensor(1.7544, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9327, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4209, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2853\n",
      "-------------------------------\n",
      "train_loss tensor(1.7613, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9592, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4072, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2854\n",
      "-------------------------------\n",
      "train_loss tensor(1.7551, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9516, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5279, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2855\n",
      "-------------------------------\n",
      "train_loss tensor(1.7606, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9650, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2908, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2856\n",
      "-------------------------------\n",
      "train_loss tensor(1.7564, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9504, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3740, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2857\n",
      "-------------------------------\n",
      "train_loss tensor(1.7513, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9287, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5274, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2858\n",
      "-------------------------------\n",
      "train_loss tensor(1.7820, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9383, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4256, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2859\n",
      "-------------------------------\n",
      "train_loss tensor(1.7631, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9571, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2869, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2860\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(1.7603, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8990, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3345, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2861\n",
      "-------------------------------\n",
      "train_loss tensor(1.7634, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9830, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5979, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2862\n",
      "-------------------------------\n",
      "train_loss tensor(1.7834, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9597, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2264, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2863\n",
      "-------------------------------\n",
      "train_loss tensor(1.7982, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9655, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3761, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2864\n",
      "-------------------------------\n",
      "train_loss tensor(1.8076, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9755, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7506, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2865\n",
      "-------------------------------\n",
      "train_loss tensor(1.7961, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9524, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2803, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2866\n",
      "-------------------------------\n",
      "train_loss tensor(1.7506, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0164, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5775, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2867\n",
      "-------------------------------\n",
      "train_loss tensor(1.7579, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9090, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3120, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2868\n",
      "-------------------------------\n",
      "train_loss tensor(1.7525, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9483, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3227, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2869\n",
      "-------------------------------\n",
      "train_loss tensor(1.7439, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9563, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4601, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2870\n",
      "-------------------------------\n",
      "train_loss tensor(1.7451, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9569, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8022, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2871\n",
      "-------------------------------\n",
      "train_loss tensor(1.7373, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9010, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4365, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2872\n",
      "-------------------------------\n",
      "train_loss tensor(1.7531, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9954, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9218, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2873\n",
      "-------------------------------\n",
      "train_loss tensor(1.7519, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9159, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1145, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2874\n",
      "-------------------------------\n",
      "train_loss tensor(1.7731, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9894, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8461, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2875\n",
      "-------------------------------\n",
      "train_loss tensor(1.7823, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9425, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3280, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2876\n",
      "-------------------------------\n",
      "train_loss tensor(1.7760, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9926, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5413, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2877\n",
      "-------------------------------\n",
      "train_loss tensor(1.7928, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9803, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6437, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2878\n",
      "-------------------------------\n",
      "train_loss tensor(1.7919, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9209, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2125, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2879\n",
      "-------------------------------\n",
      "train_loss tensor(1.7692, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0310, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6909, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2880\n",
      "-------------------------------\n",
      "train_loss tensor(1.7973, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8944, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2017, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2881\n",
      "-------------------------------\n",
      "train_loss tensor(1.7903, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0344, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.1463, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2882\n",
      "-------------------------------\n",
      "train_loss tensor(1.7854, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8811, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1268, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2883\n",
      "-------------------------------\n",
      "train_loss tensor(1.7798, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9638, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5130, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2884\n",
      "-------------------------------\n",
      "train_loss tensor(1.7855, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0053, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6785, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2885\n",
      "-------------------------------\n",
      "train_loss tensor(1.7802, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9448, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2833, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2886\n",
      "-------------------------------\n",
      "train_loss tensor(1.7557, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9786, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(8.4658, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2887\n",
      "-------------------------------\n",
      "train_loss tensor(1.7582, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9497, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4657, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2888\n",
      "-------------------------------\n",
      "train_loss tensor(1.7628, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9818, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7336, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2889\n",
      "-------------------------------\n",
      "train_loss tensor(1.7613, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9418, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4190, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2890\n",
      "-------------------------------\n",
      "train_loss tensor(1.7636, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9671, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5826, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2891\n",
      "-------------------------------\n",
      "train_loss tensor(1.7678, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9306, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6436, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2892\n",
      "-------------------------------\n",
      "train_loss tensor(1.7613, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9738, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4449, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2893\n",
      "-------------------------------\n",
      "train_loss tensor(1.7467, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9351, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5333, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2894\n",
      "-------------------------------\n",
      "train_loss tensor(1.7622, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9672, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8022, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2895\n",
      "-------------------------------\n",
      "train_loss tensor(1.7350, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9272, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2577, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2896\n",
      "-------------------------------\n",
      "train_loss tensor(1.7433, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9342, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5060, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2897\n",
      "-------------------------------\n",
      "train_loss tensor(1.7296, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9266, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4009, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2898\n",
      "-------------------------------\n",
      "train_loss tensor(1.7310, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9631, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7381, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2899\n",
      "-------------------------------\n",
      "train_loss tensor(1.7315, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9247, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3563, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2900\n",
      "-------------------------------\n",
      "train_loss tensor(1.7373, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9898, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8029, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2901\n",
      "-------------------------------\n",
      "train_loss tensor(1.7408, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9137, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4717, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2902\n",
      "-------------------------------\n",
      "train_loss tensor(1.7348, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9405, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6771, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2903\n",
      "-------------------------------\n",
      "train_loss tensor(1.7303, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9490, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7252, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2904\n",
      "-------------------------------\n",
      "train_loss tensor(1.7297, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9437, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3189, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2905\n",
      "-------------------------------\n",
      "train_loss tensor(1.7614, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9559, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5660, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2906\n",
      "-------------------------------\n",
      "train_loss tensor(1.7353, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9661, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5732, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2907\n",
      "-------------------------------\n",
      "train_loss tensor(1.7250, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9675, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4682, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2908\n",
      "-------------------------------\n",
      "train_loss tensor(1.7232, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9634, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6985, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2909\n",
      "-------------------------------\n",
      "train_loss tensor(1.7289, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9123, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3494, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2910\n",
      "-------------------------------\n",
      "train_loss tensor(1.7212, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9617, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4649, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2911\n",
      "-------------------------------\n",
      "train_loss tensor(1.7156, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9273, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4361, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2912\n",
      "-------------------------------\n",
      "train_loss tensor(1.7388, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9840, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7529, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2913\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(1.7684, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9613, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6611, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2914\n",
      "-------------------------------\n",
      "train_loss tensor(1.7629, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9390, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5665, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2915\n",
      "-------------------------------\n",
      "train_loss tensor(1.8167, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9470, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1833, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2916\n",
      "-------------------------------\n",
      "train_loss tensor(1.7694, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0183, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7686, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2917\n",
      "-------------------------------\n",
      "train_loss tensor(1.7951, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9401, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2852, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2918\n",
      "-------------------------------\n",
      "train_loss tensor(1.8597, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9948, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.0525, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2919\n",
      "-------------------------------\n",
      "train_loss tensor(1.8281, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0037, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2914, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2920\n",
      "-------------------------------\n",
      "train_loss tensor(1.8404, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9503, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5839, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2921\n",
      "-------------------------------\n",
      "train_loss tensor(1.8040, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9813, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3655, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2922\n",
      "-------------------------------\n",
      "train_loss tensor(1.7894, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0066, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3126, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2923\n",
      "-------------------------------\n",
      "train_loss tensor(1.7786, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9417, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6241, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2924\n",
      "-------------------------------\n",
      "train_loss tensor(1.7858, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0018, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1744, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2925\n",
      "-------------------------------\n",
      "train_loss tensor(1.8320, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9649, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9134, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2926\n",
      "-------------------------------\n",
      "train_loss tensor(1.7794, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9411, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.0259, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2927\n",
      "-------------------------------\n",
      "train_loss tensor(1.7998, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9897, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3777, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2928\n",
      "-------------------------------\n",
      "train_loss tensor(1.7667, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8979, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2339, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2929\n",
      "-------------------------------\n",
      "train_loss tensor(1.7580, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9923, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6011, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2930\n",
      "-------------------------------\n",
      "train_loss tensor(1.7748, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9853, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4876, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2931\n",
      "-------------------------------\n",
      "train_loss tensor(1.7632, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9718, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3148, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2932\n",
      "-------------------------------\n",
      "train_loss tensor(1.7822, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9815, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.9026, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2933\n",
      "-------------------------------\n",
      "train_loss tensor(1.8012, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9936, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5791, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2934\n",
      "-------------------------------\n",
      "train_loss tensor(1.7845, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9260, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.1982, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2935\n",
      "-------------------------------\n",
      "train_loss tensor(1.7650, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0088, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4316, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2936\n",
      "-------------------------------\n",
      "train_loss tensor(1.7741, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8974, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5435, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2937\n",
      "-------------------------------\n",
      "train_loss tensor(1.7630, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9326, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3965, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2938\n",
      "-------------------------------\n",
      "train_loss tensor(1.7407, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9845, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2995, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2939\n",
      "-------------------------------\n",
      "train_loss tensor(1.7207, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9670, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(8.5580, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2940\n",
      "-------------------------------\n",
      "train_loss tensor(1.7398, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.8990, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4043, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2941\n",
      "-------------------------------\n",
      "train_loss tensor(1.7301, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9918, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6876, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2942\n",
      "-------------------------------\n",
      "train_loss tensor(1.7266, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9285, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4615, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2943\n",
      "-------------------------------\n",
      "train_loss tensor(1.7177, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9456, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4954, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2944\n",
      "-------------------------------\n",
      "train_loss tensor(1.7151, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9425, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3056, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2945\n",
      "-------------------------------\n",
      "train_loss tensor(1.7227, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9491, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5693, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2946\n",
      "-------------------------------\n",
      "train_loss tensor(1.7174, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9209, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4415, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2947\n",
      "-------------------------------\n",
      "train_loss tensor(1.7152, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9670, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4472, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2948\n",
      "-------------------------------\n",
      "train_loss tensor(1.7237, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9321, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5281, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2949\n",
      "-------------------------------\n",
      "train_loss tensor(1.7216, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9616, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.2039, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2950\n",
      "-------------------------------\n",
      "train_loss tensor(1.7278, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9570, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6032, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2951\n",
      "-------------------------------\n",
      "train_loss tensor(1.7153, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9043, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5372, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2952\n",
      "-------------------------------\n",
      "train_loss tensor(1.7192, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9747, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6355, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2953\n",
      "-------------------------------\n",
      "train_loss tensor(1.7191, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9276, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3936, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2954\n",
      "-------------------------------\n",
      "train_loss tensor(1.7074, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9693, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6132, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2955\n",
      "-------------------------------\n",
      "train_loss tensor(1.7111, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9544, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5318, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2956\n",
      "-------------------------------\n",
      "train_loss tensor(1.7176, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9831, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5224, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2957\n",
      "-------------------------------\n",
      "train_loss tensor(1.7202, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9563, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4761, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2958\n",
      "-------------------------------\n",
      "train_loss tensor(1.7586, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9674, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6221, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2959\n",
      "-------------------------------\n",
      "train_loss tensor(1.7363, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9734, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3896, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2960\n",
      "-------------------------------\n",
      "train_loss tensor(1.7126, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9751, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6962, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2961\n",
      "-------------------------------\n",
      "train_loss tensor(1.7264, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9204, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7145, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2962\n",
      "-------------------------------\n",
      "train_loss tensor(1.7296, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9753, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7201, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2963\n",
      "-------------------------------\n",
      "train_loss tensor(1.7246, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9567, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6591, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2964\n",
      "-------------------------------\n",
      "train_loss tensor(1.7164, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9524, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7618, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2965\n",
      "-------------------------------\n",
      "train_loss tensor(1.7190, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9740, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5570, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2966\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss tensor(1.7211, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9666, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4623, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2967\n",
      "-------------------------------\n",
      "train_loss tensor(1.7197, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9752, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3808, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2968\n",
      "-------------------------------\n",
      "train_loss tensor(1.7243, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9629, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5414, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2969\n",
      "-------------------------------\n",
      "train_loss tensor(1.7327, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9843, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3430, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2970\n",
      "-------------------------------\n",
      "train_loss tensor(1.7322, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9281, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3554, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2971\n",
      "-------------------------------\n",
      "train_loss tensor(1.7273, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9890, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4061, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2972\n",
      "-------------------------------\n",
      "train_loss tensor(1.7161, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9408, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5114, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2973\n",
      "-------------------------------\n",
      "train_loss tensor(1.7239, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9759, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3499, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2974\n",
      "-------------------------------\n",
      "train_loss tensor(1.7285, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9677, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5808, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2975\n",
      "-------------------------------\n",
      "train_loss tensor(1.7284, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9227, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4503, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2976\n",
      "-------------------------------\n",
      "train_loss tensor(1.7190, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9876, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.8255, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2977\n",
      "-------------------------------\n",
      "train_loss tensor(1.7521, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9408, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3222, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2978\n",
      "-------------------------------\n",
      "train_loss tensor(1.7549, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9560, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4445, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2979\n",
      "-------------------------------\n",
      "train_loss tensor(1.7327, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9987, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6487, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2980\n",
      "-------------------------------\n",
      "train_loss tensor(1.7241, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9748, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3244, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2981\n",
      "-------------------------------\n",
      "train_loss tensor(1.7281, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9646, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5453, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2982\n",
      "-------------------------------\n",
      "train_loss tensor(1.7356, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9925, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5634, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2983\n",
      "-------------------------------\n",
      "train_loss tensor(1.7490, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9898, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5660, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2984\n",
      "-------------------------------\n",
      "train_loss tensor(1.7488, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9990, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6154, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2985\n",
      "-------------------------------\n",
      "train_loss tensor(1.7695, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0214, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.3031, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2986\n",
      "-------------------------------\n",
      "train_loss tensor(1.7820, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9592, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6317, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2987\n",
      "-------------------------------\n",
      "train_loss tensor(1.7579, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9344, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7343, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2988\n",
      "-------------------------------\n",
      "train_loss tensor(1.7876, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0607, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7915, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2989\n",
      "-------------------------------\n",
      "train_loss tensor(1.7885, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9781, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6386, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2990\n",
      "-------------------------------\n",
      "train_loss tensor(1.7592, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0135, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.4123, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2991\n",
      "-------------------------------\n",
      "train_loss tensor(1.7570, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(5.0401, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7627, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2992\n",
      "-------------------------------\n",
      "train_loss tensor(1.7546, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9322, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nobil_loss tensor(8.5129, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2993\n",
      "-------------------------------\n",
      "train_loss tensor(1.7473, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9841, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.1656, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2994\n",
      "-------------------------------\n",
      "train_loss tensor(1.7350, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9323, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5137, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2995\n",
      "-------------------------------\n",
      "train_loss tensor(1.7102, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9663, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7758, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2996\n",
      "-------------------------------\n",
      "train_loss tensor(1.7066, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9211, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5554, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2997\n",
      "-------------------------------\n",
      "train_loss tensor(1.7106, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9984, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.7355, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2998\n",
      "-------------------------------\n",
      "train_loss tensor(1.7020, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9508, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.6460, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 2999\n",
      "-------------------------------\n",
      "train_loss tensor(1.6981, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9646, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(9.0576, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch 3000\n",
      "-------------------------------\n",
      "train_loss tensor(1.6947, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_loss tensor(4.9665, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "test_nobil_loss tensor(8.5653, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "class LRCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LRCN, self).__init__()\n",
    "        self.layer_1 = nn.Conv2d(3,15,5,stride=2,dtype=torch.float64)\n",
    "        self.layer_2 = nn.Conv2d(15,13,5,stride=2,dtype=torch.float64)\n",
    "        self.layer_3 = nn.Conv2d(13,7,5,stride=2,dtype=torch.float64)\n",
    "        self.layer_4 = nn.Conv2d(7,3,5,stride=2,dtype=torch.float64)\n",
    "        self.layer_5 = nn.LSTM(81,40,2, batch_first = True,dtype=torch.float64)\n",
    "        self.layer_6 = nn.Linear(40, 1,dtype=torch.float64)\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.length = x_train.shape[1]\n",
    "        self.relu = nn.ReLU()\n",
    "        self.glob_flag=0\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.reshape((-1, 3, 100, 200))\n",
    "        x = self.layer_1(x)\n",
    "        self.a = self.relu(x)\n",
    "        x = self.layer_2(self.a)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer_3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer_4(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.reshape((self.batch_size, self.length, x.shape[-3],x.shape[-2],x.shape[-1]))\n",
    "        x = x.reshape((self.batch_size, self.length, x.shape[-3]*x.shape[-2]*x.shape[-1]))\n",
    "        x, (h_n, c_n) = self.layer_5(x)\n",
    "        #print(x.shape,h_n.shape,c_n.shape)\n",
    "        x = self.relu(x[:,1:,:])\n",
    "        x = self.layer_6(x)\n",
    "        x = torch.squeeze(x,dim=2)\n",
    "        return x\n",
    "\n",
    "model = LRCN().cuda()\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.MultiplicativeLR(optimizer=optimizer,\n",
    "                                        lr_lambda=lambda epoch: 1 ,\n",
    "                                        last_epoch=-1,\n",
    "                                        verbose=False)\n",
    "def image_out(feature,batch,name):\n",
    "    width_ = feature.grad.shape[-1]\n",
    "    #print(torch.min(feature.grad.detach()))\n",
    "    #result_temp = torch.sum(feature.grad.detach(),-1)\n",
    "    #important\n",
    "    result_temp = torch.sum(torch.abs(feature.grad.detach()),-1)\n",
    "    #print(torch.where(result_temp>=0))\n",
    "    height_ = result_temp.shape[-1]\n",
    "    result_temp = torch.sum(result_temp,-1)\n",
    "    channel=result_temp.shape[1]\n",
    "    result_temp = result_temp/channel\n",
    "    #print(result_temp.shape)\n",
    "    temp_ = feature.detach().reshape((model.batch_size*model.length, channel, height_,width_))\n",
    "    #print(torch.min(temp_))\n",
    "    #print(result_temp.shape,temp_.shape)\n",
    "    for i in range(model.length):\n",
    "        temp_sum=0\n",
    "        for j in range(result_temp.shape[1]):\n",
    "            #print(i,j,result_temp.shape[1])\n",
    "            temp_sum += result_temp[batch*model.length+i,j]*(temp_[batch*model.length+i,j,:,:])\n",
    "        #temp_sum=temp_sum\n",
    "        temp_sum = temp_sum.detach().cpu().numpy()\n",
    "        #print(np.min(temp_sum))\n",
    "        temp_positive = np.where(temp_sum>0, temp_sum,0)\n",
    "        temp_negative = np.where(temp_sum<0, temp_sum,0)\n",
    "        \n",
    "        #print(np.min(temp_sum))\n",
    "        min_= np.min(temp_sum)\n",
    "        temp_sum=temp_sum-min_\n",
    "        max_ = np.max(temp_sum)\n",
    "        result_ = np.around(((255*temp_sum)/max_)).astype(np.uint8)\n",
    "        pil_image=Image.fromarray(result_)\n",
    "        name_final = name+str(i)+'.png'\n",
    "        pil_image.save(name_final)\n",
    "        pil_image.close()\n",
    "        \"\"\"\n",
    "        max_ = np.max(temp_positive)\n",
    "        result_ = np.around(((255*temp_positive)/max_)).astype(np.uint8)\n",
    "        pil_image=Image.fromarray(result_)\n",
    "        name_final = name+str(i)+'_positive.png'\n",
    "        pil_image.save(name_final)\n",
    "        pil_image.close()\n",
    "        \n",
    "        temp_negative=np.abs(temp_negative)\n",
    "        max_ = np.max(temp_negative)\n",
    "        result_ = np.around(((255*temp_sum)/max_)).astype(np.uint8)\n",
    "        pil_image=Image.fromarray(result_)\n",
    "        name_final = name+str(i)+'_negative.png'\n",
    "        pil_image.save(name_final)\n",
    "        pil_image.close()\n",
    "        \"\"\"\n",
    "def train(dataloader, model, loss, optimizer):\n",
    "    loss_sum=0\n",
    "    total_number=len(dataloader)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        pred = model(X)\n",
    "        loss_result = loss(pred, y)\n",
    "        #print(pred.shape,y.shape)\n",
    "        optimizer.zero_grad()\n",
    "        if total_number == batch + 1:\n",
    "            model.a.retain_grad()\n",
    "        loss_result.backward()\n",
    "        optimizer.step()\n",
    "        loss_sum+=loss_result\n",
    "    loss_sum/(batch+1)\n",
    "    \n",
    "    print(\"train_loss\",loss_sum)\n",
    "    \n",
    "    if model.glob_flag==100:\n",
    "        image_out(model.a,0,\"training_LRCN_1_\")\n",
    "        #model.glob_flag=0\n",
    "        torch.save(model,\"model_1.pt\")\n",
    "        #time.sleep(1)\n",
    "            \n",
    "def test(dataloader, dataloader_2, model, loss):\n",
    "    loss_sum=0\n",
    "    total_number=len(dataloader)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        pred = model(X)\n",
    "        loss_result = loss(pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        #print(pred.shape,y.shape)\n",
    "        if total_number == batch + 1:\n",
    "            #optimizer.zero_grad()\n",
    "            model.a.retain_grad()\n",
    "        loss_result.backward()\n",
    "        loss_sum+=loss_result\n",
    "    loss_sum/(batch+1)\n",
    "    print(\"test_loss\",loss_sum)\n",
    "    \n",
    "    loss_sum=0\n",
    "    total_number=len(dataloader_2)\n",
    "    for batch, (X, y) in enumerate(dataloader_2):\n",
    "        pred = model(X)\n",
    "        loss_result = loss(pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        #print(pred.shape,y.shape)\n",
    "        if total_number == batch + 1:\n",
    "            #optimizer.zero_grad()\n",
    "            model.a.retain_grad()\n",
    "        loss_result.backward()\n",
    "        loss_sum+=loss_result\n",
    "    loss_sum/(batch+1)\n",
    "    print(\"test_nobil_loss\",loss_sum)\n",
    "    \n",
    "    if model.glob_flag==100:\n",
    "        model.glob_flag=0\n",
    "        #image_out(model.a,0,\"test_LRCN_1_\")\n",
    "        #time.sleep(1)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(dataloader, model, loss, optimizer)\n",
    "    test(dataloader_test_1, dataloader_test, model, loss)\n",
    "    model.glob_flag+=1\n",
    "    scheduler.step()\n",
    "    \n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
